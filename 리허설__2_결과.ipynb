{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP13VTYADkIlPFLjWjW+aqa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSKimGitHub/real_time_driving_predictor/blob/main/%EB%A6%AC%ED%97%88%EC%84%A4__2_%EA%B2%B0%EA%B3%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 설정"
      ],
      "metadata": {
        "id": "uUFm2M1mMWgk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhCmFpRII-YJ",
        "outputId": "451f40e6-d70b-4764-c31c-17b577091537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.177)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python numpy matplotlib ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hz7R2iysJGz0",
        "outputId": "7a0d4e77-aba8-4e12-d63b-f3ecf2fbbc72"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/towtruck_8_results.csv'\n",
        "file_path2 = '/content/drive/MyDrive/Uturn_7_dlabeled.csv'\n",
        "file_path3 = '/content/drive/MyDrive/driving_11_dlabeled.csv'\n",
        "file_path4 = '/content/drive/MyDrive/driving_12_dlabeled.csv'\n",
        "\n",
        "# CSV 파일을 DataFrame으로 읽어오기\n",
        "driving11 = pd.read_csv(file_path3)\n",
        "truck8 = pd.read_csv(file_path)\n",
        "uturn7 = pd.read_csv(file_path2)\n",
        "driving12 = pd.read_csv(file_path4)"
      ],
      "metadata": {
        "id": "ePat-NilJJjr"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# YOLOv8 모델 로드\n",
        "model = YOLO(\"yolov8n.pt\")  # 가장 가벼운 모델"
      ],
      "metadata": {
        "id": "7o136onXJM0T"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class FM_FTRL_Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim=8, k=4):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_dim, embedding_dim)\n",
        "        self.V = nn.Parameter(torch.randn(input_dim, k) * 0.01)\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        linear_part = self.linear(x)\n",
        "        fm_interactions = 0.5 * torch.sum(\n",
        "            (x @ self.V) ** 2 - (x ** 2) @ (self.V ** 2),\n",
        "            dim=1, keepdim=True\n",
        "        )\n",
        "        fm_interactions_expanded = fm_interactions.reshape(-1, 1).expand(-1, self.embedding_dim)\n",
        "        return linear_part + fm_interactions_expanded\n",
        "\n",
        "class FM_FTRL_WithClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim=8, k=4):\n",
        "        super().__init__()\n",
        "        self.encoder = FM_FTRL_Encoder(input_dim, embedding_dim, k)\n",
        "        self.classifier = nn.Linear(embedding_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedding = self.encoder(x)\n",
        "        logits = self.classifier(embedding)\n",
        "        return torch.sigmoid(logits).squeeze(1), embedding\n",
        "\n",
        "class RehearsalMemory:\n",
        "    def __init__(self, max_samples=1000):\n",
        "        self.max_samples = max_samples\n",
        "        self.data_buffer = []\n",
        "        self.label_buffer = []\n",
        "\n",
        "    def add_samples(self, data, labels):\n",
        "        \"\"\"새로운 데이터 샘플을 메모리에 추가\"\"\"\n",
        "        # 데이터를 numpy 배열로 변환하여 저장\n",
        "        if isinstance(data, torch.Tensor):\n",
        "            data = data.detach().cpu().numpy()\n",
        "        if isinstance(labels, torch.Tensor):\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "\n",
        "        # 데이터를 메모리에 추가\n",
        "        for i in range(len(data)):\n",
        "            self.data_buffer.append(data[i].copy())  # copy()로 깊은 복사\n",
        "            self.label_buffer.append(labels[i].copy())\n",
        "\n",
        "        # 최대 샘플 수를 초과하면 오래된 샘플 제거\n",
        "        if len(self.data_buffer) > self.max_samples:\n",
        "            self.data_buffer = self.data_buffer[-self.max_samples:]\n",
        "            self.label_buffer = self.label_buffer[-self.max_samples:]\n",
        "\n",
        "    def get_rehearsal_batch(self, batch_size=32):\n",
        "        \"\"\"재학습용 배치 데이터 반환\"\"\"\n",
        "        if len(self.data_buffer) == 0:\n",
        "            return None, None\n",
        "\n",
        "        # 랜덤하게 샘플링\n",
        "        indices = np.random.choice(len(self.data_buffer),\n",
        "                                 min(batch_size, len(self.data_buffer)),\n",
        "                                 replace=False)\n",
        "\n",
        "        # numpy 배열을 텐서로 변환\n",
        "        batch_data = torch.tensor(np.array([self.data_buffer[i] for i in indices]), dtype=torch.float32)\n",
        "        batch_labels = torch.tensor(np.array([self.label_buffer[i] for i in indices]), dtype=torch.float32)\n",
        "\n",
        "        return batch_data, batch_labels\n",
        "\n",
        "    def get_all_data(self):\n",
        "        \"\"\"모든 저장된 데이터 반환\"\"\"\n",
        "        if len(self.data_buffer) == 0:\n",
        "            return None, None\n",
        "\n",
        "        all_data = torch.tensor(np.array(self.data_buffer), dtype=torch.float32)\n",
        "        all_labels = torch.tensor(np.array(self.label_buffer), dtype=torch.float32)\n",
        "\n",
        "        return all_data, all_labels\n"
      ],
      "metadata": {
        "id": "4EcbcmGFJPAi"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "tCYkSHQEJUI_"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input(cls_id, conf, dist, area, cx, cy, num_classes=10):\n",
        "    x = np.zeros(num_classes + 5)\n",
        "    if 0 <= cls_id < num_classes:\n",
        "        x[cls_id] = 1.0\n",
        "    x[num_classes:] = [conf, dist / 100, area / 10000, cx / 1920, cy / 1080]\n",
        "    return torch.tensor(x, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "def add_noise(x, level=0.1):\n",
        "    return x + level * torch.randn_like(x)"
      ],
      "metadata": {
        "id": "H9z-jHX1JWA2"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = YOLO(\"yolov8n.pt\")  # YOLOv8\n",
        "input_dim = 10 + 5\n",
        "fm_model = FM_FTRL_WithClassifier(input_dim)\n",
        "optimizer = optim.Adam(fm_model.parameters(), lr=1e-3)\n",
        "\n",
        "# Rehearsal 메모리 초기화\n",
        "rehearsal_memory = RehearsalMemory(max_samples=900)\n",
        "\n",
        "fm_model.to(device)\n",
        "fm_model.train()\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "loss_buffer = []\n",
        "action_buffer = []\n",
        "measuring_loss = False\n",
        "video_file_count = 0"
      ],
      "metadata": {
        "id": "7d3gwDZXJYIc"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task1 학습"
      ],
      "metadata": {
        "id": "3DaEZhyjJlgN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## driving 11 학습 (라벨 포함)"
      ],
      "metadata": {
        "id": "-MhO4JMPMdix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driving11 = driving11['go_stop_decision']"
      ],
      "metadata": {
        "id": "vKBksFi9JbK_"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "video_path = next(iter(uploaded))\n",
        "\n",
        "#driving_11.mp4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "gCjUt9hXJfd7",
        "outputId": "be97de78-d30c-4050-898e-5166c4d0875e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ac56a8d-cb05-4a52-8abc-45c22c4331b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ac56a8d-cb05-4a52-8abc-45c22c4331b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving driving_11.mp4 to driving_11 (1).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "task_data = []\n",
        "task_labels = []\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_idx += 1\n",
        "\n",
        "    result = model(frame)[0]\n",
        "    h, w, _ = frame.shape\n",
        "    frame_actions = []\n",
        "\n",
        "    for box in result.boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        conf = float(box.conf[0])\n",
        "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "        area = (x2 - x1) * (y2 - y1)\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "        est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "        x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "        x_noisy = add_noise(x)\n",
        "\n",
        "        y_pred, emb_orig = fm_model(x)\n",
        "        _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "        # 첫 번째 태스크는 지도학습\n",
        "        label = torch.tensor([driving11[frame_idx-1]], dtype=torch.float32).to(device)\n",
        "        supervised_loss = loss_fn(y_pred, label)\n",
        "\n",
        "        # 노이즈에 대한 일관성 손실\n",
        "        consistency_loss = loss_fn(emb_noisy, emb_orig.detach())\n",
        "\n",
        "        total_loss = supervised_loss + 0.1 * consistency_loss\n",
        "\n",
        "        if measuring_loss:\n",
        "            loss_buffer.append(total_loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # 태스크 데이터를 메모리에 저장 (numpy 배열로 변환)\n",
        "        task_data.append(x.detach().cpu().numpy().squeeze(0))\n",
        "        task_labels.append(label.detach().cpu().numpy().squeeze(0))\n",
        "\n",
        "        act = int(y_pred.item() >= 0.5)\n",
        "        frame_actions.append(act)\n",
        "\n",
        "    final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "    if measuring_loss:\n",
        "        action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# 첫 번째 태스크 데이터를 rehearsal 메모리에 저장\n",
        "rehearsal_memory.add_samples(task_data, task_labels)\n",
        "\n",
        "print(\"First task completed. Data stored in rehearsal memory.\")\n",
        "print(\"Rehearsal Action Buffer:\", action_buffer)\n",
        "print(\"Loss Buffer:\", loss_buffer)\n",
        "print(f\"Total frames processed: {frame_idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl_23ba3Jmio",
        "outputId": "109588be-32e0-47bb-f0d0-e105573558a1"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 210.1ms\n",
            "Speed: 3.3ms preprocess, 210.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 205.6ms\n",
            "Speed: 3.2ms preprocess, 205.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 205.0ms\n",
            "Speed: 3.2ms preprocess, 205.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 175.9ms\n",
            "Speed: 3.1ms preprocess, 175.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.1ms\n",
            "Speed: 3.0ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.6ms\n",
            "Speed: 2.9ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 128.2ms\n",
            "Speed: 2.9ms preprocess, 128.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.3ms\n",
            "Speed: 2.8ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.6ms\n",
            "Speed: 2.9ms preprocess, 130.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 126.2ms\n",
            "Speed: 2.8ms preprocess, 126.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 146.2ms\n",
            "Speed: 3.1ms preprocess, 146.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 260.7ms\n",
            "Speed: 3.0ms preprocess, 260.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 231.4ms\n",
            "Speed: 3.5ms preprocess, 231.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 kite, 204.2ms\n",
            "Speed: 4.2ms preprocess, 204.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 339.3ms\n",
            "Speed: 5.7ms preprocess, 339.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 208.4ms\n",
            "Speed: 3.7ms preprocess, 208.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 304.5ms\n",
            "Speed: 3.2ms preprocess, 304.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 428.1ms\n",
            "Speed: 6.1ms preprocess, 428.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 305.9ms\n",
            "Speed: 10.5ms preprocess, 305.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 230.5ms\n",
            "Speed: 3.0ms preprocess, 230.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 262.7ms\n",
            "Speed: 4.2ms preprocess, 262.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 206.5ms\n",
            "Speed: 4.9ms preprocess, 206.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 241.0ms\n",
            "Speed: 8.5ms preprocess, 241.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 335.6ms\n",
            "Speed: 3.3ms preprocess, 335.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 291.7ms\n",
            "Speed: 4.1ms preprocess, 291.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 322.8ms\n",
            "Speed: 5.2ms preprocess, 322.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 311.5ms\n",
            "Speed: 3.0ms preprocess, 311.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 301.5ms\n",
            "Speed: 3.2ms preprocess, 301.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 385.9ms\n",
            "Speed: 3.2ms preprocess, 385.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 653.1ms\n",
            "Speed: 13.2ms preprocess, 653.1ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 342.9ms\n",
            "Speed: 3.3ms preprocess, 342.9ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 352.5ms\n",
            "Speed: 4.3ms preprocess, 352.5ms inference, 10.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 470.8ms\n",
            "Speed: 4.7ms preprocess, 470.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 598.2ms\n",
            "Speed: 8.9ms preprocess, 598.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 561.9ms\n",
            "Speed: 9.2ms preprocess, 561.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 455.4ms\n",
            "Speed: 3.2ms preprocess, 455.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 506.7ms\n",
            "Speed: 3.1ms preprocess, 506.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 488.9ms\n",
            "Speed: 6.7ms preprocess, 488.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 523.0ms\n",
            "Speed: 8.8ms preprocess, 523.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 427.7ms\n",
            "Speed: 6.4ms preprocess, 427.7ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 495.9ms\n",
            "Speed: 3.1ms preprocess, 495.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 638.3ms\n",
            "Speed: 3.1ms preprocess, 638.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 527.3ms\n",
            "Speed: 11.7ms preprocess, 527.3ms inference, 24.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 543.3ms\n",
            "Speed: 5.7ms preprocess, 543.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 266.3ms\n",
            "Speed: 8.7ms preprocess, 266.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.6ms\n",
            "Speed: 3.2ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.7ms\n",
            "Speed: 3.2ms preprocess, 132.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 cell phone, 129.7ms\n",
            "Speed: 3.0ms preprocess, 129.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.4ms\n",
            "Speed: 3.2ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 143.0ms\n",
            "Speed: 3.3ms preprocess, 143.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 124.5ms\n",
            "Speed: 3.2ms preprocess, 124.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 128.7ms\n",
            "Speed: 3.5ms preprocess, 128.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 123.8ms\n",
            "Speed: 3.1ms preprocess, 123.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 126.7ms\n",
            "Speed: 3.3ms preprocess, 126.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.0ms\n",
            "Speed: 3.1ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.7ms\n",
            "Speed: 3.2ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 145.1ms\n",
            "Speed: 3.1ms preprocess, 145.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 125.3ms\n",
            "Speed: 3.0ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 1 bed, 127.1ms\n",
            "Speed: 2.9ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 129.6ms\n",
            "Speed: 3.1ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 129.0ms\n",
            "Speed: 3.1ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 127.9ms\n",
            "Speed: 3.3ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 130.0ms\n",
            "Speed: 3.3ms preprocess, 130.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 144.2ms\n",
            "Speed: 3.2ms preprocess, 144.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 125.7ms\n",
            "Speed: 3.2ms preprocess, 125.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 131.2ms\n",
            "Speed: 3.5ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.7ms\n",
            "Speed: 3.1ms preprocess, 130.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.8ms\n",
            "Speed: 2.9ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 125.7ms\n",
            "Speed: 3.0ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 124.4ms\n",
            "Speed: 3.1ms preprocess, 124.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 145.2ms\n",
            "Speed: 3.3ms preprocess, 145.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.8ms\n",
            "Speed: 2.9ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.8ms\n",
            "Speed: 3.0ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 137.5ms\n",
            "Speed: 3.1ms preprocess, 137.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.9ms\n",
            "Speed: 2.8ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.9ms\n",
            "Speed: 2.9ms preprocess, 126.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 125.3ms\n",
            "Speed: 2.9ms preprocess, 125.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 133.9ms\n",
            "Speed: 2.9ms preprocess, 133.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 135.7ms\n",
            "Speed: 3.1ms preprocess, 135.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 129.3ms\n",
            "Speed: 2.9ms preprocess, 129.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.3ms\n",
            "Speed: 3.0ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.7ms\n",
            "Speed: 2.8ms preprocess, 129.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 138.0ms\n",
            "Speed: 3.1ms preprocess, 138.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 139.5ms\n",
            "Speed: 3.3ms preprocess, 139.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.8ms\n",
            "Speed: 3.2ms preprocess, 136.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 165.0ms\n",
            "Speed: 3.3ms preprocess, 165.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 142.0ms\n",
            "Speed: 3.3ms preprocess, 142.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 138.9ms\n",
            "Speed: 3.1ms preprocess, 138.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 142.5ms\n",
            "Speed: 3.0ms preprocess, 142.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 139.3ms\n",
            "Speed: 3.4ms preprocess, 139.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.3ms\n",
            "Speed: 3.3ms preprocess, 137.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 151.4ms\n",
            "Speed: 3.5ms preprocess, 151.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 154.1ms\n",
            "Speed: 4.9ms preprocess, 154.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 138.8ms\n",
            "Speed: 3.4ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 137.0ms\n",
            "Speed: 3.2ms preprocess, 137.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.6ms\n",
            "Speed: 3.1ms preprocess, 132.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 136.5ms\n",
            "Speed: 3.2ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 137.5ms\n",
            "Speed: 3.3ms preprocess, 137.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 155.0ms\n",
            "Speed: 3.2ms preprocess, 155.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 139.5ms\n",
            "Speed: 3.1ms preprocess, 139.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.4ms\n",
            "Speed: 3.2ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.7ms\n",
            "Speed: 3.3ms preprocess, 133.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 149.8ms\n",
            "Speed: 3.0ms preprocess, 149.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.7ms\n",
            "Speed: 3.5ms preprocess, 136.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 142.4ms\n",
            "Speed: 3.4ms preprocess, 142.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.9ms\n",
            "Speed: 2.7ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 139.7ms\n",
            "Speed: 3.0ms preprocess, 139.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 135.4ms\n",
            "Speed: 2.9ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 135.7ms\n",
            "Speed: 3.1ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.2ms\n",
            "Speed: 3.3ms preprocess, 134.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 187.4ms\n",
            "Speed: 3.1ms preprocess, 187.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 231.8ms\n",
            "Speed: 3.3ms preprocess, 231.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 209.3ms\n",
            "Speed: 4.3ms preprocess, 209.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 210.9ms\n",
            "Speed: 3.0ms preprocess, 210.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 204.2ms\n",
            "Speed: 3.1ms preprocess, 204.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 213.2ms\n",
            "Speed: 3.2ms preprocess, 213.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 243.8ms\n",
            "Speed: 3.4ms preprocess, 243.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 210.4ms\n",
            "Speed: 3.1ms preprocess, 210.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 204.9ms\n",
            "Speed: 3.2ms preprocess, 204.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 206.7ms\n",
            "Speed: 3.1ms preprocess, 206.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 225.0ms\n",
            "Speed: 3.1ms preprocess, 225.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 207.7ms\n",
            "Speed: 5.0ms preprocess, 207.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 202.2ms\n",
            "Speed: 3.3ms preprocess, 202.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 202.5ms\n",
            "Speed: 4.6ms preprocess, 202.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 215.2ms\n",
            "Speed: 2.7ms preprocess, 215.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 222.7ms\n",
            "Speed: 5.7ms preprocess, 222.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 212.6ms\n",
            "Speed: 3.6ms preprocess, 212.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 195.6ms\n",
            "Speed: 3.2ms preprocess, 195.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.9ms\n",
            "Speed: 3.3ms preprocess, 135.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.5ms\n",
            "Speed: 3.0ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.8ms\n",
            "Speed: 3.2ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 146.8ms\n",
            "Speed: 3.1ms preprocess, 146.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.1ms\n",
            "Speed: 3.1ms preprocess, 133.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.4ms\n",
            "Speed: 3.0ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.8ms\n",
            "Speed: 3.2ms preprocess, 132.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.1ms\n",
            "Speed: 3.1ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.7ms\n",
            "Speed: 3.0ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.3ms\n",
            "Speed: 3.0ms preprocess, 132.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 153.4ms\n",
            "Speed: 3.1ms preprocess, 153.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.9ms\n",
            "Speed: 3.2ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.6ms\n",
            "Speed: 3.6ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.8ms\n",
            "Speed: 3.4ms preprocess, 134.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 142.6ms\n",
            "Speed: 3.3ms preprocess, 142.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.5ms\n",
            "Speed: 3.4ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.3ms\n",
            "Speed: 3.5ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 148.5ms\n",
            "Speed: 5.0ms preprocess, 148.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.3ms\n",
            "Speed: 3.1ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.8ms\n",
            "Speed: 3.2ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.3ms\n",
            "Speed: 3.0ms preprocess, 137.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.6ms\n",
            "Speed: 3.5ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 142.8ms\n",
            "Speed: 2.8ms preprocess, 142.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 155.3ms\n",
            "Speed: 3.1ms preprocess, 155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.8ms\n",
            "Speed: 3.2ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.4ms\n",
            "Speed: 3.4ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.5ms\n",
            "Speed: 3.6ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.4ms\n",
            "Speed: 3.2ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.5ms\n",
            "Speed: 3.2ms preprocess, 131.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.6ms\n",
            "Speed: 3.4ms preprocess, 127.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 149.2ms\n",
            "Speed: 3.8ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.2ms\n",
            "Speed: 3.4ms preprocess, 128.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.1ms\n",
            "Speed: 3.5ms preprocess, 131.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.5ms\n",
            "Speed: 3.3ms preprocess, 133.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.7ms\n",
            "Speed: 3.2ms preprocess, 134.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.1ms\n",
            "Speed: 3.2ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 126.5ms\n",
            "Speed: 3.0ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 145.1ms\n",
            "Speed: 3.1ms preprocess, 145.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.2ms\n",
            "Speed: 4.2ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.6ms\n",
            "Speed: 3.5ms preprocess, 127.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.4ms\n",
            "Speed: 2.7ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.7ms\n",
            "Speed: 3.3ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.5ms\n",
            "Speed: 3.1ms preprocess, 128.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.3ms\n",
            "Speed: 3.2ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 148.2ms\n",
            "Speed: 2.9ms preprocess, 148.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.2ms\n",
            "Speed: 2.6ms preprocess, 129.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.0ms\n",
            "Speed: 3.4ms preprocess, 134.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.1ms\n",
            "Speed: 3.4ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.7ms\n",
            "Speed: 3.1ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.4ms\n",
            "Speed: 3.4ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.3ms\n",
            "Speed: 3.3ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 147.6ms\n",
            "Speed: 3.2ms preprocess, 147.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.8ms\n",
            "Speed: 3.0ms preprocess, 134.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.0ms\n",
            "Speed: 3.0ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 140.7ms\n",
            "Speed: 3.0ms preprocess, 140.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.4ms\n",
            "Speed: 3.1ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.4ms\n",
            "Speed: 2.9ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.9ms\n",
            "Speed: 3.7ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 147.6ms\n",
            "Speed: 3.3ms preprocess, 147.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.1ms\n",
            "Speed: 3.0ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 128.9ms\n",
            "Speed: 3.4ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.9ms\n",
            "Speed: 3.2ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.9ms\n",
            "Speed: 2.9ms preprocess, 131.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.8ms\n",
            "Speed: 3.5ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.8ms\n",
            "Speed: 3.7ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 150.9ms\n",
            "Speed: 3.4ms preprocess, 150.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 207.3ms\n",
            "Speed: 3.6ms preprocess, 207.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 199.7ms\n",
            "Speed: 3.0ms preprocess, 199.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 199.8ms\n",
            "Speed: 3.3ms preprocess, 199.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 195.1ms\n",
            "Speed: 7.5ms preprocess, 195.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 222.4ms\n",
            "Speed: 3.2ms preprocess, 222.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 206.1ms\n",
            "Speed: 3.6ms preprocess, 206.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 211.4ms\n",
            "Speed: 3.2ms preprocess, 211.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 205.5ms\n",
            "Speed: 6.0ms preprocess, 205.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 222.6ms\n",
            "Speed: 6.2ms preprocess, 222.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 205.8ms\n",
            "Speed: 6.9ms preprocess, 205.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 202.3ms\n",
            "Speed: 3.2ms preprocess, 202.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 198.4ms\n",
            "Speed: 3.2ms preprocess, 198.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 193.9ms\n",
            "Speed: 3.1ms preprocess, 193.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 219.9ms\n",
            "Speed: 3.2ms preprocess, 219.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 214.1ms\n",
            "Speed: 3.2ms preprocess, 214.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 208.0ms\n",
            "Speed: 3.1ms preprocess, 208.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 206.5ms\n",
            "Speed: 3.1ms preprocess, 206.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 156.7ms\n",
            "Speed: 3.2ms preprocess, 156.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 143.7ms\n",
            "Speed: 3.2ms preprocess, 143.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.2ms\n",
            "Speed: 3.1ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.0ms\n",
            "Speed: 3.2ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 130.5ms\n",
            "Speed: 3.0ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.6ms\n",
            "Speed: 3.4ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 132.8ms\n",
            "Speed: 3.2ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 132.6ms\n",
            "Speed: 3.1ms preprocess, 132.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 152.9ms\n",
            "Speed: 3.2ms preprocess, 152.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.1ms\n",
            "Speed: 3.1ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.3ms\n",
            "Speed: 3.1ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.5ms\n",
            "Speed: 3.5ms preprocess, 133.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.5ms\n",
            "Speed: 3.2ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.7ms\n",
            "Speed: 3.4ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.6ms\n",
            "Speed: 3.2ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 152.6ms\n",
            "Speed: 3.2ms preprocess, 152.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.5ms\n",
            "Speed: 3.0ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.7ms\n",
            "Speed: 3.2ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.2ms\n",
            "Speed: 3.3ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.7ms\n",
            "Speed: 3.3ms preprocess, 131.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.0ms\n",
            "Speed: 3.2ms preprocess, 131.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 133.7ms\n",
            "Speed: 3.2ms preprocess, 133.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 150.2ms\n",
            "Speed: 3.3ms preprocess, 150.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.3ms\n",
            "Speed: 6.6ms preprocess, 131.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.6ms\n",
            "Speed: 3.1ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 128.7ms\n",
            "Speed: 3.0ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.8ms\n",
            "Speed: 6.7ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.1ms\n",
            "Speed: 3.2ms preprocess, 133.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.7ms\n",
            "Speed: 3.2ms preprocess, 136.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 148.6ms\n",
            "Speed: 3.0ms preprocess, 148.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.1ms\n",
            "Speed: 3.1ms preprocess, 133.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.4ms\n",
            "Speed: 3.7ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.8ms\n",
            "Speed: 3.7ms preprocess, 134.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.8ms\n",
            "Speed: 3.6ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.7ms\n",
            "Speed: 3.4ms preprocess, 136.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 140.7ms\n",
            "Speed: 4.0ms preprocess, 140.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 152.0ms\n",
            "Speed: 3.0ms preprocess, 152.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.8ms\n",
            "Speed: 3.5ms preprocess, 141.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.1ms\n",
            "Speed: 3.2ms preprocess, 135.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 truck, 134.8ms\n",
            "Speed: 3.4ms preprocess, 134.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 truck, 136.4ms\n",
            "Speed: 3.2ms preprocess, 136.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 138.0ms\n",
            "Speed: 3.3ms preprocess, 138.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 147.1ms\n",
            "Speed: 3.2ms preprocess, 147.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.7ms\n",
            "Speed: 4.1ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 140.1ms\n",
            "Speed: 3.1ms preprocess, 140.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.4ms\n",
            "Speed: 3.1ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.9ms\n",
            "Speed: 3.2ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.0ms\n",
            "Speed: 3.3ms preprocess, 134.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 138.8ms\n",
            "Speed: 3.2ms preprocess, 138.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 147.4ms\n",
            "Speed: 3.7ms preprocess, 147.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.3ms\n",
            "Speed: 4.2ms preprocess, 137.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.0ms\n",
            "Speed: 3.7ms preprocess, 133.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.5ms\n",
            "Speed: 6.6ms preprocess, 133.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.4ms\n",
            "Speed: 3.2ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 143.9ms\n",
            "Speed: 3.1ms preprocess, 143.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.7ms\n",
            "Speed: 3.3ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 148.4ms\n",
            "Speed: 3.1ms preprocess, 148.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.0ms\n",
            "Speed: 4.2ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.4ms\n",
            "Speed: 3.1ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.4ms\n",
            "Speed: 3.2ms preprocess, 132.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.1ms\n",
            "Speed: 3.0ms preprocess, 134.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.1ms\n",
            "Speed: 3.0ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.2ms\n",
            "Speed: 3.1ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 156.9ms\n",
            "Speed: 3.2ms preprocess, 156.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.1ms\n",
            "Speed: 3.4ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 160.3ms\n",
            "Speed: 3.4ms preprocess, 160.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 197.7ms\n",
            "Speed: 4.2ms preprocess, 197.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 201.2ms\n",
            "Speed: 3.8ms preprocess, 201.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 226.3ms\n",
            "Speed: 3.1ms preprocess, 226.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 192.4ms\n",
            "Speed: 3.1ms preprocess, 192.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 188.0ms\n",
            "Speed: 3.1ms preprocess, 188.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 206.8ms\n",
            "Speed: 3.0ms preprocess, 206.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 198.5ms\n",
            "Speed: 5.9ms preprocess, 198.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 truck, 198.9ms\n",
            "Speed: 3.2ms preprocess, 198.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 192.6ms\n",
            "Speed: 3.0ms preprocess, 192.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 195.3ms\n",
            "Speed: 3.1ms preprocess, 195.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 199.9ms\n",
            "Speed: 3.1ms preprocess, 199.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 198.9ms\n",
            "Speed: 2.8ms preprocess, 198.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 232.3ms\n",
            "Speed: 3.0ms preprocess, 232.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 193.5ms\n",
            "Speed: 3.2ms preprocess, 193.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 220.5ms\n",
            "Speed: 3.3ms preprocess, 220.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 206.5ms\n",
            "Speed: 4.1ms preprocess, 206.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 200.7ms\n",
            "Speed: 7.3ms preprocess, 200.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 210.0ms\n",
            "Speed: 8.3ms preprocess, 210.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.5ms\n",
            "Speed: 3.2ms preprocess, 132.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.4ms\n",
            "Speed: 3.3ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.8ms\n",
            "Speed: 3.9ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.6ms\n",
            "Speed: 3.3ms preprocess, 135.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.2ms\n",
            "Speed: 3.2ms preprocess, 133.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.5ms\n",
            "Speed: 3.0ms preprocess, 136.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 139.5ms\n",
            "Speed: 5.5ms preprocess, 139.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 139.3ms\n",
            "Speed: 3.0ms preprocess, 139.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.8ms\n",
            "Speed: 3.2ms preprocess, 135.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.2ms\n",
            "Speed: 3.2ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.9ms\n",
            "Speed: 3.7ms preprocess, 135.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 137.0ms\n",
            "Speed: 3.2ms preprocess, 137.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 153.4ms\n",
            "Speed: 3.4ms preprocess, 153.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.0ms\n",
            "Speed: 3.1ms preprocess, 136.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.9ms\n",
            "Speed: 3.0ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.2ms\n",
            "Speed: 3.6ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.3ms\n",
            "Speed: 3.8ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 128.8ms\n",
            "Speed: 3.1ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.9ms\n",
            "Speed: 3.8ms preprocess, 132.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 150.4ms\n",
            "Speed: 3.6ms preprocess, 150.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.4ms\n",
            "Speed: 3.5ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.5ms\n",
            "Speed: 3.2ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 126.2ms\n",
            "Speed: 3.7ms preprocess, 126.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 128.9ms\n",
            "Speed: 3.4ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.1ms\n",
            "Speed: 3.1ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 127.0ms\n",
            "Speed: 3.4ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 146.3ms\n",
            "Speed: 3.3ms preprocess, 146.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.6ms\n",
            "Speed: 6.5ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 126.8ms\n",
            "Speed: 5.2ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.7ms\n",
            "Speed: 3.3ms preprocess, 130.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 126.4ms\n",
            "Speed: 3.3ms preprocess, 126.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 127.8ms\n",
            "Speed: 3.4ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "First task completed. Data stored in rehearsal memory.\n",
            "Rehearsal Action Buffer: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss Buffer: [0.21263432502746582, 0.25857076048851013, 0.3389688730239868, 0.24148285388946533, 0.18101570010185242, 0.17303767800331116, 0.21629910171031952, 0.327926903963089, 0.15108650922775269, 0.19588398933410645, 0.3217637836933136, 0.13185395300388336, 0.17466239631175995, 0.12004157900810242, 0.1605074107646942, 0.1496599018573761, 0.10582607984542847, 0.31011316180229187, 0.13200484216213226, 0.08914873003959656, 0.07929714024066925, 0.11793123185634613, 0.11131016910076141, 0.06602030247449875, 0.2961684763431549, 0.10017939656972885, 0.05605718865990639, 0.2888360917568207, 0.08985063433647156, 0.04968687519431114, 0.28346335887908936, 0.08256057649850845, 0.04435082897543907, 0.2786356806755066, 0.5282779335975647, 0.6243489980697632, 0.45248645544052124, 0.2246241420507431, 0.5407928228378296, 0.6071640849113464, 0.2240561693906784, 0.525640606880188, 0.5817229151725769, 0.22071881592273712, 0.5127175450325012, 0.5309697985649109, 0.5035403966903687, 0.47907567024230957, 0.21463197469711304, 0.4877597987651825, 0.4295162856578827, 0.21197138726711273, 0.46309390664100647, 0.3902970254421234, 0.20637038350105286, 0.43848568201065063, 0.3549475073814392, 0.20304694771766663, 0.3248615264892578, 0.40189290046691895, 0.19866417348384857, 0.3838198781013489, 0.28934571146965027, 0.191949725151062, 0.2728714048862457, 0.3500130772590637, 0.18717913329601288, 0.2551894187927246, 0.3236665427684784, 0.24020400643348694, 0.30596035718917847, 0.2969124913215637, 0.2235306054353714, 0.2813332676887512, 0.21448826789855957, 0.2667844295501709, 0.20458370447158813, 0.2501380741596222, 0.19601933658123016, 0.23381629586219788, 0.18824562430381775, 0.21810051798820496, 0.18069525063037872, 0.2033621221780777, 0.17484621703624725, 0.18997807800769806, 0.16823790967464447, 0.17856153845787048, 0.16292642056941986, 0.16816624999046326, 0.15835003554821014, 0.15875695645809174, 0.1533978134393692, 0.15007047355175018, 0.14913393557071686, 0.3803260624408722, 0.39290180802345276, 0.1375759243965149, 0.1436200886964798, 0.13397051393985748, 0.14184710383415222, 0.1300356090068817, 0.13860797882080078, 0.13828809559345245, 0.12435772269964218, 0.13575366139411926, 0.1218138188123703, 0.1329548954963684, 0.11813785135746002, 0.1296181082725525, 0.11466033011674881, 0.1264861524105072, 0.11303630471229553, 0.11311408132314682, 0.12928465008735657, 0.1197737604379654, 0.11956228315830231, 0.1086202934384346, 0.11710980534553528, 0.10802481323480606, 0.1236671656370163, 0.12265624105930328, 0.11309942603111267, 0.11300565302371979, 0.11204167455434799, 0.11794809997081757, 0.10965733230113983, 0.10980161279439926, 0.11545498669147491, 0.11582670360803604, 0.11362101137638092, 0.1056218072772026, 0.1121121197938919, 0.11423957347869873, 0.10288633406162262, 0.11034805327653885, 0.11375993490219116, 0.10022664070129395, 0.10807424038648605, 0.09842859208583832, 0.10689550638198853, 0.11354035139083862, 0.09607022255659103, 0.10476168990135193, 0.0942973792552948, 0.10372903198003769, 0.09221991151571274, 0.10357578098773956, 0.09060703217983246, 0.08909044414758682, 0.08784205466508865, 0.09705337136983871, 0.09520046412944794, 0.08507855981588364, 0.08403560519218445, 0.09172356873750687, 0.08309949189424515, 0.08068136125802994, 0.08452340960502625, 0.07707889378070831, 0.07531324774026871, 0.07415373623371124, 0.06165207922458649, 0.5704616904258728, 0.06696801632642746, 0.06453963369131088, 0.06255749613046646, 0.06139019876718521, 0.06061330810189247, 0.06754345446825027, 0.06629858911037445, 0.05493536219000816, 0.053147539496421814, 0.06170259416103363, 0.05066141486167908, 0.05909543111920357, 0.04863835871219635, 0.046531349420547485, 0.04497896134853363, 0.06649253517389297, 0.04254910349845886, 0.04965412616729736, 0.03984031826257706, 0.08217434585094452, 0.03771507740020752, 0.08513904362916946, 0.03551868349313736, 0.08658719807863235, 0.04427154362201691, 0.08727657794952393, 0.03203766047954559, 0.030387263745069504, 0.029246091842651367, 0.02825031243264675, 0.02709348313510418, 0.02646121382713318, 0.026475870981812477, 0.026547959074378014, 0.06739199161529541, 0.026025135070085526, 0.06532490998506546, 0.02565206028521061, 0.02571115829050541, 0.0627390444278717, 0.02414243295788765, 0.030895618721842766, 0.03004639223217964, 0.030375640839338303, 0.03089260123670101, 0.023949652910232544, 0.030075211077928543, 0.023379778489470482, 0.022855395451188087, 0.021654509007930756, 0.021268831565976143, 0.01990215852856636, 0.019134795293211937, 0.0183523241430521, 0.017134854570031166, 0.016421977430582047, 0.015244731679558754, 0.01448195893317461, 0.013987403362989426, 0.013385282829403877, 0.012636343948543072, 0.011435162276029587, 0.010896285995841026, 0.012606993317604065, 0.009997877292335033, 0.009502746164798737, 0.008673567324876785, 0.00830660667270422, 0.00757718225941062, 0.006963944528251886, 0.007946529425680637, 0.0062958174385130405, 0.007263263687491417, 0.006392709445208311, 0.0060665784403681755, 0.005266112741082907, 0.0047412752173841, 0.8725939989089966, 0.8837761282920837, 0.8857192993164062, 0.8879403471946716, 0.889151930809021, 0.894506573677063, 0.8925232291221619, 0.8922939300537109, 0.8926197290420532, 0.8874508142471313, 0.8835626840591431, 0.8814855813980103, 0.8757755160331726, 0.8757005929946899, 0.8665307760238647, 0.8551257252693176, 0.8454599380493164, 0.8347617387771606, 0.8219482898712158, 0.8068317770957947, 0.7907668948173523, 0.7717898488044739, 0.7506366968154907, 0.7282410860061646, 0.7037431001663208, 0.6769790649414062, 0.6473711729049683, 0.6156364679336548, 0.5810166597366333, 0.5438334941864014, 0.505216121673584, 0.4641435444355011, 0.4224313497543335, 0.38036319613456726, 0.33912575244903564, 0.2981168329715729, 0.25914058089256287, 0.2239052653312683, 0.26827511191368103, 0.16200250387191772, 0.13822795450687408, 0.11585456877946854, 0.09838703274726868, 0.0822964608669281, 0.0686635971069336, 0.05810470134019852, 0.04970395565032959, 0.04251781851053238, 0.06733623892068863, 0.030451511964201927, 0.04991564899682999, 0.02294079214334488, 0.03875613957643509, 0.01760311983525753, 0.031265102326869965, 0.013618161901831627, 0.026378871873021126, 0.01153454277664423, 0.022140467539429665, 0.009151442907750607, 0.018772920593619347, 0.007919611409306526, 0.01603025197982788, 0.006427675485610962, 0.00492611899971962, 0.011203156784176826, 0.00898811500519514, 0.004133753944188356, 0.0049295127391815186, 0.009955145418643951, 0.014524949714541435, 0.006653268355876207, 0.019949711859226227, 0.014257258735597134, 0.017940636724233627, 0.03719994053244591, 0.6153067946434021, 0.5639525651931763, 0.5137622356414795, 0.47006282210350037, 0.4296417236328125, 0.5529211163520813, 0.38504043221473694, 0.34566086530685425, 0.32827243208885193, 0.3113107979297638, 0.2962275445461273, 0.2851378321647644, 0.2717738747596741, 0.1571742296218872, 0.25263917446136475, 0.24185915291309357, 0.14908280968666077, 0.22661463916301727, 0.1440013200044632, 0.20822358131408691, 0.13950222730636597, 0.19782137870788574, 0.19225680828094482, 0.18720291554927826, 0.1800668090581894, 0.17611846327781677, 0.17398297786712646, 0.17154556512832642, 0.16880744695663452, 0.16630437970161438, 0.16422878205776215, 0.16162990033626556, 0.159407839179039, 0.16023613512516022, 0.19426938891410828, 0.1541980504989624, 0.18988190591335297, 0.1495572328567505, 0.14711792767047882, 0.1448511928319931, 0.38263094425201416, 0.13968676328659058, 0.13711993396282196, 0.13557587563991547, 0.1334105134010315, 0.13245905935764313, 0.1311711072921753, 0.13087725639343262, 0.13101975619792938, 0.23807398974895477, 0.12570077180862427, 0.2332979440689087, 0.1209041029214859, 0.22422710061073303, 0.21915051341056824, 0.21645595133304596, 0.218618705868721, 0.14521969854831696, 0.21264703571796417, 0.10865865647792816, 0.13524377346038818, 0.1324838250875473, 0.10012808442115784, 0.1859426647424698, 0.0966501384973526, 0.09273813664913177, 0.09257148206233978, 0.17843341827392578, 0.08809170126914978, 0.08657700568437576, 0.16834840178489685, 0.08361701667308807, 0.1571682095527649, 0.07703348249197006, 0.07500843703746796, 0.1470731645822525, 0.0676218569278717, 0.06561630964279175, 0.12972700595855713, 0.12738515436649323, 0.06040961667895317, 0.11735252290964127, 0.05473588407039642, 0.10695195198059082, 0.048304036259651184, 0.10087659955024719, 0.04425884410738945, 0.49513790011405945, 0.6408843398094177, 0.5050345063209534, 0.6412843465805054, 0.5110008120536804, 0.6362613439559937, 0.49208322167396545, 0.6322436928749084, 0.6178907155990601, 0.45595207810401917, 0.4421848654747009, 0.5625085234642029, 0.39282840490341187, 0.5127180218696594, 0.3307693600654602, 0.4465197026729584, 0.2775351107120514, 0.35994186997413635, 0.18566085398197174, 0.15418197214603424, 0.2507210075855255, 0.1989697813987732, 0.08183512836694717, 0.12806767225265503, 0.08021669089794159, 0.035191815346479416, 0.023074351251125336, 0.018517853692173958, 0.03802109882235527, 0.03155244141817093, 0.009486515074968338, 0.021362828090786934, 0.007203019689768553, 0.0136100510135293, 0.004335638601332903, 0.00998509582132101, 0.0034332526847720146, 0.007815038785338402, 0.0034297583624720573, 0.0059684221632778645, 0.0019561592489480972, 0.004947832319885492, 0.0015204483643174171, 0.0041352822445333, 0.001340672723017633, 0.003974607214331627, 0.001702778972685337, 0.003805719083175063, 0.0011890631867572665, 0.003753846511244774, 0.0012631481513381004, 0.0031215378548949957, 0.0010412184055894613, 0.0028135336469858885, 0.0012426862958818674, 0.0035149119794368744, 0.0020991098135709763, 0.0031435564160346985, 0.0028347678016871214, 0.0014076782390475273, 0.0025342244189232588, 0.0026679043658077717, 0.0010597024811431766, 0.002441014861688018, 0.0018673159647732973, 0.002687574364244938, 0.0008755985181778669, 0.0024427827447652817, 0.0009707739809527993, 0.002541830064728856, 0.0008521932177245617, 0.002254252089187503, 0.0010070926509797573, 0.00095107447123155, 0.00235337414778769, 0.0009529558010399342, 0.002446497557684779, 0.002618433441966772, 0.0008769360720179975, 0.0022557415068149567, 0.0007617274532094598, 0.002362098777666688, 0.0009295072522945702, 0.0022053259890526533, 0.0010685035958886147, 0.002095886506140232, 0.0020893013570457697, 0.000878767401445657, 0.002118564210832119, 0.0013967951526865363, 0.0021825777366757393, 0.0008883225964382291, 0.0022871308028697968, 0.0007126852869987488, 0.002281023422256112, 0.0007434422732330859, 0.001938311499543488, 0.0007732420926913619, 0.0020199003629386425, 0.0010793134570121765, 0.0017611890798434615, 0.0010249648476019502, 0.000926762935705483, 0.0017114535439759493]\n",
            "Total frames processed: 327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#첫 번째 태스크 손실 시각화\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 이동평균 함수\n",
        "def moving_average(data, window_size):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "# 원본 데이터\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_buffer, color='lightblue', alpha=0.5, label='Raw Loss')\n",
        "\n",
        "# 이동평균 데이터\n",
        "smoothed_loss = moving_average(loss_buffer, 10)\n",
        "plt.plot(range(10-1, len(loss_buffer)), smoothed_loss, color='red', label='Smoothed (window=10)')\n",
        "\n",
        "plt.title(\"Rehearsal Learning Loss over frames (Smoothed)\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "vj3JwtHcJtSl",
        "outputId": "40f15e8d-5348-45d7-ecf0-22968d3a8cc5"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#첫 번째 태스크 액션 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loss 변화 시각화\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(action_buffer, marker='o', markersize=3, linewidth=1)\n",
        "plt.title(\"actions over frames\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"actions\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "bdg3kSezJwJo",
        "outputId": "0f83f07b-321f-420a-d774-4ff35e98bdeb"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## driving 13 학습 (라벨 미포함)"
      ],
      "metadata": {
        "id": "tAReZEM1MjND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#두 번째 태스크 학습 (라벨 없이, rehearsal 사용)\n",
        "#두 번째 비디오 업로드\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "video_path = next(iter(uploaded))\n",
        "\n",
        "#driving_13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4FcpxbiDJ2IM",
        "outputId": "ce0c046c-d1c5-40ca-860e-56eb2cf04edc"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8e3e9ac0-aa1d-4d85-80e0-c336161c179a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8e3e9ac0-aa1d-4d85-80e0-c336161c179a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving driving_13.mp4 to driving_13 (1).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 두 번째 태스크 학습 (rehearsal 방식) =====\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "new_task_data = []\n",
        "new_task_labels = []\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_idx += 1\n",
        "    step += 1\n",
        "\n",
        "    result = model(frame)[0]\n",
        "    h, w, _ = frame.shape\n",
        "    frame_actions = []\n",
        "\n",
        "    for box in result.boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        conf = float(box.conf[0])\n",
        "        if conf <= 0.6:\n",
        "            continue\n",
        "        else:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 노이즈에 대한 일관성 손실\n",
        "            consistency_loss = loss_fn(emb_noisy, emb_orig.detach())\n",
        "\n",
        "            # Rehearsal 손실: 이전 태스크 데이터와 함께 학습\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                # 이전 태스크 데이터에 대한 예측\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            # 총 손실 = 일관성 손실 + rehearsal 손실\n",
        "            total_loss = consistency_loss + 0.5 * rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                loss_buffer.append(total_loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 새로운 태스크 데이터 저장 (numpy 배열로 변환)\n",
        "            new_task_data.append(x.detach().cpu().numpy().squeeze(0))\n",
        "            # 라벨이 없으므로 예측값을 pseudo-label로 사용\n",
        "            new_task_labels.append(y_pred.detach().cpu().numpy().squeeze(0))\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "    final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "    if measuring_loss:\n",
        "        action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# 새로운 태스크 데이터를 rehearsal 메모리에 추가\n",
        "rehearsal_memory.add_samples(new_task_data, new_task_labels)\n",
        "\n",
        "print(\"Second task completed with rehearsal learning.\")\n",
        "print(\"Rehearsal Action Buffer:\", action_buffer)\n",
        "print(\"Loss Buffer:\", loss_buffer)\n",
        "print(f\"Rehearsal memory size: {len(rehearsal_memory.data_buffer)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gseC6x0MJ9gz",
        "outputId": "18947097-ae6a-46c0-8589-3e5f48b4ab94"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 car, 1 truck, 135.0ms\n",
            "Speed: 3.3ms preprocess, 135.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 473.9ms\n",
            "Speed: 3.0ms preprocess, 473.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 130.1ms\n",
            "Speed: 2.8ms preprocess, 130.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 127.6ms\n",
            "Speed: 3.9ms preprocess, 127.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 136.8ms\n",
            "Speed: 3.9ms preprocess, 136.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.2ms\n",
            "Speed: 3.0ms preprocess, 133.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 132.2ms\n",
            "Speed: 3.0ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.7ms\n",
            "Speed: 3.0ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.6ms\n",
            "Speed: 3.0ms preprocess, 136.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.6ms\n",
            "Speed: 2.9ms preprocess, 135.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 150.4ms\n",
            "Speed: 3.2ms preprocess, 150.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.5ms\n",
            "Speed: 3.1ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.7ms\n",
            "Speed: 3.1ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.3ms\n",
            "Speed: 3.1ms preprocess, 131.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 132.7ms\n",
            "Speed: 3.1ms preprocess, 132.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 139.2ms\n",
            "Speed: 3.0ms preprocess, 139.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 128.0ms\n",
            "Speed: 3.1ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 149.1ms\n",
            "Speed: 3.1ms preprocess, 149.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 134.2ms\n",
            "Speed: 3.1ms preprocess, 134.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.4ms\n",
            "Speed: 3.1ms preprocess, 132.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.9ms\n",
            "Speed: 3.2ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 133.6ms\n",
            "Speed: 3.2ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.7ms\n",
            "Speed: 3.4ms preprocess, 136.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.9ms\n",
            "Speed: 3.1ms preprocess, 130.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 147.1ms\n",
            "Speed: 3.0ms preprocess, 147.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.0ms\n",
            "Speed: 2.9ms preprocess, 130.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.9ms\n",
            "Speed: 3.2ms preprocess, 133.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 163.8ms\n",
            "Speed: 3.3ms preprocess, 163.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.5ms\n",
            "Speed: 2.9ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.1ms\n",
            "Speed: 3.2ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 142.8ms\n",
            "Speed: 3.0ms preprocess, 142.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 217.7ms\n",
            "Speed: 3.1ms preprocess, 217.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 193.9ms\n",
            "Speed: 3.1ms preprocess, 193.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 205.2ms\n",
            "Speed: 3.1ms preprocess, 205.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 193.8ms\n",
            "Speed: 3.4ms preprocess, 193.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 194.8ms\n",
            "Speed: 3.1ms preprocess, 194.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 207.1ms\n",
            "Speed: 7.0ms preprocess, 207.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 202.9ms\n",
            "Speed: 3.0ms preprocess, 202.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 200.0ms\n",
            "Speed: 3.0ms preprocess, 200.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 193.8ms\n",
            "Speed: 3.0ms preprocess, 193.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 197.5ms\n",
            "Speed: 4.5ms preprocess, 197.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 213.1ms\n",
            "Speed: 4.1ms preprocess, 213.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 209.6ms\n",
            "Speed: 8.2ms preprocess, 209.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 191.1ms\n",
            "Speed: 3.1ms preprocess, 191.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 196.5ms\n",
            "Speed: 3.0ms preprocess, 196.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 207.5ms\n",
            "Speed: 2.9ms preprocess, 207.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 218.9ms\n",
            "Speed: 4.6ms preprocess, 218.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 214.7ms\n",
            "Speed: 3.1ms preprocess, 214.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 166.8ms\n",
            "Speed: 3.1ms preprocess, 166.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 127.7ms\n",
            "Speed: 3.0ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 129.1ms\n",
            "Speed: 3.2ms preprocess, 129.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 139.3ms\n",
            "Speed: 3.2ms preprocess, 139.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 140.2ms\n",
            "Speed: 3.0ms preprocess, 140.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 132.7ms\n",
            "Speed: 3.0ms preprocess, 132.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 129.8ms\n",
            "Speed: 3.2ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 125.6ms\n",
            "Speed: 3.1ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.6ms\n",
            "Speed: 3.0ms preprocess, 127.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 130.0ms\n",
            "Speed: 3.1ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 cell phone, 139.1ms\n",
            "Speed: 3.1ms preprocess, 139.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 146.8ms\n",
            "Speed: 3.2ms preprocess, 146.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.5ms\n",
            "Speed: 3.1ms preprocess, 131.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.7ms\n",
            "Speed: 4.8ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.9ms\n",
            "Speed: 3.3ms preprocess, 130.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.0ms\n",
            "Speed: 3.0ms preprocess, 131.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.5ms\n",
            "Speed: 3.2ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 131.9ms\n",
            "Speed: 2.9ms preprocess, 131.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 156.1ms\n",
            "Speed: 2.9ms preprocess, 156.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 138.6ms\n",
            "Speed: 3.6ms preprocess, 138.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.2ms\n",
            "Speed: 2.9ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.3ms\n",
            "Speed: 3.2ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.4ms\n",
            "Speed: 2.9ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.5ms\n",
            "Speed: 3.4ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.2ms\n",
            "Speed: 3.2ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 149.9ms\n",
            "Speed: 3.3ms preprocess, 149.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.7ms\n",
            "Speed: 4.5ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.1ms\n",
            "Speed: 3.2ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.6ms\n",
            "Speed: 2.6ms preprocess, 128.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.9ms\n",
            "Speed: 3.1ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.1ms\n",
            "Speed: 3.2ms preprocess, 132.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.9ms\n",
            "Speed: 3.1ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 150.0ms\n",
            "Speed: 3.2ms preprocess, 150.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.2ms\n",
            "Speed: 3.1ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.6ms\n",
            "Speed: 3.3ms preprocess, 132.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.9ms\n",
            "Speed: 3.4ms preprocess, 132.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.2ms\n",
            "Speed: 3.2ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.5ms\n",
            "Speed: 3.3ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.6ms\n",
            "Speed: 3.4ms preprocess, 131.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 148.1ms\n",
            "Speed: 3.5ms preprocess, 148.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 128.2ms\n",
            "Speed: 3.2ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.0ms\n",
            "Speed: 3.5ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.0ms\n",
            "Speed: 3.2ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.2ms\n",
            "Speed: 2.9ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.3ms\n",
            "Speed: 3.2ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.9ms\n",
            "Speed: 3.1ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 153.9ms\n",
            "Speed: 3.2ms preprocess, 153.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.5ms\n",
            "Speed: 3.1ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.8ms\n",
            "Speed: 2.8ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.0ms\n",
            "Speed: 3.7ms preprocess, 132.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.1ms\n",
            "Speed: 3.6ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.1ms\n",
            "Speed: 3.7ms preprocess, 133.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.8ms\n",
            "Speed: 3.1ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 156.2ms\n",
            "Speed: 3.5ms preprocess, 156.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.2ms\n",
            "Speed: 3.2ms preprocess, 137.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.1ms\n",
            "Speed: 3.4ms preprocess, 138.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.9ms\n",
            "Speed: 3.5ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 139.5ms\n",
            "Speed: 3.5ms preprocess, 139.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.3ms\n",
            "Speed: 3.2ms preprocess, 135.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.4ms\n",
            "Speed: 3.3ms preprocess, 137.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 149.2ms\n",
            "Speed: 3.2ms preprocess, 149.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.0ms\n",
            "Speed: 3.4ms preprocess, 134.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.3ms\n",
            "Speed: 4.0ms preprocess, 136.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.0ms\n",
            "Speed: 3.1ms preprocess, 137.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.9ms\n",
            "Speed: 3.4ms preprocess, 131.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.2ms\n",
            "Speed: 3.8ms preprocess, 137.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.5ms\n",
            "Speed: 3.5ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 149.6ms\n",
            "Speed: 3.2ms preprocess, 149.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 189.2ms\n",
            "Speed: 3.1ms preprocess, 189.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 204.1ms\n",
            "Speed: 3.2ms preprocess, 204.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 209.7ms\n",
            "Speed: 3.1ms preprocess, 209.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 200.9ms\n",
            "Speed: 3.1ms preprocess, 200.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 205.2ms\n",
            "Speed: 4.9ms preprocess, 205.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 202.4ms\n",
            "Speed: 3.1ms preprocess, 202.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 201.2ms\n",
            "Speed: 3.3ms preprocess, 201.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 201.8ms\n",
            "Speed: 3.0ms preprocess, 201.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 210.6ms\n",
            "Speed: 3.0ms preprocess, 210.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 213.0ms\n",
            "Speed: 3.0ms preprocess, 213.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 207.2ms\n",
            "Speed: 3.1ms preprocess, 207.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 200.9ms\n",
            "Speed: 3.1ms preprocess, 200.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 200.2ms\n",
            "Speed: 3.1ms preprocess, 200.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 202.2ms\n",
            "Speed: 3.0ms preprocess, 202.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 232.9ms\n",
            "Speed: 3.1ms preprocess, 232.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 203.5ms\n",
            "Speed: 2.9ms preprocess, 203.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 205.8ms\n",
            "Speed: 3.3ms preprocess, 205.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 206.9ms\n",
            "Speed: 3.1ms preprocess, 206.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 141.5ms\n",
            "Speed: 6.7ms preprocess, 141.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 146.2ms\n",
            "Speed: 3.2ms preprocess, 146.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 129.1ms\n",
            "Speed: 3.1ms preprocess, 129.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.7ms\n",
            "Speed: 2.9ms preprocess, 126.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.0ms\n",
            "Speed: 3.6ms preprocess, 134.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.0ms\n",
            "Speed: 3.4ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.6ms\n",
            "Speed: 4.1ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 128.8ms\n",
            "Speed: 3.4ms preprocess, 128.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 149.8ms\n",
            "Speed: 3.8ms preprocess, 149.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.5ms\n",
            "Speed: 3.3ms preprocess, 128.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.0ms\n",
            "Speed: 3.0ms preprocess, 130.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 131.6ms\n",
            "Speed: 2.9ms preprocess, 131.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 136.4ms\n",
            "Speed: 3.4ms preprocess, 136.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.9ms\n",
            "Speed: 3.0ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.3ms\n",
            "Speed: 3.8ms preprocess, 133.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 147.7ms\n",
            "Speed: 3.1ms preprocess, 147.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.7ms\n",
            "Speed: 3.1ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.5ms\n",
            "Speed: 3.3ms preprocess, 128.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 126.0ms\n",
            "Speed: 3.5ms preprocess, 126.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 127.4ms\n",
            "Speed: 3.0ms preprocess, 127.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.4ms\n",
            "Speed: 3.1ms preprocess, 133.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.0ms\n",
            "Speed: 3.3ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 138.3ms\n",
            "Speed: 3.0ms preprocess, 138.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.2ms\n",
            "Speed: 3.0ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.1ms\n",
            "Speed: 3.0ms preprocess, 134.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.0ms\n",
            "Speed: 3.1ms preprocess, 128.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.6ms\n",
            "Speed: 3.6ms preprocess, 128.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.4ms\n",
            "Speed: 2.7ms preprocess, 126.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.9ms\n",
            "Speed: 4.0ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.9ms\n",
            "Speed: 3.1ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 147.4ms\n",
            "Speed: 4.2ms preprocess, 147.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.2ms\n",
            "Speed: 3.0ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.3ms\n",
            "Speed: 7.0ms preprocess, 137.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.1ms\n",
            "Speed: 6.4ms preprocess, 134.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 136.1ms\n",
            "Speed: 2.5ms preprocess, 136.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 142.1ms\n",
            "Speed: 3.6ms preprocess, 142.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 151.5ms\n",
            "Speed: 3.1ms preprocess, 151.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 149.1ms\n",
            "Speed: 3.3ms preprocess, 149.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 143.1ms\n",
            "Speed: 3.5ms preprocess, 143.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 143.8ms\n",
            "Speed: 3.6ms preprocess, 143.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 146.3ms\n",
            "Speed: 3.4ms preprocess, 146.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 152.4ms\n",
            "Speed: 3.3ms preprocess, 152.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 140.4ms\n",
            "Speed: 3.3ms preprocess, 140.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 1 cell phone, 153.6ms\n",
            "Speed: 3.1ms preprocess, 153.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 1 cell phone, 143.0ms\n",
            "Speed: 3.0ms preprocess, 143.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 1 cell phone, 140.1ms\n",
            "Speed: 3.3ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 1 cell phone, 139.4ms\n",
            "Speed: 3.1ms preprocess, 139.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 1 cell phone, 137.0ms\n",
            "Speed: 4.3ms preprocess, 137.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 1 cell phone, 159.3ms\n",
            "Speed: 3.2ms preprocess, 159.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 143.9ms\n",
            "Speed: 3.5ms preprocess, 143.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 143.8ms\n",
            "Speed: 4.3ms preprocess, 143.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 138.4ms\n",
            "Speed: 5.5ms preprocess, 138.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 139.8ms\n",
            "Speed: 3.8ms preprocess, 139.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 135.4ms\n",
            "Speed: 3.1ms preprocess, 135.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 134.9ms\n",
            "Speed: 3.3ms preprocess, 134.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 137.2ms\n",
            "Speed: 3.4ms preprocess, 137.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 157.5ms\n",
            "Speed: 3.1ms preprocess, 157.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 143.6ms\n",
            "Speed: 3.4ms preprocess, 143.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 145.5ms\n",
            "Speed: 3.8ms preprocess, 145.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 139.6ms\n",
            "Speed: 3.3ms preprocess, 139.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 142.9ms\n",
            "Speed: 4.6ms preprocess, 142.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 140.9ms\n",
            "Speed: 3.2ms preprocess, 140.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 136.9ms\n",
            "Speed: 2.9ms preprocess, 136.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 158.2ms\n",
            "Speed: 3.1ms preprocess, 158.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 141.3ms\n",
            "Speed: 3.0ms preprocess, 141.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 197.5ms\n",
            "Speed: 3.0ms preprocess, 197.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 208.0ms\n",
            "Speed: 3.3ms preprocess, 208.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 208.3ms\n",
            "Speed: 3.2ms preprocess, 208.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 212.1ms\n",
            "Speed: 3.4ms preprocess, 212.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 kite, 210.8ms\n",
            "Speed: 2.9ms preprocess, 210.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 202.6ms\n",
            "Speed: 3.4ms preprocess, 202.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 kite, 205.9ms\n",
            "Speed: 3.0ms preprocess, 205.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 kite, 212.4ms\n",
            "Speed: 8.5ms preprocess, 212.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 kite, 214.3ms\n",
            "Speed: 6.7ms preprocess, 214.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 kite, 206.5ms\n",
            "Speed: 6.5ms preprocess, 206.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 202.6ms\n",
            "Speed: 3.3ms preprocess, 202.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 kite, 202.6ms\n",
            "Speed: 3.1ms preprocess, 202.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 216.8ms\n",
            "Speed: 3.3ms preprocess, 216.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 201.7ms\n",
            "Speed: 3.5ms preprocess, 201.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 207.8ms\n",
            "Speed: 3.1ms preprocess, 207.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 206.4ms\n",
            "Speed: 6.6ms preprocess, 206.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 217.5ms\n",
            "Speed: 5.1ms preprocess, 217.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 213.7ms\n",
            "Speed: 3.1ms preprocess, 213.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 173.6ms\n",
            "Speed: 3.2ms preprocess, 173.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.4ms\n",
            "Speed: 6.4ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 128.0ms\n",
            "Speed: 3.6ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 125.7ms\n",
            "Speed: 3.0ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 133.2ms\n",
            "Speed: 3.3ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 143.1ms\n",
            "Speed: 3.4ms preprocess, 143.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 156.4ms\n",
            "Speed: 3.2ms preprocess, 156.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 131.7ms\n",
            "Speed: 3.2ms preprocess, 131.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 139.2ms\n",
            "Speed: 2.9ms preprocess, 139.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.7ms\n",
            "Speed: 3.3ms preprocess, 134.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 141.7ms\n",
            "Speed: 4.1ms preprocess, 141.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 141.6ms\n",
            "Speed: 3.7ms preprocess, 141.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 137.7ms\n",
            "Speed: 3.3ms preprocess, 137.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 160.5ms\n",
            "Speed: 3.6ms preprocess, 160.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 142.7ms\n",
            "Speed: 3.7ms preprocess, 142.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 140.4ms\n",
            "Speed: 3.3ms preprocess, 140.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 150.7ms\n",
            "Speed: 3.3ms preprocess, 150.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.4ms\n",
            "Speed: 3.3ms preprocess, 141.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 138.6ms\n",
            "Speed: 4.0ms preprocess, 138.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 140.9ms\n",
            "Speed: 3.5ms preprocess, 140.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 142.7ms\n",
            "Speed: 3.7ms preprocess, 142.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.2ms\n",
            "Speed: 3.5ms preprocess, 138.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 135.8ms\n",
            "Speed: 3.4ms preprocess, 135.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.1ms\n",
            "Speed: 4.0ms preprocess, 133.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 136.0ms\n",
            "Speed: 3.3ms preprocess, 136.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 142.2ms\n",
            "Speed: 3.2ms preprocess, 142.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 155.3ms\n",
            "Speed: 4.3ms preprocess, 155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 135.8ms\n",
            "Speed: 6.4ms preprocess, 135.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 134.2ms\n",
            "Speed: 3.2ms preprocess, 134.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 145.9ms\n",
            "Speed: 3.5ms preprocess, 145.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 143.4ms\n",
            "Speed: 3.8ms preprocess, 143.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 140.7ms\n",
            "Speed: 3.3ms preprocess, 140.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 142.1ms\n",
            "Speed: 3.5ms preprocess, 142.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 161.5ms\n",
            "Speed: 3.0ms preprocess, 161.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 137.9ms\n",
            "Speed: 3.2ms preprocess, 137.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 146.9ms\n",
            "Speed: 3.9ms preprocess, 146.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 133.5ms\n",
            "Speed: 6.2ms preprocess, 133.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 133.3ms\n",
            "Speed: 3.7ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.4ms\n",
            "Speed: 3.0ms preprocess, 137.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 155.0ms\n",
            "Speed: 3.2ms preprocess, 155.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 143.3ms\n",
            "Speed: 3.1ms preprocess, 143.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 135.9ms\n",
            "Speed: 5.0ms preprocess, 135.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 139.0ms\n",
            "Speed: 3.3ms preprocess, 139.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 138.9ms\n",
            "Speed: 4.5ms preprocess, 138.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 134.7ms\n",
            "Speed: 2.8ms preprocess, 134.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 137.8ms\n",
            "Speed: 4.7ms preprocess, 137.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 155.4ms\n",
            "Speed: 3.6ms preprocess, 155.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 131.9ms\n",
            "Speed: 2.6ms preprocess, 131.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 136.9ms\n",
            "Speed: 3.2ms preprocess, 136.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 136.3ms\n",
            "Speed: 5.3ms preprocess, 136.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 133.6ms\n",
            "Speed: 3.1ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 135.0ms\n",
            "Speed: 3.1ms preprocess, 135.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 135.1ms\n",
            "Speed: 3.7ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 155.5ms\n",
            "Speed: 4.2ms preprocess, 155.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 131.5ms\n",
            "Speed: 5.1ms preprocess, 131.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 135.0ms\n",
            "Speed: 3.9ms preprocess, 135.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 137.5ms\n",
            "Speed: 3.4ms preprocess, 137.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 141.9ms\n",
            "Speed: 3.9ms preprocess, 141.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 142.5ms\n",
            "Speed: 3.2ms preprocess, 142.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 139.1ms\n",
            "Speed: 3.5ms preprocess, 139.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 141.4ms\n",
            "Speed: 3.1ms preprocess, 141.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 141.9ms\n",
            "Speed: 6.4ms preprocess, 141.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 142.8ms\n",
            "Speed: 3.3ms preprocess, 142.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 138.3ms\n",
            "Speed: 4.0ms preprocess, 138.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 188.1ms\n",
            "Speed: 3.4ms preprocess, 188.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 219.2ms\n",
            "Speed: 3.8ms preprocess, 219.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 211.8ms\n",
            "Speed: 2.9ms preprocess, 211.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 210.1ms\n",
            "Speed: 3.2ms preprocess, 210.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 203.0ms\n",
            "Speed: 3.3ms preprocess, 203.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 200.8ms\n",
            "Speed: 3.3ms preprocess, 200.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 226.5ms\n",
            "Speed: 3.2ms preprocess, 226.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 208.2ms\n",
            "Speed: 3.6ms preprocess, 208.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 204.2ms\n",
            "Speed: 3.6ms preprocess, 204.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 210.4ms\n",
            "Speed: 3.1ms preprocess, 210.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 203.5ms\n",
            "Speed: 3.5ms preprocess, 203.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 214.5ms\n",
            "Speed: 3.5ms preprocess, 214.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 200.9ms\n",
            "Speed: 3.3ms preprocess, 200.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 203.6ms\n",
            "Speed: 7.7ms preprocess, 203.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 212.1ms\n",
            "Speed: 4.6ms preprocess, 212.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 228.7ms\n",
            "Speed: 3.3ms preprocess, 228.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 217.4ms\n",
            "Speed: 3.3ms preprocess, 217.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 197.9ms\n",
            "Speed: 5.3ms preprocess, 197.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 138.5ms\n",
            "Speed: 3.4ms preprocess, 138.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 133.2ms\n",
            "Speed: 3.7ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 135.5ms\n",
            "Speed: 3.2ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 159.9ms\n",
            "Speed: 3.1ms preprocess, 159.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 144.5ms\n",
            "Speed: 3.9ms preprocess, 144.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 143.7ms\n",
            "Speed: 3.4ms preprocess, 143.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 131.8ms\n",
            "Speed: 3.4ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 134.6ms\n",
            "Speed: 3.3ms preprocess, 134.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 137.9ms\n",
            "Speed: 3.3ms preprocess, 137.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 139.7ms\n",
            "Speed: 3.1ms preprocess, 139.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 156.1ms\n",
            "Speed: 5.0ms preprocess, 156.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 138.0ms\n",
            "Speed: 3.4ms preprocess, 138.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 138.4ms\n",
            "Speed: 3.3ms preprocess, 138.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 133.1ms\n",
            "Speed: 3.6ms preprocess, 133.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 134.7ms\n",
            "Speed: 3.6ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 143.1ms\n",
            "Speed: 3.2ms preprocess, 143.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 143.4ms\n",
            "Speed: 3.3ms preprocess, 143.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 139.0ms\n",
            "Speed: 3.1ms preprocess, 139.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 138.8ms\n",
            "Speed: 3.5ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 137.5ms\n",
            "Speed: 3.0ms preprocess, 137.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 cell phone, 131.5ms\n",
            "Speed: 2.9ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 142.2ms\n",
            "Speed: 4.2ms preprocess, 142.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 136.6ms\n",
            "Speed: 3.6ms preprocess, 136.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 157.3ms\n",
            "Speed: 3.5ms preprocess, 157.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 143.1ms\n",
            "Speed: 3.7ms preprocess, 143.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 132.4ms\n",
            "Speed: 5.3ms preprocess, 132.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 136.0ms\n",
            "Speed: 4.1ms preprocess, 136.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 139.5ms\n",
            "Speed: 3.5ms preprocess, 139.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 140.1ms\n",
            "Speed: 3.5ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 140.7ms\n",
            "Speed: 4.4ms preprocess, 140.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 157.3ms\n",
            "Speed: 3.8ms preprocess, 157.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 140.4ms\n",
            "Speed: 3.3ms preprocess, 140.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 136.6ms\n",
            "Speed: 3.4ms preprocess, 136.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 137.9ms\n",
            "Speed: 4.2ms preprocess, 137.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 139.9ms\n",
            "Speed: 4.0ms preprocess, 139.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 138.2ms\n",
            "Speed: 3.1ms preprocess, 138.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 155.0ms\n",
            "Speed: 3.1ms preprocess, 155.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 131.1ms\n",
            "Speed: 4.6ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 130.0ms\n",
            "Speed: 3.2ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 135.0ms\n",
            "Speed: 3.0ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 136.2ms\n",
            "Speed: 3.0ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 136.0ms\n",
            "Speed: 3.1ms preprocess, 136.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 140.4ms\n",
            "Speed: 4.0ms preprocess, 140.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 156.1ms\n",
            "Speed: 3.1ms preprocess, 156.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 133.3ms\n",
            "Speed: 3.1ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 133.2ms\n",
            "Speed: 3.1ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 141.5ms\n",
            "Speed: 3.0ms preprocess, 141.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 136.1ms\n",
            "Speed: 3.2ms preprocess, 136.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 132.7ms\n",
            "Speed: 2.9ms preprocess, 132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 139.7ms\n",
            "Speed: 4.1ms preprocess, 139.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 155.1ms\n",
            "Speed: 3.0ms preprocess, 155.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 135.1ms\n",
            "Speed: 3.1ms preprocess, 135.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 135.4ms\n",
            "Speed: 2.9ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 150.2ms\n",
            "Speed: 3.1ms preprocess, 150.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 133.7ms\n",
            "Speed: 3.5ms preprocess, 133.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 137.6ms\n",
            "Speed: 3.3ms preprocess, 137.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 157.3ms\n",
            "Speed: 3.3ms preprocess, 157.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 132.6ms\n",
            "Speed: 4.3ms preprocess, 132.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 134.9ms\n",
            "Speed: 3.1ms preprocess, 134.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 140.8ms\n",
            "Speed: 5.1ms preprocess, 140.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 134.4ms\n",
            "Speed: 3.2ms preprocess, 134.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 138.9ms\n",
            "Speed: 3.3ms preprocess, 138.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 138.1ms\n",
            "Speed: 3.2ms preprocess, 138.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 226.1ms\n",
            "Speed: 3.1ms preprocess, 226.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 210.1ms\n",
            "Speed: 3.0ms preprocess, 210.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 kite, 208.8ms\n",
            "Speed: 3.1ms preprocess, 208.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 204.8ms\n",
            "Speed: 3.1ms preprocess, 204.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 kite, 211.0ms\n",
            "Speed: 3.5ms preprocess, 211.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 kite, 212.9ms\n",
            "Speed: 5.8ms preprocess, 212.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 227.2ms\n",
            "Speed: 3.2ms preprocess, 227.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 kite, 212.1ms\n",
            "Speed: 3.9ms preprocess, 212.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 204.5ms\n",
            "Speed: 3.1ms preprocess, 204.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 227.0ms\n",
            "Speed: 3.2ms preprocess, 227.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 207.1ms\n",
            "Speed: 7.2ms preprocess, 207.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 208.4ms\n",
            "Speed: 4.1ms preprocess, 208.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 203.5ms\n",
            "Speed: 3.0ms preprocess, 203.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 207.0ms\n",
            "Speed: 4.9ms preprocess, 207.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 238.3ms\n",
            "Speed: 3.1ms preprocess, 238.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 209.9ms\n",
            "Speed: 3.1ms preprocess, 209.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 209.9ms\n",
            "Speed: 10.2ms preprocess, 209.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 200.5ms\n",
            "Speed: 3.0ms preprocess, 200.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 123.9ms\n",
            "Speed: 2.8ms preprocess, 123.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 153.3ms\n",
            "Speed: 2.9ms preprocess, 153.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 205.9ms\n",
            "Speed: 3.3ms preprocess, 205.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 416.2ms\n",
            "Speed: 6.6ms preprocess, 416.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 kites, 137.3ms\n",
            "Speed: 3.5ms preprocess, 137.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 kites, 148.3ms\n",
            "Speed: 3.2ms preprocess, 148.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 kites, 346.6ms\n",
            "Speed: 3.2ms preprocess, 346.6ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 542.9ms\n",
            "Speed: 19.7ms preprocess, 542.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 236.5ms\n",
            "Speed: 6.7ms preprocess, 236.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 202.2ms\n",
            "Speed: 5.5ms preprocess, 202.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 205.4ms\n",
            "Speed: 3.3ms preprocess, 205.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 205.3ms\n",
            "Speed: 3.2ms preprocess, 205.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 206.0ms\n",
            "Speed: 3.3ms preprocess, 206.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 202.6ms\n",
            "Speed: 3.3ms preprocess, 202.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 201.0ms\n",
            "Speed: 2.9ms preprocess, 201.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 217.9ms\n",
            "Speed: 3.2ms preprocess, 217.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 197.8ms\n",
            "Speed: 6.5ms preprocess, 197.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 206.7ms\n",
            "Speed: 3.3ms preprocess, 206.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 213.4ms\n",
            "Speed: 3.1ms preprocess, 213.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 212.1ms\n",
            "Speed: 3.2ms preprocess, 212.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 211.1ms\n",
            "Speed: 3.1ms preprocess, 211.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 209.5ms\n",
            "Speed: 3.3ms preprocess, 209.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 155.3ms\n",
            "Speed: 3.1ms preprocess, 155.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 139.3ms\n",
            "Speed: 4.2ms preprocess, 139.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.3ms\n",
            "Speed: 3.3ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.4ms\n",
            "Speed: 3.1ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.9ms\n",
            "Speed: 3.3ms preprocess, 137.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.2ms\n",
            "Speed: 3.2ms preprocess, 137.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.9ms\n",
            "Speed: 3.3ms preprocess, 136.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 160.2ms\n",
            "Speed: 3.2ms preprocess, 160.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.5ms\n",
            "Speed: 3.0ms preprocess, 137.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.2ms\n",
            "Speed: 3.1ms preprocess, 136.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.6ms\n",
            "Speed: 2.6ms preprocess, 136.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 138.9ms\n",
            "Speed: 3.2ms preprocess, 138.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.6ms\n",
            "Speed: 3.2ms preprocess, 133.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 152.2ms\n",
            "Speed: 3.2ms preprocess, 152.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 144.9ms\n",
            "Speed: 3.1ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.5ms\n",
            "Speed: 3.1ms preprocess, 133.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.4ms\n",
            "Speed: 2.8ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.5ms\n",
            "Speed: 4.2ms preprocess, 135.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 134.0ms\n",
            "Speed: 3.2ms preprocess, 134.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 airplanes, 135.9ms\n",
            "Speed: 3.0ms preprocess, 135.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 airplanes, 161.0ms\n",
            "Speed: 3.3ms preprocess, 161.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 135.5ms\n",
            "Speed: 3.4ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 139.4ms\n",
            "Speed: 3.3ms preprocess, 139.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 136.2ms\n",
            "Speed: 3.1ms preprocess, 136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 2 airplanes, 139.4ms\n",
            "Speed: 3.7ms preprocess, 139.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 137.0ms\n",
            "Speed: 3.2ms preprocess, 137.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 139.1ms\n",
            "Speed: 3.0ms preprocess, 139.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 156.0ms\n",
            "Speed: 3.1ms preprocess, 156.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 173.1ms\n",
            "Speed: 3.5ms preprocess, 173.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 203.2ms\n",
            "Speed: 7.4ms preprocess, 203.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 205.1ms\n",
            "Speed: 4.3ms preprocess, 205.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 203.3ms\n",
            "Speed: 4.7ms preprocess, 203.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 213.6ms\n",
            "Speed: 4.7ms preprocess, 213.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 199.4ms\n",
            "Speed: 4.6ms preprocess, 199.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 209.9ms\n",
            "Speed: 3.7ms preprocess, 209.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 203.8ms\n",
            "Speed: 6.1ms preprocess, 203.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 202.1ms\n",
            "Speed: 9.5ms preprocess, 202.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 210.2ms\n",
            "Speed: 3.9ms preprocess, 210.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 199.9ms\n",
            "Speed: 5.9ms preprocess, 199.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 202.3ms\n",
            "Speed: 6.5ms preprocess, 202.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 206.2ms\n",
            "Speed: 4.4ms preprocess, 206.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 201.0ms\n",
            "Speed: 3.3ms preprocess, 201.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 212.8ms\n",
            "Speed: 5.1ms preprocess, 212.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 201.4ms\n",
            "Speed: 3.1ms preprocess, 201.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 205.0ms\n",
            "Speed: 12.0ms preprocess, 205.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 205.0ms\n",
            "Speed: 3.1ms preprocess, 205.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.3ms\n",
            "Speed: 3.2ms preprocess, 131.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 143.9ms\n",
            "Speed: 3.1ms preprocess, 143.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 139.8ms\n",
            "Speed: 4.4ms preprocess, 139.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 135.6ms\n",
            "Speed: 3.1ms preprocess, 135.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 140.0ms\n",
            "Speed: 3.1ms preprocess, 140.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 135.6ms\n",
            "Speed: 2.9ms preprocess, 135.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 134.9ms\n",
            "Speed: 3.4ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 153.6ms\n",
            "Speed: 3.8ms preprocess, 153.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 142.6ms\n",
            "Speed: 3.1ms preprocess, 142.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 144.1ms\n",
            "Speed: 3.6ms preprocess, 144.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 137.4ms\n",
            "Speed: 3.2ms preprocess, 137.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 1 kite, 140.9ms\n",
            "Speed: 3.8ms preprocess, 140.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 1 kite, 131.9ms\n",
            "Speed: 3.3ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 135.8ms\n",
            "Speed: 3.2ms preprocess, 135.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 154.7ms\n",
            "Speed: 3.3ms preprocess, 154.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 139.8ms\n",
            "Speed: 4.2ms preprocess, 139.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 131.4ms\n",
            "Speed: 3.3ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 133.9ms\n",
            "Speed: 5.0ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 133.1ms\n",
            "Speed: 4.5ms preprocess, 133.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 132.4ms\n",
            "Speed: 3.7ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 137.1ms\n",
            "Speed: 4.1ms preprocess, 137.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 149.7ms\n",
            "Speed: 6.8ms preprocess, 149.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 134.8ms\n",
            "Speed: 3.0ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 131.6ms\n",
            "Speed: 3.3ms preprocess, 131.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 137.5ms\n",
            "Speed: 5.8ms preprocess, 137.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 131.3ms\n",
            "Speed: 3.1ms preprocess, 131.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 133.2ms\n",
            "Speed: 3.1ms preprocess, 133.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 139.3ms\n",
            "Speed: 4.2ms preprocess, 139.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 139.5ms\n",
            "Speed: 3.2ms preprocess, 139.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 134.5ms\n",
            "Speed: 3.1ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 139.3ms\n",
            "Speed: 3.8ms preprocess, 139.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 129.9ms\n",
            "Speed: 3.1ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 129.7ms\n",
            "Speed: 3.5ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 135.5ms\n",
            "Speed: 3.1ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 154.7ms\n",
            "Speed: 3.0ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 138.8ms\n",
            "Speed: 3.1ms preprocess, 138.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 130.0ms\n",
            "Speed: 3.1ms preprocess, 130.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 132.1ms\n",
            "Speed: 3.5ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 133.0ms\n",
            "Speed: 3.3ms preprocess, 133.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 130.5ms\n",
            "Speed: 3.2ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 129.9ms\n",
            "Speed: 3.3ms preprocess, 129.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 148.2ms\n",
            "Speed: 3.3ms preprocess, 148.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 140.1ms\n",
            "Speed: 3.1ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 135.2ms\n",
            "Speed: 3.3ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 136.2ms\n",
            "Speed: 2.9ms preprocess, 136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 165.6ms\n",
            "Speed: 4.5ms preprocess, 165.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 164.0ms\n",
            "Speed: 3.7ms preprocess, 164.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 168.3ms\n",
            "Speed: 6.7ms preprocess, 168.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 133.4ms\n",
            "Speed: 4.1ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 129.1ms\n",
            "Speed: 2.8ms preprocess, 129.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 139.0ms\n",
            "Speed: 3.9ms preprocess, 139.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 135.2ms\n",
            "Speed: 3.2ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 134.1ms\n",
            "Speed: 3.4ms preprocess, 134.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 133.6ms\n",
            "Speed: 4.7ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 157.9ms\n",
            "Speed: 3.4ms preprocess, 157.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 kite, 136.2ms\n",
            "Speed: 3.3ms preprocess, 136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 134.4ms\n",
            "Speed: 3.1ms preprocess, 134.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 136.4ms\n",
            "Speed: 3.3ms preprocess, 136.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 134.5ms\n",
            "Speed: 3.0ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Second task completed with rehearsal learning.\n",
            "Rehearsal Action Buffer: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
            "Loss Buffer: [0.21263432502746582, 0.25857076048851013, 0.3389688730239868, 0.24148285388946533, 0.18101570010185242, 0.17303767800331116, 0.21629910171031952, 0.327926903963089, 0.15108650922775269, 0.19588398933410645, 0.3217637836933136, 0.13185395300388336, 0.17466239631175995, 0.12004157900810242, 0.1605074107646942, 0.1496599018573761, 0.10582607984542847, 0.31011316180229187, 0.13200484216213226, 0.08914873003959656, 0.07929714024066925, 0.11793123185634613, 0.11131016910076141, 0.06602030247449875, 0.2961684763431549, 0.10017939656972885, 0.05605718865990639, 0.2888360917568207, 0.08985063433647156, 0.04968687519431114, 0.28346335887908936, 0.08256057649850845, 0.04435082897543907, 0.2786356806755066, 0.5282779335975647, 0.6243489980697632, 0.45248645544052124, 0.2246241420507431, 0.5407928228378296, 0.6071640849113464, 0.2240561693906784, 0.525640606880188, 0.5817229151725769, 0.22071881592273712, 0.5127175450325012, 0.5309697985649109, 0.5035403966903687, 0.47907567024230957, 0.21463197469711304, 0.4877597987651825, 0.4295162856578827, 0.21197138726711273, 0.46309390664100647, 0.3902970254421234, 0.20637038350105286, 0.43848568201065063, 0.3549475073814392, 0.20304694771766663, 0.3248615264892578, 0.40189290046691895, 0.19866417348384857, 0.3838198781013489, 0.28934571146965027, 0.191949725151062, 0.2728714048862457, 0.3500130772590637, 0.18717913329601288, 0.2551894187927246, 0.3236665427684784, 0.24020400643348694, 0.30596035718917847, 0.2969124913215637, 0.2235306054353714, 0.2813332676887512, 0.21448826789855957, 0.2667844295501709, 0.20458370447158813, 0.2501380741596222, 0.19601933658123016, 0.23381629586219788, 0.18824562430381775, 0.21810051798820496, 0.18069525063037872, 0.2033621221780777, 0.17484621703624725, 0.18997807800769806, 0.16823790967464447, 0.17856153845787048, 0.16292642056941986, 0.16816624999046326, 0.15835003554821014, 0.15875695645809174, 0.1533978134393692, 0.15007047355175018, 0.14913393557071686, 0.3803260624408722, 0.39290180802345276, 0.1375759243965149, 0.1436200886964798, 0.13397051393985748, 0.14184710383415222, 0.1300356090068817, 0.13860797882080078, 0.13828809559345245, 0.12435772269964218, 0.13575366139411926, 0.1218138188123703, 0.1329548954963684, 0.11813785135746002, 0.1296181082725525, 0.11466033011674881, 0.1264861524105072, 0.11303630471229553, 0.11311408132314682, 0.12928465008735657, 0.1197737604379654, 0.11956228315830231, 0.1086202934384346, 0.11710980534553528, 0.10802481323480606, 0.1236671656370163, 0.12265624105930328, 0.11309942603111267, 0.11300565302371979, 0.11204167455434799, 0.11794809997081757, 0.10965733230113983, 0.10980161279439926, 0.11545498669147491, 0.11582670360803604, 0.11362101137638092, 0.1056218072772026, 0.1121121197938919, 0.11423957347869873, 0.10288633406162262, 0.11034805327653885, 0.11375993490219116, 0.10022664070129395, 0.10807424038648605, 0.09842859208583832, 0.10689550638198853, 0.11354035139083862, 0.09607022255659103, 0.10476168990135193, 0.0942973792552948, 0.10372903198003769, 0.09221991151571274, 0.10357578098773956, 0.09060703217983246, 0.08909044414758682, 0.08784205466508865, 0.09705337136983871, 0.09520046412944794, 0.08507855981588364, 0.08403560519218445, 0.09172356873750687, 0.08309949189424515, 0.08068136125802994, 0.08452340960502625, 0.07707889378070831, 0.07531324774026871, 0.07415373623371124, 0.06165207922458649, 0.5704616904258728, 0.06696801632642746, 0.06453963369131088, 0.06255749613046646, 0.06139019876718521, 0.06061330810189247, 0.06754345446825027, 0.06629858911037445, 0.05493536219000816, 0.053147539496421814, 0.06170259416103363, 0.05066141486167908, 0.05909543111920357, 0.04863835871219635, 0.046531349420547485, 0.04497896134853363, 0.06649253517389297, 0.04254910349845886, 0.04965412616729736, 0.03984031826257706, 0.08217434585094452, 0.03771507740020752, 0.08513904362916946, 0.03551868349313736, 0.08658719807863235, 0.04427154362201691, 0.08727657794952393, 0.03203766047954559, 0.030387263745069504, 0.029246091842651367, 0.02825031243264675, 0.02709348313510418, 0.02646121382713318, 0.026475870981812477, 0.026547959074378014, 0.06739199161529541, 0.026025135070085526, 0.06532490998506546, 0.02565206028521061, 0.02571115829050541, 0.0627390444278717, 0.02414243295788765, 0.030895618721842766, 0.03004639223217964, 0.030375640839338303, 0.03089260123670101, 0.023949652910232544, 0.030075211077928543, 0.023379778489470482, 0.022855395451188087, 0.021654509007930756, 0.021268831565976143, 0.01990215852856636, 0.019134795293211937, 0.0183523241430521, 0.017134854570031166, 0.016421977430582047, 0.015244731679558754, 0.01448195893317461, 0.013987403362989426, 0.013385282829403877, 0.012636343948543072, 0.011435162276029587, 0.010896285995841026, 0.012606993317604065, 0.009997877292335033, 0.009502746164798737, 0.008673567324876785, 0.00830660667270422, 0.00757718225941062, 0.006963944528251886, 0.007946529425680637, 0.0062958174385130405, 0.007263263687491417, 0.006392709445208311, 0.0060665784403681755, 0.005266112741082907, 0.0047412752173841, 0.8725939989089966, 0.8837761282920837, 0.8857192993164062, 0.8879403471946716, 0.889151930809021, 0.894506573677063, 0.8925232291221619, 0.8922939300537109, 0.8926197290420532, 0.8874508142471313, 0.8835626840591431, 0.8814855813980103, 0.8757755160331726, 0.8757005929946899, 0.8665307760238647, 0.8551257252693176, 0.8454599380493164, 0.8347617387771606, 0.8219482898712158, 0.8068317770957947, 0.7907668948173523, 0.7717898488044739, 0.7506366968154907, 0.7282410860061646, 0.7037431001663208, 0.6769790649414062, 0.6473711729049683, 0.6156364679336548, 0.5810166597366333, 0.5438334941864014, 0.505216121673584, 0.4641435444355011, 0.4224313497543335, 0.38036319613456726, 0.33912575244903564, 0.2981168329715729, 0.25914058089256287, 0.2239052653312683, 0.26827511191368103, 0.16200250387191772, 0.13822795450687408, 0.11585456877946854, 0.09838703274726868, 0.0822964608669281, 0.0686635971069336, 0.05810470134019852, 0.04970395565032959, 0.04251781851053238, 0.06733623892068863, 0.030451511964201927, 0.04991564899682999, 0.02294079214334488, 0.03875613957643509, 0.01760311983525753, 0.031265102326869965, 0.013618161901831627, 0.026378871873021126, 0.01153454277664423, 0.022140467539429665, 0.009151442907750607, 0.018772920593619347, 0.007919611409306526, 0.01603025197982788, 0.006427675485610962, 0.00492611899971962, 0.011203156784176826, 0.00898811500519514, 0.004133753944188356, 0.0049295127391815186, 0.009955145418643951, 0.014524949714541435, 0.006653268355876207, 0.019949711859226227, 0.014257258735597134, 0.017940636724233627, 0.03719994053244591, 0.6153067946434021, 0.5639525651931763, 0.5137622356414795, 0.47006282210350037, 0.4296417236328125, 0.5529211163520813, 0.38504043221473694, 0.34566086530685425, 0.32827243208885193, 0.3113107979297638, 0.2962275445461273, 0.2851378321647644, 0.2717738747596741, 0.1571742296218872, 0.25263917446136475, 0.24185915291309357, 0.14908280968666077, 0.22661463916301727, 0.1440013200044632, 0.20822358131408691, 0.13950222730636597, 0.19782137870788574, 0.19225680828094482, 0.18720291554927826, 0.1800668090581894, 0.17611846327781677, 0.17398297786712646, 0.17154556512832642, 0.16880744695663452, 0.16630437970161438, 0.16422878205776215, 0.16162990033626556, 0.159407839179039, 0.16023613512516022, 0.19426938891410828, 0.1541980504989624, 0.18988190591335297, 0.1495572328567505, 0.14711792767047882, 0.1448511928319931, 0.38263094425201416, 0.13968676328659058, 0.13711993396282196, 0.13557587563991547, 0.1334105134010315, 0.13245905935764313, 0.1311711072921753, 0.13087725639343262, 0.13101975619792938, 0.23807398974895477, 0.12570077180862427, 0.2332979440689087, 0.1209041029214859, 0.22422710061073303, 0.21915051341056824, 0.21645595133304596, 0.218618705868721, 0.14521969854831696, 0.21264703571796417, 0.10865865647792816, 0.13524377346038818, 0.1324838250875473, 0.10012808442115784, 0.1859426647424698, 0.0966501384973526, 0.09273813664913177, 0.09257148206233978, 0.17843341827392578, 0.08809170126914978, 0.08657700568437576, 0.16834840178489685, 0.08361701667308807, 0.1571682095527649, 0.07703348249197006, 0.07500843703746796, 0.1470731645822525, 0.0676218569278717, 0.06561630964279175, 0.12972700595855713, 0.12738515436649323, 0.06040961667895317, 0.11735252290964127, 0.05473588407039642, 0.10695195198059082, 0.048304036259651184, 0.10087659955024719, 0.04425884410738945, 0.49513790011405945, 0.6408843398094177, 0.5050345063209534, 0.6412843465805054, 0.5110008120536804, 0.6362613439559937, 0.49208322167396545, 0.6322436928749084, 0.6178907155990601, 0.45595207810401917, 0.4421848654747009, 0.5625085234642029, 0.39282840490341187, 0.5127180218696594, 0.3307693600654602, 0.4465197026729584, 0.2775351107120514, 0.35994186997413635, 0.18566085398197174, 0.15418197214603424, 0.2507210075855255, 0.1989697813987732, 0.08183512836694717, 0.12806767225265503, 0.08021669089794159, 0.035191815346479416, 0.023074351251125336, 0.018517853692173958, 0.03802109882235527, 0.03155244141817093, 0.009486515074968338, 0.021362828090786934, 0.007203019689768553, 0.0136100510135293, 0.004335638601332903, 0.00998509582132101, 0.0034332526847720146, 0.007815038785338402, 0.0034297583624720573, 0.0059684221632778645, 0.0019561592489480972, 0.004947832319885492, 0.0015204483643174171, 0.0041352822445333, 0.001340672723017633, 0.003974607214331627, 0.001702778972685337, 0.003805719083175063, 0.0011890631867572665, 0.003753846511244774, 0.0012631481513381004, 0.0031215378548949957, 0.0010412184055894613, 0.0028135336469858885, 0.0012426862958818674, 0.0035149119794368744, 0.0020991098135709763, 0.0031435564160346985, 0.0028347678016871214, 0.0014076782390475273, 0.0025342244189232588, 0.0026679043658077717, 0.0010597024811431766, 0.002441014861688018, 0.0018673159647732973, 0.002687574364244938, 0.0008755985181778669, 0.0024427827447652817, 0.0009707739809527993, 0.002541830064728856, 0.0008521932177245617, 0.002254252089187503, 0.0010070926509797573, 0.00095107447123155, 0.00235337414778769, 0.0009529558010399342, 0.002446497557684779, 0.002618433441966772, 0.0008769360720179975, 0.0022557415068149567, 0.0007617274532094598, 0.002362098777666688, 0.0009295072522945702, 0.0022053259890526533, 0.0010685035958886147, 0.002095886506140232, 0.0020893013570457697, 0.000878767401445657, 0.002118564210832119, 0.0013967951526865363, 0.0021825777366757393, 0.0008883225964382291, 0.0022871308028697968, 0.0007126852869987488, 0.002281023422256112, 0.0007434422732330859, 0.001938311499543488, 0.0007732420926913619, 0.0020199003629386425, 0.0010793134570121765, 0.0017611890798434615, 0.0010249648476019502, 0.000926762935705483, 0.0017114535439759493, 0.07382987439632416, 0.08565075695514679, 0.11153233051300049, 0.09206820279359818, 0.05875307694077492, 0.12180664390325546, 0.15153047442436218, 0.06783819198608398, 0.0819883644580841, 0.07586593925952911, 0.08638586103916168, 0.10365532338619232, 0.08040815591812134, 0.07392024993896484, 0.08732450753450394, 0.0929948166012764, 0.07827784866094589, 0.08196781575679779, 0.1129530817270279, 0.06170062720775604, 0.10747218132019043, 0.08531614392995834, 0.09292465448379517, 0.06600382924079895, 0.09917885065078735, 0.09205905348062515, 0.09045646339654922, 0.08420857042074203, 0.09807056933641434, 0.090894415974617, 0.04860890656709671, 0.08824321627616882, 0.059087157249450684, 0.10142400860786438, 0.06575673818588257, 0.07299204915761948, 0.09506894648075104, 0.08791296929121017, 0.09587200731039047, 0.06509885936975479, 0.07389731705188751, 0.06991849094629288, 0.06474688649177551, 0.0746384784579277, 0.08105485886335373, 0.08658289164304733, 0.04118048772215843, 0.08258655667304993, 0.07562024891376495, 0.10131516307592392, 0.07860688120126724, 0.07078942656517029, 0.07835042476654053, 0.08447305858135223, 0.06332330405712128, 0.053875960409641266, 0.08252338320016861, 0.07010260969400406, 0.07853631675243378, 0.0860101655125618, 0.10655520111322403, 0.07402264326810837, 0.06972341984510422, 0.08989569544792175, 0.05478101596236229, 0.08871133625507355, 0.059398334473371506, 0.07355879247188568, 0.08109065145254135, 0.0836954265832901, 0.05394695699214935, 0.04103505238890648, 0.09032099694013596, 0.06571539491415024, 0.06808245927095413, 0.07905525714159012, 0.05261966958642006, 0.05350274220108986, 0.07311117649078369, 0.07018838822841644, 0.06635834276676178, 0.10045550018548965, 0.06198643893003464, 0.07432428747415543, 0.05391479283571243, 0.06310463696718216, 0.08962047100067139, 0.06882986426353455, 0.06696227937936783, 0.07497619837522507, 0.07156987488269806, 0.059260040521621704, 0.08112076669931412, 0.09640555828809738, 0.07075833529233932, 0.0878162682056427, 0.058991335332393646, 0.07778776437044144, 0.05793927237391472, 0.07437529414892197, 0.08653362840414047, 0.07288046181201935, 0.06138358637690544, 0.08531519025564194, 0.05083426088094711, 0.07168123126029968, 0.05348491296172142, 0.05544203892350197, 0.0514569915831089, 0.06524624675512314, 0.0698089450597763, 0.08542045950889587, 0.06781019270420074, 0.10970263183116913, 0.06673291325569153, 0.057979147881269455, 0.07838255167007446, 0.06400766968727112, 0.07216216623783112, 0.06124001741409302, 0.07071494311094284, 0.06773309409618378, 0.09380816668272018, 0.08222710341215134, 0.06462334841489792, 0.06317776441574097, 0.07835885882377625, 0.055371832102537155, 0.0692749097943306, 0.0655284970998764, 0.05829291790723801, 0.07565616816282272, 0.06612814217805862, 0.07314693927764893, 0.04461490735411644, 0.07177578657865524, 0.08269113302230835, 0.07109421491622925, 0.06284447759389877, 0.07383115589618683, 0.08136064559221268, 0.07854417711496353, 0.057203508913517, 0.08590790629386902, 0.06735020875930786, 0.09182114154100418, 0.09787014126777649, 0.0691026896238327, 0.08300014585256577, 0.06386934965848923, 0.061209701001644135, 0.08452817052602768, 0.0863148644566536, 0.07193280011415482, 0.0712895542383194, 0.05561874806880951, 0.06396528333425522, 0.06443124264478683, 0.07282407581806183, 0.09784086793661118, 0.05526275187730789, 0.08276346325874329, 0.05631852522492409, 0.06704039126634598, 0.06932906806468964, 0.055533695966005325, 0.07673808187246323, 0.0785355493426323, 0.0788143053650856, 0.08785883337259293, 0.08313272893428802, 0.04516220837831497, 0.060735780745744705, 0.0790582075715065, 0.06028377264738083, 0.07132478803396225, 0.08179965615272522, 0.0513470321893692, 0.06969065964221954, 0.07177212834358215, 0.0704503208398819, 0.0449228398501873, 0.05611202493309975, 0.07421692460775375, 0.08094602078199387, 0.0827280580997467, 0.06978368759155273, 0.0601310133934021, 0.052623819559812546, 0.056742191314697266, 0.05569873005151749, 0.06319227069616318, 0.08322855085134506, 0.07651518285274506, 0.0757988691329956, 0.049183279275894165, 0.07955627888441086, 0.06863880157470703, 0.05076908320188522, 0.06144733726978302, 0.07414129376411438, 0.07609784603118896, 0.04931512847542763, 0.054195333272218704, 0.07504512369632721, 0.07181313633918762, 0.039070092141628265, 0.08080750703811646, 0.07701295614242554, 0.051311470568180084, 0.07921825349330902, 0.07806094735860825, 0.06962218135595322, 0.05474301427602768, 0.06303121894598007, 0.08204378187656403]\n",
            "Rehearsal memory size: 724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#두 번째 태스크 손실 시각화\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 이동평균 함수\n",
        "def moving_average(data, window_size):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
        "\n",
        "# 원본 데이터\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(loss_buffer, color='lightblue', alpha=0.5, label='Raw Loss')\n",
        "\n",
        "# 이동평균 데이터\n",
        "smoothed_loss = moving_average(loss_buffer, 10)\n",
        "plt.plot(range(10-1, len(loss_buffer)), smoothed_loss, color='red', label='Smoothed (window=10)')\n",
        "\n",
        "plt.title(\"Rehearsal Learning Loss over frames (Smoothed)\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "e2Cjvc6yKAzQ",
        "outputId": "5335fc49-a66f-4301-dafc-add46c424795"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#두 번째 태스크 액션 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Loss 변화 시각화\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(action_buffer, marker='o', markersize=3, linewidth=1)\n",
        "plt.title(\"actions over frames\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"actions\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "jd7kylLdKDTb",
        "outputId": "86bab00f-f978-40d9-94c3-03499c109d1a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task1 평가\n"
      ],
      "metadata": {
        "id": "dUWh1rznYvZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## driving 12 평가"
      ],
      "metadata": {
        "id": "OnvvJ5FsZ2R3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_cl_metrics(final_tasks, final_labels, baseline_acc=0.5):\n",
        "    \"\"\"\n",
        "    Continual Learning metrics: IM, FWT, BWT 계산\n",
        "    - IM (Initial Accuracy): 각 태스크 처음 배운 직후의 평균 정확도\n",
        "    - FWT (Forward Transfer): baseline 대비 이후 태스크 성능 향상\n",
        "    - BWT (Backward Transfer): 마지막 학습 후 이전 태스크 성능 변화\n",
        "    \"\"\"\n",
        "\n",
        "    num_tasks = len(final_tasks)\n",
        "    task_accuracies = []\n",
        "\n",
        "    # 태스크별 정확도 계산\n",
        "    for idx in range(num_tasks):\n",
        "        preds = np.array(final_tasks[idx]).flatten()\n",
        "        labels = np.array(final_labels[idx]).flatten()\n",
        "\n",
        "        if preds.size == 0 or labels.size == 0:\n",
        "            acc = 0.0\n",
        "        else:\n",
        "            acc = np.mean(preds == labels)\n",
        "\n",
        "        task_accuracies.append(acc)\n",
        "\n",
        "    task_accuracies = np.array(task_accuracies)\n",
        "    print(\"Task accuracies:\", task_accuracies)\n",
        "\n",
        "    # IM\n",
        "    IM = np.mean(task_accuracies) if num_tasks > 0 else 0.0\n",
        "\n",
        "    # FWT\n",
        "    if num_tasks > 1:\n",
        "        FWT = np.mean(task_accuracies[1:] - baseline_acc)\n",
        "    else:\n",
        "        FWT = 0.0\n",
        "\n",
        "    # BWT\n",
        "    if num_tasks > 1:\n",
        "        BWT = np.mean(task_accuracies[-1] - task_accuracies[:-1])\n",
        "    else:\n",
        "        BWT = 0.0\n",
        "\n",
        "    return IM, FWT, BWT\n"
      ],
      "metadata": {
        "id": "bSm0HD-U5LON"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨 결과 저장\n",
        "final_labels = []\n",
        "final_tasks=[]"
      ],
      "metadata": {
        "id": "XpOyJXwoKMHO"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 모드 설정\n",
        "fm_model.eval()\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "test_loss_buffer = []\n",
        "test_action_buffer = []\n",
        "measuring_loss = False\n",
        "test_video_file_count = 0\n"
      ],
      "metadata": {
        "id": "fd86IH0eKSNU"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 비디오 업로드 (driving12)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "test_video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "vBz85tdfKT3y",
        "outputId": "fe2a592a-ad43-4964-f351-a7c5673066b6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9cbe5fb0-6526-456b-9404-03df12d9da67\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9cbe5fb0-6526-456b-9404-03df12d9da67\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving driving_12.mp4 to driving_12 (3).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 테스트용 비디오 불러오기 =====\n",
        "cap = cv2.VideoCapture(test_video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "\n",
        "with torch.no_grad():  # 테스트 시 gradient 계산 비활성화\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "        step += 1\n",
        "\n",
        "        result = model(frame)[0]\n",
        "        h, w, _ = frame.shape\n",
        "        frame_actions = []\n",
        "\n",
        "        for box in result.boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 테스트 시에는 rehearsal 손실만 계산 (학습하지 않음)\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            total_loss = rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                test_loss_buffer.append(total_loss.item())\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "        final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "        if measuring_loss:\n",
        "            test_action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(\"Test completed with rehearsal evaluation.\")\n",
        "print(\"Test Action Buffer:\", test_action_buffer)\n",
        "print(\"Test Loss Buffer:\", test_loss_buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTlUYAnlKbbq",
        "outputId": "348c81d6-cbed-4ddf-d86a-dfe65b18cf02"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 1 car, 133.4ms\n",
            "Speed: 4.7ms preprocess, 133.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 138.0ms\n",
            "Speed: 3.2ms preprocess, 138.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.1ms\n",
            "Speed: 3.0ms preprocess, 135.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.7ms\n",
            "Speed: 3.8ms preprocess, 135.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 134.5ms\n",
            "Speed: 4.2ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 151.9ms\n",
            "Speed: 3.4ms preprocess, 151.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 134.2ms\n",
            "Speed: 3.6ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 135.3ms\n",
            "Speed: 3.0ms preprocess, 135.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.4ms\n",
            "Speed: 3.7ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 131.2ms\n",
            "Speed: 3.2ms preprocess, 131.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 133.3ms\n",
            "Speed: 3.2ms preprocess, 133.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.8ms\n",
            "Speed: 3.2ms preprocess, 131.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 151.2ms\n",
            "Speed: 3.5ms preprocess, 151.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.9ms\n",
            "Speed: 3.1ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 141.8ms\n",
            "Speed: 3.2ms preprocess, 141.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.4ms\n",
            "Speed: 3.4ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 134.9ms\n",
            "Speed: 3.0ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.9ms\n",
            "Speed: 3.0ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 136.3ms\n",
            "Speed: 3.4ms preprocess, 136.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 149.4ms\n",
            "Speed: 3.3ms preprocess, 149.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.8ms\n",
            "Speed: 3.2ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 132.1ms\n",
            "Speed: 3.0ms preprocess, 132.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 132.7ms\n",
            "Speed: 2.9ms preprocess, 132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 132.0ms\n",
            "Speed: 3.0ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 131.7ms\n",
            "Speed: 3.1ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.8ms\n",
            "Speed: 3.0ms preprocess, 128.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 151.8ms\n",
            "Speed: 3.2ms preprocess, 151.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 130.3ms\n",
            "Speed: 2.9ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 131.7ms\n",
            "Speed: 3.2ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.4ms\n",
            "Speed: 3.3ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 136.2ms\n",
            "Speed: 3.1ms preprocess, 136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.3ms\n",
            "Speed: 3.0ms preprocess, 135.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 174.9ms\n",
            "Speed: 4.1ms preprocess, 174.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 175.8ms\n",
            "Speed: 4.3ms preprocess, 175.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 163.0ms\n",
            "Speed: 4.1ms preprocess, 163.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 152.0ms\n",
            "Speed: 3.6ms preprocess, 152.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 137.9ms\n",
            "Speed: 3.5ms preprocess, 137.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.6ms\n",
            "Speed: 3.1ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.4ms\n",
            "Speed: 3.1ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 148.3ms\n",
            "Speed: 3.1ms preprocess, 148.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.8ms\n",
            "Speed: 2.9ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.6ms\n",
            "Speed: 3.6ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 139.6ms\n",
            "Speed: 3.2ms preprocess, 139.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.5ms\n",
            "Speed: 3.1ms preprocess, 133.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.3ms\n",
            "Speed: 3.1ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.4ms\n",
            "Speed: 3.0ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 175.2ms\n",
            "Speed: 3.2ms preprocess, 175.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 136.9ms\n",
            "Speed: 3.9ms preprocess, 136.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 136.8ms\n",
            "Speed: 3.4ms preprocess, 136.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.0ms\n",
            "Speed: 3.2ms preprocess, 132.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 139.4ms\n",
            "Speed: 3.2ms preprocess, 139.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 134.7ms\n",
            "Speed: 3.1ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.4ms\n",
            "Speed: 3.0ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 chair, 154.3ms\n",
            "Speed: 3.2ms preprocess, 154.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 144.3ms\n",
            "Speed: 3.0ms preprocess, 144.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.7ms\n",
            "Speed: 3.0ms preprocess, 136.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 136.9ms\n",
            "Speed: 3.2ms preprocess, 136.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 couch, 132.1ms\n",
            "Speed: 3.1ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 137.2ms\n",
            "Speed: 3.2ms preprocess, 137.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 bed, 147.2ms\n",
            "Speed: 3.0ms preprocess, 147.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 129.7ms\n",
            "Speed: 6.7ms preprocess, 129.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 134.4ms\n",
            "Speed: 3.0ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 161.6ms\n",
            "Speed: 3.4ms preprocess, 161.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 199.8ms\n",
            "Speed: 3.2ms preprocess, 199.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 203.0ms\n",
            "Speed: 3.0ms preprocess, 203.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 207.2ms\n",
            "Speed: 3.1ms preprocess, 207.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 203.6ms\n",
            "Speed: 3.0ms preprocess, 203.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 192.3ms\n",
            "Speed: 3.3ms preprocess, 192.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 192.4ms\n",
            "Speed: 4.1ms preprocess, 192.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 206.5ms\n",
            "Speed: 3.7ms preprocess, 206.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 225.1ms\n",
            "Speed: 4.0ms preprocess, 225.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 205.9ms\n",
            "Speed: 3.4ms preprocess, 205.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 209.1ms\n",
            "Speed: 3.5ms preprocess, 209.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 202.7ms\n",
            "Speed: 4.8ms preprocess, 202.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 206.6ms\n",
            "Speed: 3.2ms preprocess, 206.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 204.7ms\n",
            "Speed: 3.3ms preprocess, 204.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 201.0ms\n",
            "Speed: 3.2ms preprocess, 201.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 192.8ms\n",
            "Speed: 3.3ms preprocess, 192.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 218.0ms\n",
            "Speed: 3.2ms preprocess, 218.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 211.6ms\n",
            "Speed: 3.1ms preprocess, 211.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 203.3ms\n",
            "Speed: 5.5ms preprocess, 203.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 124.8ms\n",
            "Speed: 4.2ms preprocess, 124.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.7ms\n",
            "Speed: 3.2ms preprocess, 127.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 131.6ms\n",
            "Speed: 3.6ms preprocess, 131.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 127.2ms\n",
            "Speed: 2.8ms preprocess, 127.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 124.0ms\n",
            "Speed: 3.2ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toilet, 128.2ms\n",
            "Speed: 3.2ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 toilet, 128.6ms\n",
            "Speed: 3.2ms preprocess, 128.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 131.4ms\n",
            "Speed: 2.8ms preprocess, 131.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 131.1ms\n",
            "Speed: 3.3ms preprocess, 131.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 132.3ms\n",
            "Speed: 3.3ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 130.5ms\n",
            "Speed: 3.7ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 129.1ms\n",
            "Speed: 3.2ms preprocess, 129.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 156.7ms\n",
            "Speed: 3.7ms preprocess, 156.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 171.5ms\n",
            "Speed: 6.9ms preprocess, 171.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 166.7ms\n",
            "Speed: 4.7ms preprocess, 166.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 147.2ms\n",
            "Speed: 4.3ms preprocess, 147.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 146.5ms\n",
            "Speed: 4.3ms preprocess, 146.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 136.2ms\n",
            "Speed: 4.2ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 128.1ms\n",
            "Speed: 3.8ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 147.2ms\n",
            "Speed: 3.5ms preprocess, 147.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.3ms\n",
            "Speed: 4.2ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 135.8ms\n",
            "Speed: 4.6ms preprocess, 135.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 135.0ms\n",
            "Speed: 3.4ms preprocess, 135.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 131.1ms\n",
            "Speed: 3.7ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.4ms\n",
            "Speed: 3.3ms preprocess, 133.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 139.2ms\n",
            "Speed: 3.3ms preprocess, 139.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 133.9ms\n",
            "Speed: 3.2ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 131.6ms\n",
            "Speed: 4.6ms preprocess, 131.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.2ms\n",
            "Speed: 3.6ms preprocess, 134.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.6ms\n",
            "Speed: 4.1ms preprocess, 137.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.4ms\n",
            "Speed: 3.1ms preprocess, 126.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.9ms\n",
            "Speed: 3.3ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.4ms\n",
            "Speed: 3.2ms preprocess, 133.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 142.4ms\n",
            "Speed: 3.2ms preprocess, 142.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.4ms\n",
            "Speed: 5.7ms preprocess, 130.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.7ms\n",
            "Speed: 3.3ms preprocess, 133.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.4ms\n",
            "Speed: 3.4ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.1ms\n",
            "Speed: 3.6ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.7ms\n",
            "Speed: 3.7ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 133.5ms\n",
            "Speed: 3.5ms preprocess, 133.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 148.2ms\n",
            "Speed: 3.4ms preprocess, 148.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.2ms\n",
            "Speed: 3.6ms preprocess, 133.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.9ms\n",
            "Speed: 3.5ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.4ms\n",
            "Speed: 3.2ms preprocess, 129.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.6ms\n",
            "Speed: 3.2ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.1ms\n",
            "Speed: 4.6ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.3ms\n",
            "Speed: 3.2ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 147.5ms\n",
            "Speed: 3.1ms preprocess, 147.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 127.9ms\n",
            "Speed: 3.4ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 129.2ms\n",
            "Speed: 3.2ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 142.9ms\n",
            "Speed: 3.1ms preprocess, 142.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 133.4ms\n",
            "Speed: 3.9ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 126.3ms\n",
            "Speed: 3.4ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 130.1ms\n",
            "Speed: 3.2ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 145.4ms\n",
            "Speed: 3.1ms preprocess, 145.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 127.9ms\n",
            "Speed: 3.1ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 128.2ms\n",
            "Speed: 3.2ms preprocess, 128.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 139.6ms\n",
            "Speed: 6.3ms preprocess, 139.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 131.4ms\n",
            "Speed: 3.3ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 132.2ms\n",
            "Speed: 3.6ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 132.6ms\n",
            "Speed: 3.5ms preprocess, 132.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 171.8ms\n",
            "Speed: 11.8ms preprocess, 171.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 164.6ms\n",
            "Speed: 4.6ms preprocess, 164.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 168.7ms\n",
            "Speed: 4.2ms preprocess, 168.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 188.3ms\n",
            "Speed: 4.1ms preprocess, 188.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 218.1ms\n",
            "Speed: 4.7ms preprocess, 218.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 207.1ms\n",
            "Speed: 4.6ms preprocess, 207.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 194.1ms\n",
            "Speed: 3.5ms preprocess, 194.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 1 truck, 204.8ms\n",
            "Speed: 3.7ms preprocess, 204.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 199.7ms\n",
            "Speed: 3.8ms preprocess, 199.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 207.5ms\n",
            "Speed: 3.6ms preprocess, 207.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 198.6ms\n",
            "Speed: 3.6ms preprocess, 198.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 204.5ms\n",
            "Speed: 3.6ms preprocess, 204.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 1 truck, 196.8ms\n",
            "Speed: 9.9ms preprocess, 196.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 199.4ms\n",
            "Speed: 4.5ms preprocess, 199.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 218.3ms\n",
            "Speed: 3.2ms preprocess, 218.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 199.2ms\n",
            "Speed: 3.1ms preprocess, 199.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 194.8ms\n",
            "Speed: 9.7ms preprocess, 194.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 213.8ms\n",
            "Speed: 4.2ms preprocess, 213.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 206.9ms\n",
            "Speed: 3.4ms preprocess, 206.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 219.1ms\n",
            "Speed: 3.2ms preprocess, 219.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 191.0ms\n",
            "Speed: 3.2ms preprocess, 191.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 134.7ms\n",
            "Speed: 2.8ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 129.7ms\n",
            "Speed: 3.1ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 130.1ms\n",
            "Speed: 3.1ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 127.5ms\n",
            "Speed: 3.2ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 149.9ms\n",
            "Speed: 3.3ms preprocess, 149.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.4ms\n",
            "Speed: 5.4ms preprocess, 137.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.5ms\n",
            "Speed: 3.6ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 134.1ms\n",
            "Speed: 3.5ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 137.0ms\n",
            "Speed: 3.6ms preprocess, 137.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.0ms\n",
            "Speed: 3.2ms preprocess, 133.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.4ms\n",
            "Speed: 3.2ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 148.0ms\n",
            "Speed: 3.3ms preprocess, 148.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.0ms\n",
            "Speed: 3.2ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.1ms\n",
            "Speed: 4.2ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.8ms\n",
            "Speed: 5.0ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 138.2ms\n",
            "Speed: 3.3ms preprocess, 138.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.0ms\n",
            "Speed: 3.4ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.4ms\n",
            "Speed: 3.1ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 1 cell phone, 151.0ms\n",
            "Speed: 3.4ms preprocess, 151.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 133.5ms\n",
            "Speed: 3.1ms preprocess, 133.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.0ms\n",
            "Speed: 3.6ms preprocess, 134.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.9ms\n",
            "Speed: 3.2ms preprocess, 136.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.5ms\n",
            "Speed: 3.4ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.6ms\n",
            "Speed: 3.6ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.0ms\n",
            "Speed: 3.1ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 149.1ms\n",
            "Speed: 5.6ms preprocess, 149.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 127.8ms\n",
            "Speed: 3.7ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.6ms\n",
            "Speed: 3.1ms preprocess, 127.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 127.8ms\n",
            "Speed: 3.1ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 128.4ms\n",
            "Speed: 2.9ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 124.6ms\n",
            "Speed: 3.6ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 127.9ms\n",
            "Speed: 3.2ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 151.4ms\n",
            "Speed: 3.7ms preprocess, 151.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 130.6ms\n",
            "Speed: 4.5ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 130.5ms\n",
            "Speed: 3.4ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.0ms\n",
            "Speed: 3.2ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.6ms\n",
            "Speed: 3.1ms preprocess, 133.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 162.0ms\n",
            "Speed: 3.9ms preprocess, 162.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 190.0ms\n",
            "Speed: 4.7ms preprocess, 190.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 167.7ms\n",
            "Speed: 4.2ms preprocess, 167.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 161.8ms\n",
            "Speed: 4.3ms preprocess, 161.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 155.4ms\n",
            "Speed: 3.7ms preprocess, 155.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.0ms\n",
            "Speed: 3.2ms preprocess, 134.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 128.8ms\n",
            "Speed: 3.2ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 130.9ms\n",
            "Speed: 2.9ms preprocess, 130.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 149.4ms\n",
            "Speed: 3.3ms preprocess, 149.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.2ms\n",
            "Speed: 3.1ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 135.5ms\n",
            "Speed: 3.3ms preprocess, 135.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.4ms\n",
            "Speed: 3.2ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.1ms\n",
            "Speed: 3.7ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.8ms\n",
            "Speed: 3.2ms preprocess, 129.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.0ms\n",
            "Speed: 3.5ms preprocess, 136.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 147.2ms\n",
            "Speed: 6.7ms preprocess, 147.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.4ms\n",
            "Speed: 3.2ms preprocess, 132.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.4ms\n",
            "Speed: 3.7ms preprocess, 132.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.4ms\n",
            "Speed: 3.2ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.3ms\n",
            "Speed: 3.1ms preprocess, 131.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 137.0ms\n",
            "Speed: 5.2ms preprocess, 137.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.4ms\n",
            "Speed: 3.1ms preprocess, 138.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 149.4ms\n",
            "Speed: 4.2ms preprocess, 149.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 137.5ms\n",
            "Speed: 4.0ms preprocess, 137.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.8ms\n",
            "Speed: 3.5ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 128.8ms\n",
            "Speed: 4.4ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 138.6ms\n",
            "Speed: 3.0ms preprocess, 138.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 149.9ms\n",
            "Speed: 3.3ms preprocess, 149.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 214.3ms\n",
            "Speed: 3.2ms preprocess, 214.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 209.3ms\n",
            "Speed: 3.1ms preprocess, 209.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 198.7ms\n",
            "Speed: 3.8ms preprocess, 198.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 206.9ms\n",
            "Speed: 3.1ms preprocess, 206.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 198.7ms\n",
            "Speed: 3.8ms preprocess, 198.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 224.9ms\n",
            "Speed: 3.7ms preprocess, 224.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 209.8ms\n",
            "Speed: 3.7ms preprocess, 209.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 203.8ms\n",
            "Speed: 3.2ms preprocess, 203.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 201.4ms\n",
            "Speed: 3.2ms preprocess, 201.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 196.9ms\n",
            "Speed: 4.8ms preprocess, 196.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 207.5ms\n",
            "Speed: 3.1ms preprocess, 207.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 200.5ms\n",
            "Speed: 3.2ms preprocess, 200.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 201.9ms\n",
            "Speed: 3.1ms preprocess, 201.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 206.8ms\n",
            "Speed: 3.0ms preprocess, 206.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 216.4ms\n",
            "Speed: 3.7ms preprocess, 216.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 214.7ms\n",
            "Speed: 3.3ms preprocess, 214.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 199.6ms\n",
            "Speed: 3.3ms preprocess, 199.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 133.7ms\n",
            "Speed: 3.3ms preprocess, 133.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 132.7ms\n",
            "Speed: 3.0ms preprocess, 132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 130.1ms\n",
            "Speed: 3.4ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.8ms\n",
            "Speed: 3.1ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 148.7ms\n",
            "Speed: 3.1ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.6ms\n",
            "Speed: 6.2ms preprocess, 128.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.5ms\n",
            "Speed: 3.2ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.7ms\n",
            "Speed: 3.7ms preprocess, 129.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.6ms\n",
            "Speed: 4.0ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.3ms\n",
            "Speed: 3.2ms preprocess, 135.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 163.3ms\n",
            "Speed: 3.8ms preprocess, 163.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 166.6ms\n",
            "Speed: 3.2ms preprocess, 166.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 162.7ms\n",
            "Speed: 4.1ms preprocess, 162.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 170.2ms\n",
            "Speed: 4.5ms preprocess, 170.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 162.4ms\n",
            "Speed: 4.7ms preprocess, 162.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 144.0ms\n",
            "Speed: 3.3ms preprocess, 144.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 157.7ms\n",
            "Speed: 3.6ms preprocess, 157.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 132.0ms\n",
            "Speed: 3.5ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.4ms\n",
            "Speed: 3.0ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 136.3ms\n",
            "Speed: 3.1ms preprocess, 136.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 133.2ms\n",
            "Speed: 3.0ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 136.9ms\n",
            "Speed: 3.4ms preprocess, 136.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.1ms\n",
            "Speed: 3.8ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 144.5ms\n",
            "Speed: 3.2ms preprocess, 144.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 137.0ms\n",
            "Speed: 3.2ms preprocess, 137.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 134.7ms\n",
            "Speed: 3.2ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.9ms\n",
            "Speed: 3.4ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.2ms\n",
            "Speed: 3.1ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.8ms\n",
            "Speed: 3.2ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.3ms\n",
            "Speed: 3.2ms preprocess, 138.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 150.6ms\n",
            "Speed: 3.5ms preprocess, 150.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.7ms\n",
            "Speed: 4.2ms preprocess, 130.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.6ms\n",
            "Speed: 3.3ms preprocess, 132.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.4ms\n",
            "Speed: 3.9ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.1ms\n",
            "Speed: 3.4ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.6ms\n",
            "Speed: 3.2ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 126.8ms\n",
            "Speed: 2.9ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 157.2ms\n",
            "Speed: 3.0ms preprocess, 157.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 132.4ms\n",
            "Speed: 4.0ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.8ms\n",
            "Speed: 3.2ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.4ms\n",
            "Speed: 3.3ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.0ms\n",
            "Speed: 3.5ms preprocess, 137.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 147.0ms\n",
            "Speed: 3.7ms preprocess, 147.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 126.1ms\n",
            "Speed: 5.2ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 153.3ms\n",
            "Speed: 3.2ms preprocess, 153.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.8ms\n",
            "Speed: 4.8ms preprocess, 141.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.7ms\n",
            "Speed: 4.0ms preprocess, 135.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.5ms\n",
            "Speed: 3.8ms preprocess, 132.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 134.6ms\n",
            "Speed: 4.5ms preprocess, 134.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 134.3ms\n",
            "Speed: 3.3ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.5ms\n",
            "Speed: 3.2ms preprocess, 137.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 155.0ms\n",
            "Speed: 3.2ms preprocess, 155.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.2ms\n",
            "Speed: 3.3ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.5ms\n",
            "Speed: 3.1ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.8ms\n",
            "Speed: 3.3ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.0ms\n",
            "Speed: 4.9ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 126.6ms\n",
            "Speed: 3.2ms preprocess, 126.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.1ms\n",
            "Speed: 3.8ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 151.2ms\n",
            "Speed: 4.8ms preprocess, 151.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.4ms\n",
            "Speed: 3.7ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.2ms\n",
            "Speed: 3.2ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.2ms\n",
            "Speed: 3.0ms preprocess, 138.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.2ms\n",
            "Speed: 3.7ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.4ms\n",
            "Speed: 4.6ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 139.4ms\n",
            "Speed: 3.6ms preprocess, 139.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 225.5ms\n",
            "Speed: 3.2ms preprocess, 225.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 198.0ms\n",
            "Speed: 3.3ms preprocess, 198.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 199.9ms\n",
            "Speed: 3.4ms preprocess, 199.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 194.7ms\n",
            "Speed: 3.3ms preprocess, 194.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 203.6ms\n",
            "Speed: 4.4ms preprocess, 203.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 205.1ms\n",
            "Speed: 3.0ms preprocess, 205.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 203.1ms\n",
            "Speed: 7.6ms preprocess, 203.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 199.6ms\n",
            "Speed: 3.9ms preprocess, 199.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 204.0ms\n",
            "Speed: 5.1ms preprocess, 204.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 203.9ms\n",
            "Speed: 3.6ms preprocess, 203.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 231.9ms\n",
            "Speed: 3.4ms preprocess, 231.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 233.3ms\n",
            "Speed: 7.8ms preprocess, 233.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 234.6ms\n",
            "Speed: 12.7ms preprocess, 234.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 232.4ms\n",
            "Speed: 6.2ms preprocess, 232.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 207.8ms\n",
            "Speed: 3.1ms preprocess, 207.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 truck, 207.9ms\n",
            "Speed: 3.0ms preprocess, 207.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 204.3ms\n",
            "Speed: 3.2ms preprocess, 204.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 152.1ms\n",
            "Speed: 3.3ms preprocess, 152.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.9ms\n",
            "Speed: 6.6ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 151.9ms\n",
            "Speed: 3.5ms preprocess, 151.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 139.6ms\n",
            "Speed: 3.0ms preprocess, 139.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.9ms\n",
            "Speed: 3.3ms preprocess, 130.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.6ms\n",
            "Speed: 4.1ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.9ms\n",
            "Speed: 4.3ms preprocess, 136.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.2ms\n",
            "Speed: 3.2ms preprocess, 137.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.3ms\n",
            "Speed: 3.9ms preprocess, 132.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 144.8ms\n",
            "Speed: 3.4ms preprocess, 144.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.0ms\n",
            "Speed: 2.5ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.6ms\n",
            "Speed: 3.2ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.5ms\n",
            "Speed: 5.0ms preprocess, 134.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 132.6ms\n",
            "Speed: 3.6ms preprocess, 132.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.7ms\n",
            "Speed: 3.7ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.3ms\n",
            "Speed: 3.1ms preprocess, 136.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 147.4ms\n",
            "Speed: 3.2ms preprocess, 147.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.9ms\n",
            "Speed: 3.4ms preprocess, 136.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.2ms\n",
            "Speed: 3.2ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.1ms\n",
            "Speed: 6.9ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.9ms\n",
            "Speed: 3.5ms preprocess, 133.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.9ms\n",
            "Speed: 2.9ms preprocess, 131.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 130.9ms\n",
            "Speed: 5.7ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 151.1ms\n",
            "Speed: 3.0ms preprocess, 151.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.8ms\n",
            "Speed: 2.9ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 131.8ms\n",
            "Speed: 3.2ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 136.3ms\n",
            "Speed: 3.1ms preprocess, 136.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.4ms\n",
            "Speed: 3.4ms preprocess, 135.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 138.1ms\n",
            "Speed: 3.2ms preprocess, 138.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 141.1ms\n",
            "Speed: 3.6ms preprocess, 141.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.3ms\n",
            "Speed: 3.6ms preprocess, 137.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.1ms\n",
            "Speed: 6.2ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.9ms\n",
            "Speed: 3.3ms preprocess, 133.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.9ms\n",
            "Speed: 3.0ms preprocess, 135.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.7ms\n",
            "Speed: 3.3ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.9ms\n",
            "Speed: 3.4ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 141.7ms\n",
            "Speed: 3.3ms preprocess, 141.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.5ms\n",
            "Speed: 2.9ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.7ms\n",
            "Speed: 4.8ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 128.3ms\n",
            "Speed: 3.1ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.0ms\n",
            "Speed: 5.1ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.9ms\n",
            "Speed: 3.2ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Test completed with rehearsal evaluation.\n",
            "Test Action Buffer: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Test Loss Buffer: [0.13543789088726044, 0.07207493484020233, 0.09289020299911499, 0.08881346136331558, 0.11617682129144669, 0.10864340513944626, 0.07182897627353668, 0.07961824536323547, 0.09887069463729858, 0.07232432812452316, 0.07217758148908615, 0.11602068692445755, 0.08805792033672333, 0.1606736034154892, 0.09874223917722702, 0.09577193111181259, 0.08281048387289047, 0.09279303252696991, 0.17691944539546967, 0.0750088095664978, 0.08968281000852585, 0.09690170735120773, 0.07027465105056763, 0.05242002755403519, 0.07123425602912903, 0.09477712213993073, 0.11447550356388092, 0.0913221538066864, 0.07130903750658035, 0.08386459201574326, 0.07101146876811981, 0.07411467283964157, 0.04969841614365578, 0.12422863394021988, 0.07470637559890747, 0.10469668358564377, 0.10424549132585526, 0.08330635726451874, 0.06751684099435806, 0.0987163782119751, 0.11917954683303833, 0.07911333441734314, 0.12657567858695984, 0.08936841040849686, 0.08779656887054443, 0.07639153301715851, 0.11238987743854523, 0.07069680094718933, 0.08783364295959473, 0.05054228752851486, 0.09899589419364929, 0.08254162967205048, 0.1303579956293106, 0.11635682731866837, 0.0736556276679039, 0.07772575318813324, 0.09369480609893799, 0.07567061483860016, 0.11345723271369934, 0.09099728614091873, 0.08259107172489166, 0.12124177068471909, 0.1128605306148529, 0.12203420698642731, 0.06815718114376068, 0.07539992779493332, 0.08275583386421204, 0.07827453315258026, 0.06249983608722687, 0.032233089208602905, 0.10780561715364456, 0.09696778655052185, 0.06527754664421082, 0.15789034962654114, 0.09855837374925613, 0.14194567501544952, 0.10941857099533081, 0.04301965981721878, 0.037543829530477524, 0.149281308054924, 0.09588711708784103, 0.13939152657985687, 0.06566211581230164, 0.11676639318466187, 0.08472009003162384, 0.07794419676065445, 0.09246188402175903, 0.11944879591464996, 0.0804050862789154, 0.05467456579208374, 0.05748782306909561, 0.08164993673563004, 0.06379199028015137, 0.07870932668447495, 0.10035281628370285, 0.1206403374671936, 0.047178395092487335, 0.09716076403856277, 0.05720124393701553, 0.10846727341413498, 0.15573787689208984, 0.063722625374794, 0.09513229131698608, 0.05593537539243698, 0.0706353709101677, 0.12512058019638062, 0.035748809576034546, 0.09484110027551651, 0.05217084661126137, 0.0902247503399849, 0.10616840422153473, 0.07150665670633316, 0.07522081583738327, 0.0689312070608139, 0.1381293684244156, 0.08637015521526337, 0.11694658547639847, 0.10542406886816025, 0.09956257045269012, 0.03807767480611801, 0.12213490158319473, 0.08213729411363602, 0.06818952411413193, 0.1057155579328537, 0.12660059332847595, 0.10168834030628204, 0.12172357738018036, 0.0871947705745697, 0.09413531422615051, 0.10109002143144608, 0.10231777280569077, 0.11662480980157852, 0.07903968542814255, 0.09096977114677429, 0.06787575781345367, 0.11602936685085297, 0.068334199488163, 0.10338882356882095, 0.10916617512702942, 0.12785156071186066, 0.12276320904493332, 0.11144758760929108, 0.1305789202451706, 0.07424329966306686, 0.08485077321529388, 0.13782548904418945, 0.0962299108505249, 0.11309480667114258, 0.08409974724054337, 0.11707207560539246, 0.05116841569542885, 0.06843893229961395, 0.10509644448757172, 0.06112002953886986, 0.15207219123840332, 0.08812575787305832, 0.11414104700088501, 0.09965305030345917, 0.10568548738956451, 0.09314928948879242, 0.04711806774139404, 0.10950493812561035, 0.09091093391180038, 0.0784812718629837, 0.09436548501253128, 0.06863772124052048, 0.11386382579803467, 0.06660204380750656, 0.11018059402704239, 0.12162043154239655, 0.07256388664245605, 0.05968252196907997, 0.07858208566904068, 0.0813988745212555, 0.1301191747188568, 0.06693307310342789, 0.11419346183538437, 0.09954487532377243, 0.09099867194890976, 0.05405527353286743, 0.09509944170713425, 0.11664396524429321, 0.08392655104398727, 0.050635579973459244, 0.08995258808135986, 0.11679692566394806, 0.06845295429229736, 0.0655364990234375, 0.050145287066698074, 0.10817070305347443, 0.06451036781072617, 0.10913264751434326, 0.0787656232714653, 0.08150655031204224, 0.05940669775009155, 0.06447640061378479, 0.06806324422359467, 0.08790520578622818, 0.06808196753263474, 0.0923445001244545, 0.10464988648891449, 0.05734272673726082, 0.0626816377043724, 0.10665924102067947, 0.069629967212677, 0.11999047547578812, 0.10472387075424194, 0.1406933218240738, 0.11639158427715302, 0.1036837249994278, 0.0913844183087349, 0.07972540706396103, 0.049645740538835526, 0.06584913283586502, 0.07639412581920624, 0.06610061973333359, 0.05514083430171013, 0.05757223814725876, 0.07950747758150101, 0.09629091620445251, 0.09843669086694717, 0.10056894272565842, 0.11728350818157196, 0.06577901542186737, 0.10111725330352783, 0.07771944999694824, 0.06959778070449829, 0.07569021731615067, 0.15091648697853088, 0.0652947947382927, 0.061515118926763535, 0.10106449574232101, 0.046722181141376495, 0.09098625183105469, 0.11000809073448181, 0.05915718525648117, 0.1197284534573555, 0.0467076450586319, 0.07173691689968109, 0.07594773173332214, 0.10623717308044434, 0.055397599935531616, 0.08341831713914871, 0.1350400447845459, 0.08226116001605988, 0.13429629802703857, 0.09676431864500046, 0.08042506873607635, 0.11471793055534363, 0.09440353512763977, 0.09527948498725891, 0.07964897900819778, 0.08464249968528748, 0.0972537249326706, 0.058789968490600586, 0.08000436425209045, 0.08630167692899704, 0.1436798870563507, 0.06788487732410431, 0.06914054602384567, 0.10244596004486084, 0.11993762850761414, 0.0699024647474289, 0.10298852622509003, 0.05650166794657707, 0.06954475492238998, 0.11006296426057816, 0.069673553109169, 0.07749974727630615, 0.11840555816888809, 0.16403205692768097, 0.099180668592453, 0.1117727980017662, 0.05487419292330742, 0.08320549875497818, 0.10895111411809921, 0.07719682157039642, 0.0923955887556076, 0.09067053347826004, 0.07047799974679947, 0.08477455377578735, 0.06589183956384659, 0.077518031001091, 0.12128747254610062, 0.07806427031755447, 0.1291877031326294, 0.07871599495410919, 0.10005611181259155, 0.088454969227314, 0.10198929905891418, 0.1331806629896164, 0.060432009398937225, 0.0828636884689331, 0.14477477967739105, 0.07962533086538315, 0.09839985519647598, 0.1163322776556015, 0.072875015437603, 0.10245895385742188, 0.11032833158969879, 0.11395378410816193, 0.08152938634157181, 0.09215249121189117, 0.06422702223062515, 0.037073783576488495, 0.09667222201824188, 0.05588189512491226, 0.09932401776313782, 0.0540347620844841, 0.07126922905445099, 0.07836835831403732, 0.04572448506951332, 0.14888903498649597, 0.08997833728790283, 0.0710475891828537, 0.08213844895362854, 0.06217152997851372, 0.0871567651629448, 0.11581273376941681, 0.07835958153009415, 0.09096192568540573, 0.11633151769638062, 0.11127909272909164, 0.06477972120046616, 0.07080898433923721, 0.1575114130973816, 0.10611439496278763, 0.06835830956697464, 0.10227054357528687, 0.06992504745721817, 0.08397436141967773, 0.08283079415559769, 0.06780509650707245, 0.11271441727876663, 0.12768450379371643, 0.1101425513625145, 0.048030730336904526, 0.10862277448177338, 0.08669652789831161, 0.0712217465043068, 0.10748685896396637, 0.11732462048530579, 0.14442767202854156, 0.10826045274734497, 0.16027885675430298, 0.10913626849651337, 0.10594989359378815, 0.07888215035200119, 0.10707996040582657, 0.12583588063716888, 0.08910281211137772, 0.08315459638834, 0.09187247604131699, 0.08761156350374222, 0.1649893969297409, 0.0565907284617424, 0.057301804423332214, 0.045416928827762604, 0.12592381238937378, 0.1367240697145462, 0.08443275094032288, 0.09088751673698425, 0.10128217935562134, 0.09454071521759033, 0.09165920317173004, 0.0632975697517395, 0.10194438695907593, 0.0928475558757782, 0.0796484723687172, 0.08233058452606201, 0.11917317658662796, 0.0504751056432724, 0.10364516079425812, 0.0869351178407669, 0.057900067418813705, 0.073328897356987, 0.05902616307139397, 0.0963272824883461, 0.06007872521877289, 0.07454188913106918, 0.10861915349960327, 0.0702674612402916, 0.07921764254570007, 0.11355134844779968, 0.05693007633090019, 0.11279798299074173, 0.06288503110408783, 0.07854864746332169, 0.03760271519422531, 0.07044905424118042, 0.07754048705101013, 0.05327366292476654, 0.07418395578861237, 0.07139404863119125, 0.07589402794837952, 0.09176282584667206, 0.11958664655685425, 0.05495069548487663, 0.046719394624233246, 0.07383944094181061, 0.103169284760952, 0.10126183927059174, 0.054275982081890106, 0.06722500920295715, 0.15303701162338257, 0.08018368482589722, 0.0723683089017868, 0.09209592640399933, 0.12789808213710785, 0.07029140740633011, 0.05173593759536743, 0.06993342936038971, 0.0770529955625534, 0.05254856497049332, 0.07031102478504181, 0.09991082549095154, 0.050852589309215546, 0.08654049783945084, 0.07974199950695038, 0.04505499452352524, 0.0657782107591629, 0.07735084742307663, 0.11845213174819946, 0.08167616277933121, 0.060122448951005936, 0.10395742952823639, 0.09363353252410889, 0.14973172545433044, 0.07240942120552063, 0.11500611901283264, 0.09860190749168396, 0.10365237295627594, 0.06955624371767044, 0.0774724930524826, 0.10396093130111694, 0.09338980168104172, 0.06959271430969238, 0.057594213634729385, 0.1030312329530716, 0.08417989313602448, 0.05122717097401619, 0.10230407863855362, 0.06998599320650101, 0.12332174181938171, 0.10426753759384155, 0.10433583706617355, 0.1317434459924698, 0.08973892778158188, 0.1088341549038887, 0.0813232958316803, 0.1332184076309204, 0.09989771991968155, 0.06661004573106766, 0.062208227813243866, 0.05902925878763199, 0.08614859730005264, 0.09901349991559982, 0.08773517608642578, 0.10168429464101791, 0.09094859659671783, 0.09807943552732468, 0.08254663646221161, 0.11338739097118378, 0.12099334597587585, 0.04759053513407707, 0.1345006227493286, 0.06504228711128235, 0.08896009624004364, 0.08770700544118881, 0.10482900589704514, 0.06669476628303528, 0.14892266690731049, 0.06902743130922318, 0.07217399030923843, 0.10074970126152039, 0.0921722799539566, 0.07515009492635727, 0.0964459478855133, 0.08012045919895172, 0.07860351353883743, 0.09224393218755722, 0.11875035613775253, 0.10446742177009583, 0.07188538461923599, 0.12050971388816833, 0.09125512093305588, 0.1261582225561142, 0.08304349333047867, 0.10692582279443741, 0.06810452044010162, 0.07591813802719116, 0.09175503998994827, 0.09133362770080566, 0.06787940114736557, 0.07712645083665848, 0.061161108314991, 0.0514042042195797, 0.08366838842630386, 0.07591370493173599, 0.08077307790517807, 0.0768042504787445, 0.07987183332443237, 0.07834035158157349, 0.10897756367921829, 0.10898400098085403, 0.14233216643333435, 0.11023592948913574, 0.07680704444646835, 0.11336762458086014, 0.11835931241512299, 0.08430074900388718, 0.08929882943630219, 0.12055977433919907, 0.03472965955734253, 0.07912734895944595, 0.03770727664232254, 0.07469213008880615, 0.10370045900344849, 0.09546194225549698, 0.0551324188709259, 0.09415595233440399, 0.06155054643750191, 0.08904094249010086, 0.06390303373336792, 0.08582896739244461, 0.1495577096939087, 0.09765694290399551, 0.09454387426376343, 0.08788016438484192, 0.057366449385881424, 0.08770264685153961, 0.10135027766227722, 0.10570631921291351, 0.10617921501398087, 0.08055389672517776, 0.06572191417217255, 0.09906293451786041, 0.06096377968788147, 0.07327558100223541, 0.18347889184951782, 0.053784266114234924, 0.06562232226133347, 0.07190956175327301, 0.10655062645673752, 0.0685693770647049, 0.05795605480670929, 0.10291706025600433, 0.08388680964708328, 0.0918678492307663, 0.05778313800692558, 0.06212190166115761, 0.08994896709918976, 0.07834519445896149, 0.09247173368930817, 0.09699402749538422, 0.08582224696874619, 0.07697884738445282, 0.11599361151456833, 0.07948790490627289, 0.0900612622499466, 0.08808562159538269, 0.0674600750207901, 0.07071604579687119, 0.061429865658283234, 0.14213865995407104, 0.10390150547027588, 0.07225947082042694, 0.06762540340423584, 0.07107766717672348, 0.11008848994970322, 0.09171389788389206, 0.08704609423875809, 0.07219408452510834, 0.0599835179746151, 0.0807114765048027, 0.10273664444684982, 0.08530166000127792, 0.06428757309913635, 0.10150422900915146, 0.0755903422832489, 0.07726068794727325, 0.058101411908864975, 0.13201259076595306, 0.13468341529369354, 0.11259506642818451, 0.14775647222995758, 0.0919913649559021, 0.08427520841360092, 0.06746815145015717, 0.07573329657316208, 0.09294404089450836, 0.06084228307008743, 0.10767143219709396, 0.05857805907726288, 0.07547731697559357, 0.10608889907598495, 0.08940713107585907, 0.06195276230573654, 0.06508582830429077, 0.0818486362695694, 0.07250532507896423, 0.094631128013134, 0.08103737235069275, 0.05652894824743271, 0.09841534495353699, 0.08458102494478226, 0.04405633360147476, 0.07367616891860962, 0.058369070291519165, 0.06834249198436737, 0.14122770726680756, 0.05019862949848175, 0.08593032509088516, 0.13242366909980774, 0.10441121459007263, 0.034220900386571884, 0.08264508843421936, 0.12236206233501434, 0.07552166283130646, 0.07786175608634949, 0.0872257798910141, 0.10242791473865509, 0.11038902401924133, 0.08499415218830109, 0.08807806670665741, 0.14154481887817383, 0.06441505253314972, 0.09128118306398392, 0.11588163673877716]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 라벨 설정\n",
        "test_frame_labels = driving12['go_stop_decision'] # 여기에 driving12, truck8, uturn7을 값을 바꿔가며 넣기"
      ],
      "metadata": {
        "id": "yamXtMCVKfnH"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 타입 및 길이 확인\n",
        "print(type(test_action_buffer))\n",
        "print(type(test_frame_labels))\n",
        "print(len(test_action_buffer))\n",
        "print(len(test_frame_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtJ28TZ-Kh1G",
        "outputId": "f745c03e-b1cf-4ca0-b667-4bc719cb0b20"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "369\n",
            "369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과 저장\n",
        "final_tasks.append(test_action_buffer)\n",
        "final_labels.append(test_frame_labels)"
      ],
      "metadata": {
        "id": "35S5aTrtKl3C"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CL 메트릭 계산\n",
        "IM, FWT, BWT = compute_cl_metrics(final_tasks, final_labels)\n",
        "\n",
        "print(f\"IM (Initial Accuracy): {IM:.5f}\")\n",
        "print(f\"FWT (Forward Transfer): {FWT:.5f}\")\n",
        "print(f\"BWT (Backward Transfer): {BWT:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnhJXkJjKoKW",
        "outputId": "d2c09871-d722-407d-a531-e25b28734033"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task accuracies: [    0.65041]\n",
            "IM (Initial Accuracy): 0.65041\n",
            "FWT (Forward Transfer): 0.00000\n",
            "BWT (Backward Transfer): 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rehearsal 메모리 상태 확인\n",
        "print(f\"Rehearsal memory contains {len(rehearsal_memory.data_buffer)} samples\")\n",
        "print(f\"Memory usage: {len(rehearsal_memory.data_buffer)} / {rehearsal_memory.max_samples}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqYXoVGHKuzF",
        "outputId": "a35159f2-df58-4e4d-eaac-97c3acb34128"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rehearsal memory contains 724 samples\n",
            "Memory usage: 724 / 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 샘플의 일부 확인\n",
        "if len(rehearsal_memory.data_buffer) > 0:\n",
        "    sample_data = rehearsal_memory.data_buffer[0]\n",
        "    sample_label = rehearsal_memory.label_buffer[0]\n",
        "    print(f\"Sample data shape: {sample_data.shape}\")\n",
        "    print(f\"Sample label: {sample_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAWd4cKMKwBY",
        "outputId": "0ada5aac-6de8-4371-e679-136e7d4fce1b"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data shape: (15,)\n",
            "Sample label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_tasks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vg2EpXiYYtm",
        "outputId": "b9b293b2-2f7a-47b8-e3ca-fd7c39058e01"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task2 학습"
      ],
      "metadata": {
        "id": "ZdBq-voDalww"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## towtruck 9 학습 (라벨 미포함)"
      ],
      "metadata": {
        "id": "al15wrJOdn0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "train_video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "A8qUO-3payEC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "5c318b98-9846-4855-acb7-2f2e60be94fd"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1e333a74-4afd-4085-ad91-6be619fb3db4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1e333a74-4afd-4085-ad91-6be619fb3db4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving towtruck_seperation_9.mov to towtruck_seperation_9 (1).mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 모드 설정\n",
        "fm_model.train()\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "tKO3rYNV2uBm"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 세 번째 태스크 학습 (rehearsal 방식) =====\n",
        "cap = cv2.VideoCapture(train_video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "new_task_data = []\n",
        "new_task_labels = []\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_idx += 1\n",
        "    step += 1\n",
        "\n",
        "    result = model(frame)[0]\n",
        "    h, w, _ = frame.shape\n",
        "    frame_actions = []\n",
        "\n",
        "    for box in result.boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        conf = float(box.conf[0])\n",
        "        if conf <= 0.6:\n",
        "            continue\n",
        "        else:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 노이즈에 대한 일관성 손실\n",
        "            consistency_loss = loss_fn(emb_noisy, emb_orig.detach())\n",
        "\n",
        "            # Rehearsal 손실: 이전 태스크 데이터와 함께 학습\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                # 이전 태스크 데이터에 대한 예측\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            # 총 손실 = 일관성 손실 + rehearsal 손실\n",
        "            total_loss = consistency_loss + 0.5 * rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                loss_buffer.append(total_loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 새로운 태스크 데이터 저장 (numpy 배열로 변환)\n",
        "            new_task_data.append(x.detach().cpu().numpy().squeeze(0))\n",
        "            # 라벨이 없으므로 예측값을 pseudo-label로 사용\n",
        "            new_task_labels.append(y_pred.detach().cpu().numpy().squeeze(0))\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "    final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "    if measuring_loss:\n",
        "        action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# 새로운 태스크 데이터를 rehearsal 메모리에 추가\n",
        "rehearsal_memory.add_samples(new_task_data, new_task_labels)\n",
        "\n",
        "print(\"Second task completed with rehearsal learning.\")\n",
        "print(\"Rehearsal Action Buffer:\", action_buffer)\n",
        "print(\"Loss Buffer:\", loss_buffer)\n",
        "print(f\"Rehearsal memory size: {len(rehearsal_memory.data_buffer)}\")\n"
      ],
      "metadata": {
        "id": "jOcz_objdtk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af60bff3-5090-478c-a292-8a912ec51ed0"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 cars, 1 truck, 218.5ms\n",
            "Speed: 4.6ms preprocess, 218.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 203.7ms\n",
            "Speed: 8.9ms preprocess, 203.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 246.6ms\n",
            "Speed: 4.4ms preprocess, 246.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 203.0ms\n",
            "Speed: 5.8ms preprocess, 203.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 202.2ms\n",
            "Speed: 7.7ms preprocess, 202.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 207.9ms\n",
            "Speed: 10.5ms preprocess, 207.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 224.2ms\n",
            "Speed: 4.3ms preprocess, 224.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 217.6ms\n",
            "Speed: 4.4ms preprocess, 217.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 206.1ms\n",
            "Speed: 4.4ms preprocess, 206.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 195.6ms\n",
            "Speed: 4.3ms preprocess, 195.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 208.3ms\n",
            "Speed: 4.2ms preprocess, 208.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 216.2ms\n",
            "Speed: 4.6ms preprocess, 216.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 208.3ms\n",
            "Speed: 9.4ms preprocess, 208.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 227.0ms\n",
            "Speed: 8.0ms preprocess, 227.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 268.1ms\n",
            "Speed: 5.6ms preprocess, 268.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 202.9ms\n",
            "Speed: 7.3ms preprocess, 202.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 166.3ms\n",
            "Speed: 6.0ms preprocess, 166.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 163.2ms\n",
            "Speed: 5.9ms preprocess, 163.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 139.5ms\n",
            "Speed: 5.3ms preprocess, 139.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 138.4ms\n",
            "Speed: 4.2ms preprocess, 138.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 148.8ms\n",
            "Speed: 4.3ms preprocess, 148.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 138.1ms\n",
            "Speed: 4.4ms preprocess, 138.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 134.4ms\n",
            "Speed: 4.3ms preprocess, 134.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 135.4ms\n",
            "Speed: 4.4ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 143.1ms\n",
            "Speed: 4.3ms preprocess, 143.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 134.0ms\n",
            "Speed: 4.4ms preprocess, 134.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 136.8ms\n",
            "Speed: 4.1ms preprocess, 136.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 156.9ms\n",
            "Speed: 4.9ms preprocess, 156.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.0ms\n",
            "Speed: 4.1ms preprocess, 136.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.5ms\n",
            "Speed: 4.6ms preprocess, 133.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 139.0ms\n",
            "Speed: 4.1ms preprocess, 139.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.4ms\n",
            "Speed: 4.9ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.8ms\n",
            "Speed: 4.5ms preprocess, 133.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 151.9ms\n",
            "Speed: 5.2ms preprocess, 151.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 132.2ms\n",
            "Speed: 4.2ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.4ms\n",
            "Speed: 4.5ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.9ms\n",
            "Speed: 4.9ms preprocess, 134.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 138.4ms\n",
            "Speed: 6.0ms preprocess, 138.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 139.4ms\n",
            "Speed: 4.6ms preprocess, 139.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 150.1ms\n",
            "Speed: 4.7ms preprocess, 150.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.6ms\n",
            "Speed: 4.7ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 134.3ms\n",
            "Speed: 4.6ms preprocess, 134.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 134.6ms\n",
            "Speed: 4.5ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 135.5ms\n",
            "Speed: 4.5ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 2 trucks, 143.9ms\n",
            "Speed: 4.2ms preprocess, 143.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 139.4ms\n",
            "Speed: 4.3ms preprocess, 139.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 156.2ms\n",
            "Speed: 10.2ms preprocess, 156.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 139.9ms\n",
            "Speed: 4.2ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 136.4ms\n",
            "Speed: 4.2ms preprocess, 136.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 138.8ms\n",
            "Speed: 4.8ms preprocess, 138.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 140.5ms\n",
            "Speed: 4.1ms preprocess, 140.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.6ms\n",
            "Speed: 4.3ms preprocess, 135.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 149.3ms\n",
            "Speed: 5.2ms preprocess, 149.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.0ms\n",
            "Speed: 4.1ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.7ms\n",
            "Speed: 4.0ms preprocess, 135.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 138.3ms\n",
            "Speed: 4.0ms preprocess, 138.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 138.8ms\n",
            "Speed: 4.1ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 138.5ms\n",
            "Speed: 4.1ms preprocess, 138.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 154.1ms\n",
            "Speed: 4.0ms preprocess, 154.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 130.5ms\n",
            "Speed: 4.6ms preprocess, 130.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 129.9ms\n",
            "Speed: 4.5ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 132.8ms\n",
            "Speed: 4.7ms preprocess, 132.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 2 trucks, 132.4ms\n",
            "Speed: 4.5ms preprocess, 132.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.3ms\n",
            "Speed: 4.5ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 132.0ms\n",
            "Speed: 4.1ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 148.4ms\n",
            "Speed: 4.1ms preprocess, 148.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.3ms\n",
            "Speed: 4.0ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.8ms\n",
            "Speed: 4.1ms preprocess, 134.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.0ms\n",
            "Speed: 4.0ms preprocess, 136.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.3ms\n",
            "Speed: 4.4ms preprocess, 135.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 133.6ms\n",
            "Speed: 4.1ms preprocess, 133.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 151.4ms\n",
            "Speed: 4.1ms preprocess, 151.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.5ms\n",
            "Speed: 4.3ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 176.7ms\n",
            "Speed: 4.2ms preprocess, 176.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 183.3ms\n",
            "Speed: 5.6ms preprocess, 183.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 246.0ms\n",
            "Speed: 5.9ms preprocess, 246.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 bus, 245.7ms\n",
            "Speed: 7.0ms preprocess, 245.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 226.0ms\n",
            "Speed: 5.1ms preprocess, 226.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 197.6ms\n",
            "Speed: 6.2ms preprocess, 197.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 203.6ms\n",
            "Speed: 8.5ms preprocess, 203.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 211.3ms\n",
            "Speed: 6.3ms preprocess, 211.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 218.6ms\n",
            "Speed: 4.5ms preprocess, 218.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 206.4ms\n",
            "Speed: 5.8ms preprocess, 206.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 211.0ms\n",
            "Speed: 5.3ms preprocess, 211.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 202.7ms\n",
            "Speed: 5.4ms preprocess, 202.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 216.3ms\n",
            "Speed: 7.9ms preprocess, 216.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 202.1ms\n",
            "Speed: 5.3ms preprocess, 202.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 199.5ms\n",
            "Speed: 10.4ms preprocess, 199.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 218.2ms\n",
            "Speed: 6.2ms preprocess, 218.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 231.1ms\n",
            "Speed: 4.4ms preprocess, 231.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 214.0ms\n",
            "Speed: 7.3ms preprocess, 214.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 217.9ms\n",
            "Speed: 4.4ms preprocess, 217.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.8ms\n",
            "Speed: 4.5ms preprocess, 134.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.6ms\n",
            "Speed: 4.2ms preprocess, 136.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 suitcase, 135.5ms\n",
            "Speed: 4.3ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 suitcase, 157.4ms\n",
            "Speed: 4.2ms preprocess, 157.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 suitcase, 133.3ms\n",
            "Speed: 4.5ms preprocess, 133.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 suitcase, 136.1ms\n",
            "Speed: 5.8ms preprocess, 136.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.3ms\n",
            "Speed: 4.5ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.9ms\n",
            "Speed: 4.6ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.0ms\n",
            "Speed: 4.5ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 152.5ms\n",
            "Speed: 4.6ms preprocess, 152.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 138.1ms\n",
            "Speed: 4.2ms preprocess, 138.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.2ms\n",
            "Speed: 4.5ms preprocess, 130.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.8ms\n",
            "Speed: 4.7ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.8ms\n",
            "Speed: 4.7ms preprocess, 136.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 137.5ms\n",
            "Speed: 4.6ms preprocess, 137.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 139.6ms\n",
            "Speed: 4.4ms preprocess, 139.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 156.9ms\n",
            "Speed: 4.2ms preprocess, 156.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 150.1ms\n",
            "Speed: 4.3ms preprocess, 150.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 164.0ms\n",
            "Speed: 5.1ms preprocess, 164.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 163.2ms\n",
            "Speed: 5.5ms preprocess, 163.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 173.9ms\n",
            "Speed: 5.4ms preprocess, 173.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 174.3ms\n",
            "Speed: 5.5ms preprocess, 174.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 156.1ms\n",
            "Speed: 5.7ms preprocess, 156.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 128.6ms\n",
            "Speed: 4.5ms preprocess, 128.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 131.9ms\n",
            "Speed: 4.6ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 133.3ms\n",
            "Speed: 4.7ms preprocess, 133.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 133.7ms\n",
            "Speed: 4.2ms preprocess, 133.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 137.6ms\n",
            "Speed: 4.2ms preprocess, 137.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 178.3ms\n",
            "Speed: 4.3ms preprocess, 178.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.8ms\n",
            "Speed: 4.5ms preprocess, 134.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.6ms\n",
            "Speed: 3.9ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.7ms\n",
            "Speed: 4.1ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.4ms\n",
            "Speed: 4.0ms preprocess, 132.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 129.5ms\n",
            "Speed: 4.3ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Second task completed with rehearsal learning.\n",
            "Rehearsal Action Buffer: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Loss Buffer: [0.21263432502746582, 0.25857076048851013, 0.3389688730239868, 0.24148285388946533, 0.18101570010185242, 0.17303767800331116, 0.21629910171031952, 0.327926903963089, 0.15108650922775269, 0.19588398933410645, 0.3217637836933136, 0.13185395300388336, 0.17466239631175995, 0.12004157900810242, 0.1605074107646942, 0.1496599018573761, 0.10582607984542847, 0.31011316180229187, 0.13200484216213226, 0.08914873003959656, 0.07929714024066925, 0.11793123185634613, 0.11131016910076141, 0.06602030247449875, 0.2961684763431549, 0.10017939656972885, 0.05605718865990639, 0.2888360917568207, 0.08985063433647156, 0.04968687519431114, 0.28346335887908936, 0.08256057649850845, 0.04435082897543907, 0.2786356806755066, 0.5282779335975647, 0.6243489980697632, 0.45248645544052124, 0.2246241420507431, 0.5407928228378296, 0.6071640849113464, 0.2240561693906784, 0.525640606880188, 0.5817229151725769, 0.22071881592273712, 0.5127175450325012, 0.5309697985649109, 0.5035403966903687, 0.47907567024230957, 0.21463197469711304, 0.4877597987651825, 0.4295162856578827, 0.21197138726711273, 0.46309390664100647, 0.3902970254421234, 0.20637038350105286, 0.43848568201065063, 0.3549475073814392, 0.20304694771766663, 0.3248615264892578, 0.40189290046691895, 0.19866417348384857, 0.3838198781013489, 0.28934571146965027, 0.191949725151062, 0.2728714048862457, 0.3500130772590637, 0.18717913329601288, 0.2551894187927246, 0.3236665427684784, 0.24020400643348694, 0.30596035718917847, 0.2969124913215637, 0.2235306054353714, 0.2813332676887512, 0.21448826789855957, 0.2667844295501709, 0.20458370447158813, 0.2501380741596222, 0.19601933658123016, 0.23381629586219788, 0.18824562430381775, 0.21810051798820496, 0.18069525063037872, 0.2033621221780777, 0.17484621703624725, 0.18997807800769806, 0.16823790967464447, 0.17856153845787048, 0.16292642056941986, 0.16816624999046326, 0.15835003554821014, 0.15875695645809174, 0.1533978134393692, 0.15007047355175018, 0.14913393557071686, 0.3803260624408722, 0.39290180802345276, 0.1375759243965149, 0.1436200886964798, 0.13397051393985748, 0.14184710383415222, 0.1300356090068817, 0.13860797882080078, 0.13828809559345245, 0.12435772269964218, 0.13575366139411926, 0.1218138188123703, 0.1329548954963684, 0.11813785135746002, 0.1296181082725525, 0.11466033011674881, 0.1264861524105072, 0.11303630471229553, 0.11311408132314682, 0.12928465008735657, 0.1197737604379654, 0.11956228315830231, 0.1086202934384346, 0.11710980534553528, 0.10802481323480606, 0.1236671656370163, 0.12265624105930328, 0.11309942603111267, 0.11300565302371979, 0.11204167455434799, 0.11794809997081757, 0.10965733230113983, 0.10980161279439926, 0.11545498669147491, 0.11582670360803604, 0.11362101137638092, 0.1056218072772026, 0.1121121197938919, 0.11423957347869873, 0.10288633406162262, 0.11034805327653885, 0.11375993490219116, 0.10022664070129395, 0.10807424038648605, 0.09842859208583832, 0.10689550638198853, 0.11354035139083862, 0.09607022255659103, 0.10476168990135193, 0.0942973792552948, 0.10372903198003769, 0.09221991151571274, 0.10357578098773956, 0.09060703217983246, 0.08909044414758682, 0.08784205466508865, 0.09705337136983871, 0.09520046412944794, 0.08507855981588364, 0.08403560519218445, 0.09172356873750687, 0.08309949189424515, 0.08068136125802994, 0.08452340960502625, 0.07707889378070831, 0.07531324774026871, 0.07415373623371124, 0.06165207922458649, 0.5704616904258728, 0.06696801632642746, 0.06453963369131088, 0.06255749613046646, 0.06139019876718521, 0.06061330810189247, 0.06754345446825027, 0.06629858911037445, 0.05493536219000816, 0.053147539496421814, 0.06170259416103363, 0.05066141486167908, 0.05909543111920357, 0.04863835871219635, 0.046531349420547485, 0.04497896134853363, 0.06649253517389297, 0.04254910349845886, 0.04965412616729736, 0.03984031826257706, 0.08217434585094452, 0.03771507740020752, 0.08513904362916946, 0.03551868349313736, 0.08658719807863235, 0.04427154362201691, 0.08727657794952393, 0.03203766047954559, 0.030387263745069504, 0.029246091842651367, 0.02825031243264675, 0.02709348313510418, 0.02646121382713318, 0.026475870981812477, 0.026547959074378014, 0.06739199161529541, 0.026025135070085526, 0.06532490998506546, 0.02565206028521061, 0.02571115829050541, 0.0627390444278717, 0.02414243295788765, 0.030895618721842766, 0.03004639223217964, 0.030375640839338303, 0.03089260123670101, 0.023949652910232544, 0.030075211077928543, 0.023379778489470482, 0.022855395451188087, 0.021654509007930756, 0.021268831565976143, 0.01990215852856636, 0.019134795293211937, 0.0183523241430521, 0.017134854570031166, 0.016421977430582047, 0.015244731679558754, 0.01448195893317461, 0.013987403362989426, 0.013385282829403877, 0.012636343948543072, 0.011435162276029587, 0.010896285995841026, 0.012606993317604065, 0.009997877292335033, 0.009502746164798737, 0.008673567324876785, 0.00830660667270422, 0.00757718225941062, 0.006963944528251886, 0.007946529425680637, 0.0062958174385130405, 0.007263263687491417, 0.006392709445208311, 0.0060665784403681755, 0.005266112741082907, 0.0047412752173841, 0.8725939989089966, 0.8837761282920837, 0.8857192993164062, 0.8879403471946716, 0.889151930809021, 0.894506573677063, 0.8925232291221619, 0.8922939300537109, 0.8926197290420532, 0.8874508142471313, 0.8835626840591431, 0.8814855813980103, 0.8757755160331726, 0.8757005929946899, 0.8665307760238647, 0.8551257252693176, 0.8454599380493164, 0.8347617387771606, 0.8219482898712158, 0.8068317770957947, 0.7907668948173523, 0.7717898488044739, 0.7506366968154907, 0.7282410860061646, 0.7037431001663208, 0.6769790649414062, 0.6473711729049683, 0.6156364679336548, 0.5810166597366333, 0.5438334941864014, 0.505216121673584, 0.4641435444355011, 0.4224313497543335, 0.38036319613456726, 0.33912575244903564, 0.2981168329715729, 0.25914058089256287, 0.2239052653312683, 0.26827511191368103, 0.16200250387191772, 0.13822795450687408, 0.11585456877946854, 0.09838703274726868, 0.0822964608669281, 0.0686635971069336, 0.05810470134019852, 0.04970395565032959, 0.04251781851053238, 0.06733623892068863, 0.030451511964201927, 0.04991564899682999, 0.02294079214334488, 0.03875613957643509, 0.01760311983525753, 0.031265102326869965, 0.013618161901831627, 0.026378871873021126, 0.01153454277664423, 0.022140467539429665, 0.009151442907750607, 0.018772920593619347, 0.007919611409306526, 0.01603025197982788, 0.006427675485610962, 0.00492611899971962, 0.011203156784176826, 0.00898811500519514, 0.004133753944188356, 0.0049295127391815186, 0.009955145418643951, 0.014524949714541435, 0.006653268355876207, 0.019949711859226227, 0.014257258735597134, 0.017940636724233627, 0.03719994053244591, 0.6153067946434021, 0.5639525651931763, 0.5137622356414795, 0.47006282210350037, 0.4296417236328125, 0.5529211163520813, 0.38504043221473694, 0.34566086530685425, 0.32827243208885193, 0.3113107979297638, 0.2962275445461273, 0.2851378321647644, 0.2717738747596741, 0.1571742296218872, 0.25263917446136475, 0.24185915291309357, 0.14908280968666077, 0.22661463916301727, 0.1440013200044632, 0.20822358131408691, 0.13950222730636597, 0.19782137870788574, 0.19225680828094482, 0.18720291554927826, 0.1800668090581894, 0.17611846327781677, 0.17398297786712646, 0.17154556512832642, 0.16880744695663452, 0.16630437970161438, 0.16422878205776215, 0.16162990033626556, 0.159407839179039, 0.16023613512516022, 0.19426938891410828, 0.1541980504989624, 0.18988190591335297, 0.1495572328567505, 0.14711792767047882, 0.1448511928319931, 0.38263094425201416, 0.13968676328659058, 0.13711993396282196, 0.13557587563991547, 0.1334105134010315, 0.13245905935764313, 0.1311711072921753, 0.13087725639343262, 0.13101975619792938, 0.23807398974895477, 0.12570077180862427, 0.2332979440689087, 0.1209041029214859, 0.22422710061073303, 0.21915051341056824, 0.21645595133304596, 0.218618705868721, 0.14521969854831696, 0.21264703571796417, 0.10865865647792816, 0.13524377346038818, 0.1324838250875473, 0.10012808442115784, 0.1859426647424698, 0.0966501384973526, 0.09273813664913177, 0.09257148206233978, 0.17843341827392578, 0.08809170126914978, 0.08657700568437576, 0.16834840178489685, 0.08361701667308807, 0.1571682095527649, 0.07703348249197006, 0.07500843703746796, 0.1470731645822525, 0.0676218569278717, 0.06561630964279175, 0.12972700595855713, 0.12738515436649323, 0.06040961667895317, 0.11735252290964127, 0.05473588407039642, 0.10695195198059082, 0.048304036259651184, 0.10087659955024719, 0.04425884410738945, 0.49513790011405945, 0.6408843398094177, 0.5050345063209534, 0.6412843465805054, 0.5110008120536804, 0.6362613439559937, 0.49208322167396545, 0.6322436928749084, 0.6178907155990601, 0.45595207810401917, 0.4421848654747009, 0.5625085234642029, 0.39282840490341187, 0.5127180218696594, 0.3307693600654602, 0.4465197026729584, 0.2775351107120514, 0.35994186997413635, 0.18566085398197174, 0.15418197214603424, 0.2507210075855255, 0.1989697813987732, 0.08183512836694717, 0.12806767225265503, 0.08021669089794159, 0.035191815346479416, 0.023074351251125336, 0.018517853692173958, 0.03802109882235527, 0.03155244141817093, 0.009486515074968338, 0.021362828090786934, 0.007203019689768553, 0.0136100510135293, 0.004335638601332903, 0.00998509582132101, 0.0034332526847720146, 0.007815038785338402, 0.0034297583624720573, 0.0059684221632778645, 0.0019561592489480972, 0.004947832319885492, 0.0015204483643174171, 0.0041352822445333, 0.001340672723017633, 0.003974607214331627, 0.001702778972685337, 0.003805719083175063, 0.0011890631867572665, 0.003753846511244774, 0.0012631481513381004, 0.0031215378548949957, 0.0010412184055894613, 0.0028135336469858885, 0.0012426862958818674, 0.0035149119794368744, 0.0020991098135709763, 0.0031435564160346985, 0.0028347678016871214, 0.0014076782390475273, 0.0025342244189232588, 0.0026679043658077717, 0.0010597024811431766, 0.002441014861688018, 0.0018673159647732973, 0.002687574364244938, 0.0008755985181778669, 0.0024427827447652817, 0.0009707739809527993, 0.002541830064728856, 0.0008521932177245617, 0.002254252089187503, 0.0010070926509797573, 0.00095107447123155, 0.00235337414778769, 0.0009529558010399342, 0.002446497557684779, 0.002618433441966772, 0.0008769360720179975, 0.0022557415068149567, 0.0007617274532094598, 0.002362098777666688, 0.0009295072522945702, 0.0022053259890526533, 0.0010685035958886147, 0.002095886506140232, 0.0020893013570457697, 0.000878767401445657, 0.002118564210832119, 0.0013967951526865363, 0.0021825777366757393, 0.0008883225964382291, 0.0022871308028697968, 0.0007126852869987488, 0.002281023422256112, 0.0007434422732330859, 0.001938311499543488, 0.0007732420926913619, 0.0020199003629386425, 0.0010793134570121765, 0.0017611890798434615, 0.0010249648476019502, 0.000926762935705483, 0.0017114535439759493, 0.07382987439632416, 0.08565075695514679, 0.11153233051300049, 0.09206820279359818, 0.05875307694077492, 0.12180664390325546, 0.15153047442436218, 0.06783819198608398, 0.0819883644580841, 0.07586593925952911, 0.08638586103916168, 0.10365532338619232, 0.08040815591812134, 0.07392024993896484, 0.08732450753450394, 0.0929948166012764, 0.07827784866094589, 0.08196781575679779, 0.1129530817270279, 0.06170062720775604, 0.10747218132019043, 0.08531614392995834, 0.09292465448379517, 0.06600382924079895, 0.09917885065078735, 0.09205905348062515, 0.09045646339654922, 0.08420857042074203, 0.09807056933641434, 0.090894415974617, 0.04860890656709671, 0.08824321627616882, 0.059087157249450684, 0.10142400860786438, 0.06575673818588257, 0.07299204915761948, 0.09506894648075104, 0.08791296929121017, 0.09587200731039047, 0.06509885936975479, 0.07389731705188751, 0.06991849094629288, 0.06474688649177551, 0.0746384784579277, 0.08105485886335373, 0.08658289164304733, 0.04118048772215843, 0.08258655667304993, 0.07562024891376495, 0.10131516307592392, 0.07860688120126724, 0.07078942656517029, 0.07835042476654053, 0.08447305858135223, 0.06332330405712128, 0.053875960409641266, 0.08252338320016861, 0.07010260969400406, 0.07853631675243378, 0.0860101655125618, 0.10655520111322403, 0.07402264326810837, 0.06972341984510422, 0.08989569544792175, 0.05478101596236229, 0.08871133625507355, 0.059398334473371506, 0.07355879247188568, 0.08109065145254135, 0.0836954265832901, 0.05394695699214935, 0.04103505238890648, 0.09032099694013596, 0.06571539491415024, 0.06808245927095413, 0.07905525714159012, 0.05261966958642006, 0.05350274220108986, 0.07311117649078369, 0.07018838822841644, 0.06635834276676178, 0.10045550018548965, 0.06198643893003464, 0.07432428747415543, 0.05391479283571243, 0.06310463696718216, 0.08962047100067139, 0.06882986426353455, 0.06696227937936783, 0.07497619837522507, 0.07156987488269806, 0.059260040521621704, 0.08112076669931412, 0.09640555828809738, 0.07075833529233932, 0.0878162682056427, 0.058991335332393646, 0.07778776437044144, 0.05793927237391472, 0.07437529414892197, 0.08653362840414047, 0.07288046181201935, 0.06138358637690544, 0.08531519025564194, 0.05083426088094711, 0.07168123126029968, 0.05348491296172142, 0.05544203892350197, 0.0514569915831089, 0.06524624675512314, 0.0698089450597763, 0.08542045950889587, 0.06781019270420074, 0.10970263183116913, 0.06673291325569153, 0.057979147881269455, 0.07838255167007446, 0.06400766968727112, 0.07216216623783112, 0.06124001741409302, 0.07071494311094284, 0.06773309409618378, 0.09380816668272018, 0.08222710341215134, 0.06462334841489792, 0.06317776441574097, 0.07835885882377625, 0.055371832102537155, 0.0692749097943306, 0.0655284970998764, 0.05829291790723801, 0.07565616816282272, 0.06612814217805862, 0.07314693927764893, 0.04461490735411644, 0.07177578657865524, 0.08269113302230835, 0.07109421491622925, 0.06284447759389877, 0.07383115589618683, 0.08136064559221268, 0.07854417711496353, 0.057203508913517, 0.08590790629386902, 0.06735020875930786, 0.09182114154100418, 0.09787014126777649, 0.0691026896238327, 0.08300014585256577, 0.06386934965848923, 0.061209701001644135, 0.08452817052602768, 0.0863148644566536, 0.07193280011415482, 0.0712895542383194, 0.05561874806880951, 0.06396528333425522, 0.06443124264478683, 0.07282407581806183, 0.09784086793661118, 0.05526275187730789, 0.08276346325874329, 0.05631852522492409, 0.06704039126634598, 0.06932906806468964, 0.055533695966005325, 0.07673808187246323, 0.0785355493426323, 0.0788143053650856, 0.08785883337259293, 0.08313272893428802, 0.04516220837831497, 0.060735780745744705, 0.0790582075715065, 0.06028377264738083, 0.07132478803396225, 0.08179965615272522, 0.0513470321893692, 0.06969065964221954, 0.07177212834358215, 0.0704503208398819, 0.0449228398501873, 0.05611202493309975, 0.07421692460775375, 0.08094602078199387, 0.0827280580997467, 0.06978368759155273, 0.0601310133934021, 0.052623819559812546, 0.056742191314697266, 0.05569873005151749, 0.06319227069616318, 0.08322855085134506, 0.07651518285274506, 0.0757988691329956, 0.049183279275894165, 0.07955627888441086, 0.06863880157470703, 0.05076908320188522, 0.06144733726978302, 0.07414129376411438, 0.07609784603118896, 0.04931512847542763, 0.054195333272218704, 0.07504512369632721, 0.07181313633918762, 0.039070092141628265, 0.08080750703811646, 0.07701295614242554, 0.051311470568180084, 0.07921825349330902, 0.07806094735860825, 0.06962218135595322, 0.05474301427602768, 0.06303121894598007, 0.08204378187656403, 0.06467747688293457, 0.0440903939306736, 0.062442753463983536, 0.03440164029598236, 0.0349305123090744, 0.030248334631323814, 0.05893440172076225, 0.053688064217567444, 0.0414779894053936, 0.06803184747695923, 0.05806121230125427, 0.05034733563661575, 0.04773079976439476, 0.026816606521606445, 0.027697689831256866, 0.057438384741544724, 0.04613643139600754, 0.04946921020746231, 0.05939207598567009, 0.05931835621595383, 0.04497072473168373, 0.04258733615279198, 0.06702467054128647, 0.043619729578495026, 0.046963855624198914, 0.04375652223825455, 0.04716942831873894, 0.05809880420565605, 0.05095590278506279, 0.04974928870797157, 0.03866906464099884, 0.08415877819061279, 0.041525792330503464, 0.05513426288962364, 0.03639881685376167, 0.047410063445568085, 0.055353421717882156, 0.03464819863438606, 0.033446043729782104, 0.04617277905344963, 0.033879656344652176, 0.07001805305480957, 0.0556723028421402, 0.036864373832941055, 0.06537341326475143, 0.04135702922940254, 0.06784185022115707, 0.04058277979493141, 0.041307128965854645, 0.0579773485660553, 0.04108736291527748, 0.06118229776620865, 0.05609767884016037, 0.07238440215587616, 0.06717967987060547, 0.048067204654216766, 0.04104619100689888, 0.05326113849878311, 0.062216874212026596, 0.052922848612070084, 0.043649766594171524, 0.03464267775416374, 0.036779191344976425, 0.04581402242183685, 0.04775546118617058, 0.06099293380975723, 0.054767679423093796, 0.03476937115192413, 0.07953458279371262, 0.047130927443504333, 0.07341040670871735, 0.03730735555291176, 0.023818714544177055, 0.023992927744984627, 0.030706359073519707, 0.05329200625419617, 0.03749933838844299, 0.04719913750886917, 0.055049750953912735, 0.05556735396385193, 0.036350689828395844, 0.06665121763944626, 0.048985037952661514, 0.03737214207649231, 0.053696367889642715, 0.04590938612818718, 0.06947564333677292, 0.04716961458325386, 0.07666604220867157, 0.057818081229925156, 0.06127871945500374, 0.07834379374980927, 0.06775351613759995, 0.023655377328395844, 0.048046935349702835, 0.06219116970896721, 0.06426063925027847, 0.03009503334760666, 0.040557779371738434, 0.06544231623411179, 0.05503260716795921, 0.06587226688861847, 0.0521816723048687, 0.05066840723156929, 0.04389485344290733, 0.05518964305520058, 0.03636929392814636, 0.04094894230365753, 0.05543498322367668, 0.040341295301914215, 0.026747293770313263, 0.07304288446903229, 0.027193309739232063, 0.06239558756351471, 0.043714895844459534, 0.04785090684890747, 0.05203781649470329, 0.04061780869960785, 0.03729218617081642, 0.04010338708758354, 0.03604964539408684, 0.03991091251373291, 0.0509665384888649, 0.03833810240030289, 0.044557124376297, 0.029990483075380325, 0.06273303925991058, 0.03793236240744591, 0.06102606654167175, 0.039536841213703156, 0.02315109223127365, 0.040837325155735016, 0.026334555819630623, 0.03184497356414795, 0.0406351238489151, 0.04939223453402519, 0.040813226252794266, 0.06191523000597954, 0.029748983681201935, 0.038579825311899185, 0.08208905160427094, 0.03899366036057472, 0.027390114963054657, 0.03596486523747444, 0.052121687680482864, 0.06663905829191208, 0.0343935489654541, 0.06297755241394043, 0.05487355589866638, 0.060559164732694626, 0.045747678726911545, 0.05373033136129379, 0.02826184593141079, 0.048063088208436966, 0.028695670887827873, 0.031698077917099, 0.041593872010707855, 0.05796031653881073, 0.030853966251015663, 0.04982934147119522, 0.061731237918138504, 0.024328526109457016, 0.03929620236158371, 0.02681587263941765, 0.04316119849681854, 0.052767008543014526, 0.027699453756213188, 0.04013738036155701, 0.03769437223672867, 0.03786523640155792, 0.05200296267867088, 0.046285856515169144, 0.031652603298425674, 0.026737893000245094, 0.06490025669336319, 0.03639742359519005, 0.05942535027861595, 0.046694062650203705, 0.04221755266189575, 0.05504357069730759, 0.037567734718322754, 0.06934458762407303, 0.03150734305381775, 0.06902427971363068, 0.05273348093032837, 0.04268457368016243, 0.035625286400318146, 0.08465302735567093, 0.04027571529150009, 0.03449811041355133, 0.05250973254442215, 0.04031148552894592, 0.06086016446352005, 0.040561042726039886, 0.04098866507411003, 0.05803672969341278, 0.04129432141780853, 0.06609272956848145, 0.021162712946534157, 0.052695322781801224, 0.045583274215459824, 0.051883287727832794, 0.05881550535559654, 0.03255489841103554, 0.042712319642305374, 0.03555848449468613, 0.05806342139840126, 0.02820475772023201, 0.04442781209945679, 0.03514830768108368, 0.01749144308269024, 0.0386960543692112, 0.04958978667855263, 0.06061813235282898, 0.04322195053100586, 0.04525523632764816, 0.043710436671972275, 0.03095611184835434, 0.02375001087784767, 0.06474602967500687, 0.07429444789886475, 0.04215802624821663, 0.05685684457421303, 0.05108219012618065, 0.031640730798244476, 0.05138546973466873, 0.04798409342765808, 0.035537246614694595, 0.038779426366090775, 0.033386554569005966, 0.056759752333164215, 0.037268638610839844, 0.047674842178821564, 0.042751412838697433, 0.0437016561627388, 0.04545218497514725, 0.03652076795697212, 0.05619030073285103, 0.02931617759168148, 0.03924122080206871, 0.03148270398378372, 0.038948096334934235, 0.026411181315779686, 0.04116618633270264, 0.07017499208450317, 0.026553962379693985, 0.029868975281715393, 0.01960844360291958, 0.06373520195484161, 0.04740059748291969, 0.034715402871370316, 0.030234914273023605, 0.047714509069919586, 0.022041989490389824, 0.04639004170894623, 0.034203339368104935, 0.029831591993570328, 0.025576267391443253, 0.05374618247151375, 0.06513240188360214, 0.07676693797111511, 0.054625388234853745, 0.03710783272981644, 0.048799507319927216, 0.040587857365608215, 0.05224354565143585, 0.041988957673311234, 0.06496942043304443, 0.043894048780202866, 0.04147831350564957, 0.03399541229009628]\n",
            "Rehearsal memory size: 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task2 평가"
      ],
      "metadata": {
        "id": "DVamM1Uad5Z6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## driving12 평가"
      ],
      "metadata": {
        "id": "aFM5WTA7e09d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨 결과 저장\n",
        "final_labels = []\n",
        "final_tasks=[]"
      ],
      "metadata": {
        "id": "dOqenWmXe0RR"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 모드 설정\n",
        "fm_model.eval()\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "test_loss_buffer = []\n",
        "test_action_buffer = []\n",
        "measuring_loss = False\n",
        "test_video_file_count = 0\n"
      ],
      "metadata": {
        "id": "rtNFDRqAf_Gs"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 비디오 업로드 (towtruck 8)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "test_video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "WhfoXnzWgAOJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "50ad71b2-fc85-4107-8a13-ecb47f901f70"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0b45e431-398f-4c2b-838b-35158630de73\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0b45e431-398f-4c2b-838b-35158630de73\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving driving_12.mp4 to driving_12 (4).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 테스트용 비디오 불러오기 =====\n",
        "cap = cv2.VideoCapture(test_video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "\n",
        "with torch.no_grad():  # 테스트 시 gradient 계산 비활성화\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "        step += 1\n",
        "\n",
        "        result = model(frame)[0]\n",
        "        h, w, _ = frame.shape\n",
        "        frame_actions = []\n",
        "\n",
        "        for box in result.boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 테스트 시에는 rehearsal 손실만 계산 (학습하지 않음)\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            total_loss = rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                test_loss_buffer.append(total_loss.item())\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "        final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "        if measuring_loss:\n",
        "            test_action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(\"Test completed with rehearsal evaluation.\")\n",
        "print(\"Test Action Buffer:\", test_action_buffer)\n",
        "print(\"Test Loss Buffer:\", test_loss_buffer)"
      ],
      "metadata": {
        "id": "bwiDGO6egBW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08bc7810-8f0c-4b6e-d5b7-f70e57790213"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 1 car, 205.4ms\n",
            "Speed: 4.2ms preprocess, 205.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 192.8ms\n",
            "Speed: 3.7ms preprocess, 192.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 204.7ms\n",
            "Speed: 9.5ms preprocess, 204.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 196.9ms\n",
            "Speed: 3.3ms preprocess, 196.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 216.9ms\n",
            "Speed: 3.7ms preprocess, 216.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 212.3ms\n",
            "Speed: 3.3ms preprocess, 212.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 206.0ms\n",
            "Speed: 7.4ms preprocess, 206.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 223.9ms\n",
            "Speed: 3.2ms preprocess, 223.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 138.3ms\n",
            "Speed: 3.0ms preprocess, 138.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 151.8ms\n",
            "Speed: 3.4ms preprocess, 151.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 140.1ms\n",
            "Speed: 3.7ms preprocess, 140.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 150.6ms\n",
            "Speed: 3.5ms preprocess, 150.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 137.2ms\n",
            "Speed: 3.2ms preprocess, 137.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 151.7ms\n",
            "Speed: 3.3ms preprocess, 151.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 138.7ms\n",
            "Speed: 3.8ms preprocess, 138.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 136.5ms\n",
            "Speed: 3.4ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.3ms\n",
            "Speed: 3.2ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.9ms\n",
            "Speed: 3.5ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 137.0ms\n",
            "Speed: 3.2ms preprocess, 137.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 138.9ms\n",
            "Speed: 2.9ms preprocess, 138.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 145.0ms\n",
            "Speed: 3.4ms preprocess, 145.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 140.0ms\n",
            "Speed: 3.1ms preprocess, 140.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 136.2ms\n",
            "Speed: 2.9ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 131.7ms\n",
            "Speed: 3.0ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 129.1ms\n",
            "Speed: 3.2ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.2ms\n",
            "Speed: 3.6ms preprocess, 126.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 129.4ms\n",
            "Speed: 3.7ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 143.3ms\n",
            "Speed: 3.5ms preprocess, 143.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 129.5ms\n",
            "Speed: 3.0ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.4ms\n",
            "Speed: 2.8ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.5ms\n",
            "Speed: 2.8ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.7ms\n",
            "Speed: 2.9ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.5ms\n",
            "Speed: 2.9ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 125.1ms\n",
            "Speed: 2.8ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 153.0ms\n",
            "Speed: 3.1ms preprocess, 153.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.5ms\n",
            "Speed: 3.1ms preprocess, 132.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.0ms\n",
            "Speed: 6.1ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.2ms\n",
            "Speed: 3.1ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.9ms\n",
            "Speed: 3.5ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 152.2ms\n",
            "Speed: 4.2ms preprocess, 152.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 175.1ms\n",
            "Speed: 4.7ms preprocess, 175.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 171.4ms\n",
            "Speed: 4.0ms preprocess, 171.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 160.1ms\n",
            "Speed: 4.1ms preprocess, 160.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 155.8ms\n",
            "Speed: 5.3ms preprocess, 155.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 150.9ms\n",
            "Speed: 4.7ms preprocess, 150.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 134.1ms\n",
            "Speed: 3.7ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 125.5ms\n",
            "Speed: 2.9ms preprocess, 125.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 149.9ms\n",
            "Speed: 4.2ms preprocess, 149.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 134.3ms\n",
            "Speed: 4.2ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.7ms\n",
            "Speed: 3.2ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.3ms\n",
            "Speed: 3.3ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.2ms\n",
            "Speed: 3.0ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.0ms\n",
            "Speed: 2.8ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 chair, 129.6ms\n",
            "Speed: 2.9ms preprocess, 129.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 159.1ms\n",
            "Speed: 3.3ms preprocess, 159.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.8ms\n",
            "Speed: 3.1ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 130.9ms\n",
            "Speed: 3.1ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 couch, 132.7ms\n",
            "Speed: 3.1ms preprocess, 132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 133.9ms\n",
            "Speed: 3.0ms preprocess, 133.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 bed, 134.6ms\n",
            "Speed: 3.5ms preprocess, 134.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 139.3ms\n",
            "Speed: 3.5ms preprocess, 139.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 140.5ms\n",
            "Speed: 4.4ms preprocess, 140.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 134.8ms\n",
            "Speed: 2.9ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 130.8ms\n",
            "Speed: 3.3ms preprocess, 130.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 132.1ms\n",
            "Speed: 3.1ms preprocess, 132.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 130.6ms\n",
            "Speed: 3.6ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 130.6ms\n",
            "Speed: 3.3ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 133.9ms\n",
            "Speed: 4.2ms preprocess, 133.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 145.2ms\n",
            "Speed: 3.9ms preprocess, 145.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 126.0ms\n",
            "Speed: 3.1ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 127.6ms\n",
            "Speed: 3.1ms preprocess, 127.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 128.2ms\n",
            "Speed: 3.2ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 126.7ms\n",
            "Speed: 3.1ms preprocess, 126.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 208.0ms\n",
            "Speed: 3.5ms preprocess, 208.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 209.4ms\n",
            "Speed: 3.4ms preprocess, 209.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 202.1ms\n",
            "Speed: 3.4ms preprocess, 202.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 198.8ms\n",
            "Speed: 4.7ms preprocess, 198.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 195.8ms\n",
            "Speed: 3.1ms preprocess, 195.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 246.4ms\n",
            "Speed: 5.0ms preprocess, 246.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 259.6ms\n",
            "Speed: 5.3ms preprocess, 259.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 229.9ms\n",
            "Speed: 5.2ms preprocess, 229.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 217.1ms\n",
            "Speed: 6.3ms preprocess, 217.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 202.3ms\n",
            "Speed: 4.2ms preprocess, 202.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 201.6ms\n",
            "Speed: 4.2ms preprocess, 201.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 198.8ms\n",
            "Speed: 3.2ms preprocess, 198.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 194.2ms\n",
            "Speed: 3.1ms preprocess, 194.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toilet, 201.6ms\n",
            "Speed: 3.1ms preprocess, 201.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 toilet, 211.1ms\n",
            "Speed: 3.1ms preprocess, 211.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 216.8ms\n",
            "Speed: 3.1ms preprocess, 216.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 206.2ms\n",
            "Speed: 3.2ms preprocess, 206.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 203.2ms\n",
            "Speed: 4.5ms preprocess, 203.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 147.1ms\n",
            "Speed: 3.2ms preprocess, 147.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 130.3ms\n",
            "Speed: 3.2ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 131.7ms\n",
            "Speed: 3.1ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 151.8ms\n",
            "Speed: 3.2ms preprocess, 151.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 129.0ms\n",
            "Speed: 5.9ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 130.9ms\n",
            "Speed: 3.0ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 134.8ms\n",
            "Speed: 2.9ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 134.3ms\n",
            "Speed: 3.4ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 130.8ms\n",
            "Speed: 3.4ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 133.1ms\n",
            "Speed: 3.6ms preprocess, 133.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 145.5ms\n",
            "Speed: 3.2ms preprocess, 145.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 131.1ms\n",
            "Speed: 3.2ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 138.5ms\n",
            "Speed: 3.4ms preprocess, 138.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 130.6ms\n",
            "Speed: 3.3ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.4ms\n",
            "Speed: 4.1ms preprocess, 134.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 131.1ms\n",
            "Speed: 3.1ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 132.6ms\n",
            "Speed: 3.4ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 148.7ms\n",
            "Speed: 3.3ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.6ms\n",
            "Speed: 3.1ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.9ms\n",
            "Speed: 3.2ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.0ms\n",
            "Speed: 3.4ms preprocess, 133.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.1ms\n",
            "Speed: 2.9ms preprocess, 136.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.6ms\n",
            "Speed: 2.8ms preprocess, 133.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.2ms\n",
            "Speed: 3.1ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 143.4ms\n",
            "Speed: 3.1ms preprocess, 143.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.2ms\n",
            "Speed: 2.9ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.8ms\n",
            "Speed: 3.1ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.8ms\n",
            "Speed: 3.4ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.7ms\n",
            "Speed: 3.1ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 133.2ms\n",
            "Speed: 3.5ms preprocess, 133.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 140.6ms\n",
            "Speed: 3.4ms preprocess, 140.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 149.5ms\n",
            "Speed: 3.4ms preprocess, 149.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.8ms\n",
            "Speed: 3.4ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 154.5ms\n",
            "Speed: 3.6ms preprocess, 154.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 167.3ms\n",
            "Speed: 9.1ms preprocess, 167.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 168.8ms\n",
            "Speed: 4.6ms preprocess, 168.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 165.5ms\n",
            "Speed: 4.8ms preprocess, 165.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 166.6ms\n",
            "Speed: 4.8ms preprocess, 166.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 156.3ms\n",
            "Speed: 9.4ms preprocess, 156.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 139.1ms\n",
            "Speed: 3.3ms preprocess, 139.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 130.2ms\n",
            "Speed: 3.1ms preprocess, 130.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 128.5ms\n",
            "Speed: 3.0ms preprocess, 128.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 131.6ms\n",
            "Speed: 4.0ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 151.4ms\n",
            "Speed: 3.4ms preprocess, 151.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 138.4ms\n",
            "Speed: 3.2ms preprocess, 138.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 133.3ms\n",
            "Speed: 4.4ms preprocess, 133.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 134.4ms\n",
            "Speed: 3.1ms preprocess, 134.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 130.4ms\n",
            "Speed: 4.9ms preprocess, 130.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 129.7ms\n",
            "Speed: 3.4ms preprocess, 129.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 136.4ms\n",
            "Speed: 3.4ms preprocess, 136.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 152.7ms\n",
            "Speed: 3.3ms preprocess, 152.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 138.3ms\n",
            "Speed: 3.2ms preprocess, 138.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 136.8ms\n",
            "Speed: 3.7ms preprocess, 136.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 136.2ms\n",
            "Speed: 3.5ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 131.7ms\n",
            "Speed: 3.4ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 132.7ms\n",
            "Speed: 3.1ms preprocess, 132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.1ms\n",
            "Speed: 3.2ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 151.7ms\n",
            "Speed: 3.1ms preprocess, 151.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 1 truck, 129.7ms\n",
            "Speed: 3.1ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 131.4ms\n",
            "Speed: 3.2ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 126.5ms\n",
            "Speed: 3.1ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 129.6ms\n",
            "Speed: 3.1ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 128.9ms\n",
            "Speed: 3.0ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 1 truck, 127.8ms\n",
            "Speed: 3.1ms preprocess, 127.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 170.2ms\n",
            "Speed: 3.2ms preprocess, 170.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 200.7ms\n",
            "Speed: 3.2ms preprocess, 200.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 197.1ms\n",
            "Speed: 3.0ms preprocess, 197.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 204.7ms\n",
            "Speed: 3.1ms preprocess, 204.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 199.3ms\n",
            "Speed: 3.2ms preprocess, 199.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 225.1ms\n",
            "Speed: 3.1ms preprocess, 225.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 204.2ms\n",
            "Speed: 4.9ms preprocess, 204.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 244.6ms\n",
            "Speed: 9.6ms preprocess, 244.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 243.7ms\n",
            "Speed: 4.0ms preprocess, 243.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 252.6ms\n",
            "Speed: 6.8ms preprocess, 252.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 220.2ms\n",
            "Speed: 5.7ms preprocess, 220.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 198.0ms\n",
            "Speed: 3.1ms preprocess, 198.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 193.9ms\n",
            "Speed: 2.9ms preprocess, 193.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 212.1ms\n",
            "Speed: 5.1ms preprocess, 212.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 226.5ms\n",
            "Speed: 3.2ms preprocess, 226.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 218.2ms\n",
            "Speed: 3.4ms preprocess, 218.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 210.7ms\n",
            "Speed: 4.6ms preprocess, 210.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.6ms\n",
            "Speed: 4.2ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.7ms\n",
            "Speed: 3.0ms preprocess, 136.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 147.6ms\n",
            "Speed: 3.1ms preprocess, 147.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.2ms\n",
            "Speed: 4.1ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.7ms\n",
            "Speed: 3.6ms preprocess, 133.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.3ms\n",
            "Speed: 3.5ms preprocess, 133.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 138.8ms\n",
            "Speed: 3.4ms preprocess, 138.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.9ms\n",
            "Speed: 3.5ms preprocess, 135.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.4ms\n",
            "Speed: 3.3ms preprocess, 136.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 1 cell phone, 152.4ms\n",
            "Speed: 3.4ms preprocess, 152.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 131.1ms\n",
            "Speed: 3.1ms preprocess, 131.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.0ms\n",
            "Speed: 4.2ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.4ms\n",
            "Speed: 3.1ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.3ms\n",
            "Speed: 3.6ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.7ms\n",
            "Speed: 3.3ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.8ms\n",
            "Speed: 3.7ms preprocess, 136.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 143.1ms\n",
            "Speed: 3.1ms preprocess, 143.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 127.1ms\n",
            "Speed: 3.7ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.6ms\n",
            "Speed: 4.5ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 136.5ms\n",
            "Speed: 3.5ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 131.9ms\n",
            "Speed: 4.6ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 131.8ms\n",
            "Speed: 3.2ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 129.8ms\n",
            "Speed: 3.1ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 151.8ms\n",
            "Speed: 3.2ms preprocess, 151.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 163.0ms\n",
            "Speed: 3.6ms preprocess, 163.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 163.8ms\n",
            "Speed: 4.0ms preprocess, 163.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 165.3ms\n",
            "Speed: 4.6ms preprocess, 165.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 161.4ms\n",
            "Speed: 4.6ms preprocess, 161.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 169.5ms\n",
            "Speed: 3.4ms preprocess, 169.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.4ms\n",
            "Speed: 4.7ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.9ms\n",
            "Speed: 3.3ms preprocess, 129.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 125.6ms\n",
            "Speed: 3.4ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 127.1ms\n",
            "Speed: 3.0ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.4ms\n",
            "Speed: 3.1ms preprocess, 130.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.6ms\n",
            "Speed: 3.2ms preprocess, 131.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 136.9ms\n",
            "Speed: 3.3ms preprocess, 136.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.2ms\n",
            "Speed: 4.9ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.1ms\n",
            "Speed: 3.4ms preprocess, 133.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 133.2ms\n",
            "Speed: 3.2ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.1ms\n",
            "Speed: 3.9ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.7ms\n",
            "Speed: 3.0ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.9ms\n",
            "Speed: 3.3ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.8ms\n",
            "Speed: 3.4ms preprocess, 131.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.5ms\n",
            "Speed: 6.6ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.7ms\n",
            "Speed: 3.2ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.5ms\n",
            "Speed: 3.0ms preprocess, 135.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.2ms\n",
            "Speed: 3.4ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.8ms\n",
            "Speed: 3.2ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.3ms\n",
            "Speed: 3.6ms preprocess, 130.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.0ms\n",
            "Speed: 3.2ms preprocess, 127.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 147.5ms\n",
            "Speed: 3.0ms preprocess, 147.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.9ms\n",
            "Speed: 3.2ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.7ms\n",
            "Speed: 3.6ms preprocess, 132.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.1ms\n",
            "Speed: 4.2ms preprocess, 132.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 130.0ms\n",
            "Speed: 3.2ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.2ms\n",
            "Speed: 3.1ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.5ms\n",
            "Speed: 3.0ms preprocess, 136.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.3ms\n",
            "Speed: 3.4ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.6ms\n",
            "Speed: 3.2ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.7ms\n",
            "Speed: 3.3ms preprocess, 134.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.4ms\n",
            "Speed: 3.4ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.2ms\n",
            "Speed: 3.2ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 140.1ms\n",
            "Speed: 3.2ms preprocess, 140.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 146.3ms\n",
            "Speed: 3.4ms preprocess, 146.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 145.8ms\n",
            "Speed: 2.9ms preprocess, 145.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 199.7ms\n",
            "Speed: 2.8ms preprocess, 199.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 210.6ms\n",
            "Speed: 3.1ms preprocess, 210.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 198.4ms\n",
            "Speed: 3.1ms preprocess, 198.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 226.9ms\n",
            "Speed: 3.1ms preprocess, 226.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 196.0ms\n",
            "Speed: 3.8ms preprocess, 196.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 203.2ms\n",
            "Speed: 6.3ms preprocess, 203.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 207.7ms\n",
            "Speed: 4.8ms preprocess, 207.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 198.8ms\n",
            "Speed: 3.3ms preprocess, 198.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 224.0ms\n",
            "Speed: 3.2ms preprocess, 224.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 234.6ms\n",
            "Speed: 3.4ms preprocess, 234.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 253.7ms\n",
            "Speed: 4.5ms preprocess, 253.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 230.1ms\n",
            "Speed: 4.1ms preprocess, 230.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 235.7ms\n",
            "Speed: 3.3ms preprocess, 235.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 211.7ms\n",
            "Speed: 4.0ms preprocess, 211.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 200.5ms\n",
            "Speed: 3.0ms preprocess, 200.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 205.5ms\n",
            "Speed: 3.4ms preprocess, 205.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 151.3ms\n",
            "Speed: 2.9ms preprocess, 151.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 149.6ms\n",
            "Speed: 3.2ms preprocess, 149.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.1ms\n",
            "Speed: 3.0ms preprocess, 131.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.5ms\n",
            "Speed: 2.8ms preprocess, 133.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 132.6ms\n",
            "Speed: 2.9ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.0ms\n",
            "Speed: 3.0ms preprocess, 134.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.1ms\n",
            "Speed: 3.2ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.2ms\n",
            "Speed: 2.9ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 147.2ms\n",
            "Speed: 3.3ms preprocess, 147.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 135.1ms\n",
            "Speed: 3.4ms preprocess, 135.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.0ms\n",
            "Speed: 3.1ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 130.7ms\n",
            "Speed: 3.5ms preprocess, 130.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 128.1ms\n",
            "Speed: 3.2ms preprocess, 128.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 140.8ms\n",
            "Speed: 4.0ms preprocess, 140.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.1ms\n",
            "Speed: 2.9ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 168.7ms\n",
            "Speed: 3.1ms preprocess, 168.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 130.2ms\n",
            "Speed: 2.9ms preprocess, 130.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 128.3ms\n",
            "Speed: 2.8ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 126.0ms\n",
            "Speed: 8.0ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.0ms\n",
            "Speed: 2.8ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.0ms\n",
            "Speed: 3.2ms preprocess, 132.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.1ms\n",
            "Speed: 2.8ms preprocess, 137.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 142.7ms\n",
            "Speed: 3.1ms preprocess, 142.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.2ms\n",
            "Speed: 3.0ms preprocess, 131.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.8ms\n",
            "Speed: 3.2ms preprocess, 132.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.6ms\n",
            "Speed: 3.0ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.8ms\n",
            "Speed: 3.1ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.0ms\n",
            "Speed: 3.1ms preprocess, 134.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.8ms\n",
            "Speed: 3.1ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 190.1ms\n",
            "Speed: 3.7ms preprocess, 190.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 168.6ms\n",
            "Speed: 7.1ms preprocess, 168.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 158.8ms\n",
            "Speed: 4.1ms preprocess, 158.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 160.8ms\n",
            "Speed: 4.0ms preprocess, 160.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 147.0ms\n",
            "Speed: 3.8ms preprocess, 147.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 130.5ms\n",
            "Speed: 3.2ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 143.5ms\n",
            "Speed: 3.1ms preprocess, 143.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 126.5ms\n",
            "Speed: 3.6ms preprocess, 126.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 163.7ms\n",
            "Speed: 5.3ms preprocess, 163.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 162.2ms\n",
            "Speed: 3.1ms preprocess, 162.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.0ms\n",
            "Speed: 3.1ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 128.5ms\n",
            "Speed: 3.4ms preprocess, 128.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 156.3ms\n",
            "Speed: 3.1ms preprocess, 156.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.7ms\n",
            "Speed: 3.2ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.5ms\n",
            "Speed: 3.0ms preprocess, 137.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.2ms\n",
            "Speed: 3.8ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.1ms\n",
            "Speed: 3.2ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.8ms\n",
            "Speed: 3.8ms preprocess, 137.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.1ms\n",
            "Speed: 3.0ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 146.9ms\n",
            "Speed: 3.1ms preprocess, 146.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.4ms\n",
            "Speed: 3.5ms preprocess, 134.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.9ms\n",
            "Speed: 3.3ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.7ms\n",
            "Speed: 3.1ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 137.5ms\n",
            "Speed: 3.0ms preprocess, 137.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.4ms\n",
            "Speed: 3.4ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.2ms\n",
            "Speed: 3.0ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 157.3ms\n",
            "Speed: 3.2ms preprocess, 157.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.7ms\n",
            "Speed: 3.4ms preprocess, 134.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.5ms\n",
            "Speed: 3.2ms preprocess, 132.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.0ms\n",
            "Speed: 3.3ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.0ms\n",
            "Speed: 3.1ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 153.3ms\n",
            "Speed: 3.5ms preprocess, 153.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 174.9ms\n",
            "Speed: 4.0ms preprocess, 174.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 179.1ms\n",
            "Speed: 12.5ms preprocess, 179.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 152.4ms\n",
            "Speed: 4.0ms preprocess, 152.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 207.1ms\n",
            "Speed: 9.8ms preprocess, 207.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 197.2ms\n",
            "Speed: 3.4ms preprocess, 197.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 197.2ms\n",
            "Speed: 3.0ms preprocess, 197.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 199.1ms\n",
            "Speed: 6.0ms preprocess, 199.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 202.7ms\n",
            "Speed: 3.2ms preprocess, 202.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 197.5ms\n",
            "Speed: 4.8ms preprocess, 197.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 204.1ms\n",
            "Speed: 3.1ms preprocess, 204.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 205.8ms\n",
            "Speed: 3.9ms preprocess, 205.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 truck, 204.5ms\n",
            "Speed: 3.1ms preprocess, 204.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 196.4ms\n",
            "Speed: 2.9ms preprocess, 196.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 199.4ms\n",
            "Speed: 6.2ms preprocess, 199.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 193.7ms\n",
            "Speed: 3.2ms preprocess, 193.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 198.8ms\n",
            "Speed: 3.1ms preprocess, 198.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 213.3ms\n",
            "Speed: 3.3ms preprocess, 213.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 213.9ms\n",
            "Speed: 3.0ms preprocess, 213.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 206.5ms\n",
            "Speed: 5.9ms preprocess, 206.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 201.7ms\n",
            "Speed: 3.3ms preprocess, 201.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 235.8ms\n",
            "Speed: 3.0ms preprocess, 235.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 169.8ms\n",
            "Speed: 5.4ms preprocess, 169.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 166.0ms\n",
            "Speed: 4.4ms preprocess, 166.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 166.7ms\n",
            "Speed: 4.7ms preprocess, 166.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 153.3ms\n",
            "Speed: 3.7ms preprocess, 153.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 148.4ms\n",
            "Speed: 4.0ms preprocess, 148.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 157.4ms\n",
            "Speed: 3.3ms preprocess, 157.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.4ms\n",
            "Speed: 3.1ms preprocess, 136.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.3ms\n",
            "Speed: 3.0ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.3ms\n",
            "Speed: 3.0ms preprocess, 131.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.3ms\n",
            "Speed: 2.9ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.8ms\n",
            "Speed: 3.5ms preprocess, 128.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 140.3ms\n",
            "Speed: 3.1ms preprocess, 140.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 157.4ms\n",
            "Speed: 3.1ms preprocess, 157.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.9ms\n",
            "Speed: 4.7ms preprocess, 131.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 132.7ms\n",
            "Speed: 3.4ms preprocess, 132.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.6ms\n",
            "Speed: 3.0ms preprocess, 138.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.6ms\n",
            "Speed: 3.1ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 125.2ms\n",
            "Speed: 5.1ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 127.4ms\n",
            "Speed: 4.5ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 150.2ms\n",
            "Speed: 3.1ms preprocess, 150.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.2ms\n",
            "Speed: 2.9ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.3ms\n",
            "Speed: 3.1ms preprocess, 133.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.0ms\n",
            "Speed: 2.9ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.6ms\n",
            "Speed: 3.4ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.3ms\n",
            "Speed: 3.1ms preprocess, 127.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 124.6ms\n",
            "Speed: 2.9ms preprocess, 124.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 149.9ms\n",
            "Speed: 4.8ms preprocess, 149.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 139.2ms\n",
            "Speed: 3.9ms preprocess, 139.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 136.4ms\n",
            "Speed: 3.2ms preprocess, 136.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.1ms\n",
            "Speed: 3.1ms preprocess, 133.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.6ms\n",
            "Speed: 3.4ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.3ms\n",
            "Speed: 3.1ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 170.0ms\n",
            "Speed: 2.9ms preprocess, 170.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 172.0ms\n",
            "Speed: 4.6ms preprocess, 172.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Test completed with rehearsal evaluation.\n",
            "Test Action Buffer: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Test Loss Buffer: [0.05347142741084099, 0.03014548495411873, 0.08326427638530731, 0.04678851366043091, 0.06440780311822891, 0.05088428035378456, 0.04474813863635063, 0.019839094951748848, 0.03995699808001518, 0.015684625133872032, 0.04371960088610649, 0.03160946071147919, 0.06015891954302788, 0.043002840131521225, 0.07331018894910812, 0.04351744428277016, 0.029057098552584648, 0.06513653695583344, 0.07657606899738312, 0.03856843709945679, 0.019281717017292976, 0.10101446509361267, 0.03592802956700325, 0.08955191820859909, 0.041292835026979446, 0.03925890475511551, 0.05011375993490219, 0.061790723353624344, 0.052141182124614716, 0.017310181632637978, 0.02371901459991932, 0.057463739067316055, 0.10736837983131409, 0.046402689069509506, 0.04181062802672386, 0.050040800124406815, 0.043215736746788025, 0.040224749594926834, 0.03506989777088165, 0.020758043974637985, 0.043574731796979904, 0.056273363530635834, 0.08506744354963303, 0.024895070120692253, 0.07839139550924301, 0.0327153317630291, 0.022388946264982224, 0.03373182564973831, 0.06099181994795799, 0.0231635645031929, 0.03823406249284744, 0.02651672065258026, 0.04854101687669754, 0.054290637373924255, 0.0892581045627594, 0.02979949302971363, 0.030181165784597397, 0.045671239495277405, 0.06342817097902298, 0.0367831289768219, 0.057337675243616104, 0.03291487693786621, 0.03827114775776863, 0.04545282572507858, 0.05335712432861328, 0.03769395500421524, 0.04076807573437691, 0.054678600281476974, 0.03717774525284767, 0.0611896887421608, 0.0594375804066658, 0.06191440299153328, 0.04126257449388504, 0.04418786242604256, 0.046182554215192795, 0.05864432454109192, 0.03799472749233246, 0.03727130591869354, 0.05107304826378822, 0.038183748722076416, 0.07167235016822815, 0.07078272104263306, 0.0516599602997303, 0.023717353120446205, 0.06913210451602936, 0.05011966824531555, 0.048316095024347305, 0.0265759639441967, 0.06839369237422943, 0.03275754675269127, 0.05235686153173447, 0.06650728732347488, 0.06387411803007126, 0.05365394800901413, 0.051427070051431656, 0.04455514997243881, 0.07636640965938568, 0.03756950795650482, 0.04660031944513321, 0.06328409910202026, 0.06333329528570175, 0.02655942365527153, 0.043355152010917664, 0.0390288345515728, 0.06654517352581024, 0.036920733749866486, 0.0499487966299057, 0.07183275371789932, 0.038794536143541336, 0.0403742678463459, 0.05168940871953964, 0.03533457592129707, 0.03838973492383957, 0.03434741124510765, 0.06554646044969559, 0.025591576471924782, 0.04084380716085434, 0.06225459650158882, 0.026511261239647865, 0.08014321327209473, 0.025893043726682663, 0.04158695042133331, 0.10337434709072113, 0.07179845124483109, 0.052785903215408325, 0.050005849450826645, 0.08896031975746155, 0.05938325077295303, 0.018770145252346992, 0.04280145838856697, 0.04824376851320267, 0.021528523415327072, 0.05951686203479767, 0.03906363993883133, 0.05153950676321983, 0.06107740104198456, 0.04461950436234474, 0.05483595281839371, 0.06870467960834503, 0.06019970774650574, 0.031436674296855927, 0.04200443997979164, 0.021103519946336746, 0.06070931628346443, 0.04992266371846199, 0.06925854831933975, 0.040604978799819946, 0.04013079032301903, 0.0157192200422287, 0.019268877804279327, 0.030908998101949692, 0.038082659244537354, 0.04945601522922516, 0.019726436585187912, 0.040675338357686996, 0.07891149818897247, 0.03024934232234955, 0.06095293164253235, 0.09799430519342422, 0.04575767368078232, 0.04478949308395386, 0.04437397047877312, 0.04888505861163139, 0.03399583697319031, 0.06585390120744705, 0.02810167334973812, 0.04062928631901741, 0.009927310049533844, 0.023335017263889313, 0.04282718524336815, 0.06239161640405655, 0.052956271916627884, 0.013577359728515148, 0.051982682198286057, 0.028971167281270027, 0.02867252193391323, 0.04850773140788078, 0.051823534071445465, 0.012203149497509003, 0.024654529988765717, 0.05368493124842644, 0.06052498146891594, 0.054781876504421234, 0.03537466377019882, 0.0748683288693428, 0.03907901793718338, 0.03627016395330429, 0.09920238703489304, 0.031229715794324875, 0.040422193706035614, 0.02691272832453251, 0.03902886062860489, 0.03770970553159714, 0.03091885708272457, 0.03191445767879486, 0.0264284610748291, 0.0096888467669487, 0.04159901291131973, 0.032748498022556305, 0.03807321935892105, 0.10967180877923965, 0.028455689549446106, 0.017718283459544182, 0.06344099342823029, 0.04616812989115715, 0.08430778980255127, 0.010977537371218204, 0.018146662041544914, 0.04168156906962395, 0.049791254103183746, 0.03824798762798309, 0.06536366045475006, 0.030339684337377548, 0.03287062421441078, 0.06558583676815033, 0.08000018447637558, 0.03146212175488472, 0.06508466601371765, 0.05604853108525276, 0.03940025717020035, 0.053719647228717804, 0.0670042410492897, 0.03915124386548996, 0.05023391917347908, 0.033962950110435486, 0.03617625683546066, 0.0385548360645771, 0.04814411699771881, 0.022585615515708923, 0.0718957930803299, 0.021073320880532265, 0.04076606035232544, 0.03128748759627342, 0.07249125838279724, 0.04141467064619064, 0.039625782519578934, 0.022003525868058205, 0.031443703919649124, 0.04186975210905075, 0.0812874510884285, 0.10042403638362885, 0.032429710030555725, 0.0305047444999218, 0.03462015837430954, 0.06250189989805222, 0.0821232721209526, 0.033546265214681625, 0.047825369983911514, 0.04814736545085907, 0.04660625010728836, 0.07764050364494324, 0.0245035532861948, 0.040969375520944595, 0.02416193298995495, 0.08196014910936356, 0.043431684374809265, 0.0724392980337143, 0.044113315641880035, 0.09808918088674545, 0.037073325365781784, 0.049344584345817566, 0.05541108921170235, 0.05824900045990944, 0.02960970066487789, 0.037437643855810165, 0.05774344876408577, 0.050357721745967865, 0.024376098066568375, 0.07553185522556305, 0.040638234466314316, 0.043787434697151184, 0.03313576430082321, 0.047569867223501205, 0.0461832657456398, 0.05560706555843353, 0.04433971270918846, 0.027398698031902313, 0.034560274332761765, 0.07339940220117569, 0.04755948856472969, 0.1263979822397232, 0.05474221706390381, 0.07292677462100983, 0.07748108357191086, 0.04461467266082764, 0.04367972910404205, 0.08194877207279205, 0.023076951503753662, 0.06599593162536621, 0.03500844165682793, 0.03288186714053154, 0.023138780146837234, 0.03779560700058937, 0.02256864495575428, 0.044578637927770615, 0.058094900101423264, 0.03504294902086258, 0.04042903333902359, 0.01979006454348564, 0.011227705515921116, 0.07361684739589691, 0.020537424832582474, 0.03743491321802139, 0.031451866030693054, 0.011546093970537186, 0.04421817883849144, 0.04460885003209114, 0.06104399636387825, 0.04973491653800011, 0.02998296730220318, 0.07192305475473404, 0.040532492101192474, 0.07274462282657623, 0.01756085269153118, 0.046601612120866776, 0.030021272599697113, 0.023554127663373947, 0.02847628854215145, 0.02212396264076233, 0.01959383301436901, 0.024191247299313545, 0.06095019355416298, 0.041389137506484985, 0.03292643651366234, 0.07258932292461395, 0.03208315372467041, 0.01912415400147438, 0.04161735624074936, 0.055468663573265076, 0.025600792840123177, 0.05057813227176666, 0.044510383158922195, 0.03905516862869263, 0.04903677850961685, 0.03256871551275253, 0.05160476639866829, 0.06346800923347473, 0.030464202165603638, 0.03457645699381828, 0.032890062779188156, 0.013882373459637165, 0.08054228127002716, 0.02663935348391533, 0.026910170912742615, 0.08186876028776169, 0.04250139743089676, 0.043397944420576096, 0.023470750078558922, 0.03346290811896324, 0.034266937524080276, 0.03279692679643631, 0.08982501924037933, 0.06394607573747635, 0.02061331644654274, 0.008614501915872097, 0.05548906326293945, 0.07437724620103836, 0.04116855561733246, 0.006669667083770037, 0.05597582086920738, 0.03360777348279953, 0.041312068700790405, 0.06517181545495987, 0.029249873012304306, 0.04320097714662552, 0.031899046152830124, 0.1232849583029747, 0.07593026012182236, 0.04670684039592743, 0.018308596685528755, 0.060156598687171936, 0.021029027178883553, 0.022748343646526337, 0.040394920855760574, 0.028126947581768036, 0.05769813060760498, 0.058766089379787445, 0.03267429769039154, 0.03660636022686958, 0.026283949613571167, 0.06904078274965286, 0.041055236011743546, 0.020427964627742767, 0.09126753360033035, 0.06318862736225128, 0.025831397622823715, 0.02149190939962864, 0.03217772766947746, 0.050151847302913666, 0.0339067205786705, 0.053883589804172516, 0.09888696670532227, 0.05147328972816467, 0.030146075412631035, 0.08360768854618073, 0.01315175648778677, 0.028669290244579315, 0.056506358087062836, 0.024082724004983902, 0.02494947984814644, 0.03271537274122238, 0.04615991935133934, 0.0295344740152359, 0.032462842762470245, 0.04081171005964279, 0.02933136746287346, 0.06686107814311981, 0.05391811951994896, 0.047359663993120193, 0.05482981726527214, 0.06375283002853394, 0.056033656001091, 0.03050866536796093, 0.03015061840415001, 0.030590839684009552, 0.01941187120974064, 0.0250074602663517, 0.03995344415307045, 0.05815645307302475, 0.034890316426754, 0.03798219934105873, 0.05914679542183876, 0.06371930241584778, 0.049791108816862106, 0.06434190273284912, 0.03010725975036621, 0.06855513900518417, 0.009019574150443077, 0.042968399822711945, 0.03796372935175896, 0.03201698139309883, 0.031345054507255554, 0.05287500470876694, 0.04645244777202606, 0.016569973900914192, 0.05141061916947365, 0.04989532381296158, 0.03321327641606331, 0.069703109562397, 0.03894583880901337, 0.048099130392074585, 0.05516935884952545, 0.042707409709692, 0.07725229859352112, 0.027564160525798798, 0.039779700338840485, 0.04510248452425003, 0.029209012165665627, 0.05927804112434387, 0.04978681355714798, 0.05892663821578026, 0.030792605131864548, 0.05539228022098541, 0.059920139610767365, 0.05626099556684494, 0.07497961074113846, 0.04251296445727348, 0.07709084451198578, 0.02222035638988018, 0.04955879971385002, 0.02425479143857956, 0.007872442714869976, 0.04312441870570183, 0.022396737709641457, 0.03602344170212746, 0.05970205366611481, 0.042188920080661774, 0.05087306722998619, 0.018363697454333305, 0.04390078783035278, 0.046888064593076706, 0.023732176050543785, 0.0258686151355505, 0.06255542486906052, 0.027941245585680008, 0.04030552878975868, 0.05812482535839081, 0.06447961926460266, 0.048979923129081726, 0.021407494321465492, 0.038777031004428864, 0.08932448923587799, 0.011482222937047482, 0.007999159395694733, 0.057729218155145645, 0.02971257083117962, 0.0625334158539772, 0.024022536352276802, 0.02780100703239441, 0.012253348715603352, 0.046756453812122345, 0.053701918572187424, 0.014801106415688992, 0.03789237514138222, 0.0027671970892697573, 0.056247469037771225, 0.032669052481651306, 0.05030236765742302, 0.07210364937782288, 0.05907348543405533, 0.017774535343050957, 0.04021487757563591, 0.05261629447340965, 0.05353497713804245, 0.05650005862116814, 0.06743195652961731, 0.08059155941009521, 0.049333762377500534, 0.06331221759319305, 0.08076336234807968, 0.05292254686355591, 0.021364258602261543, 0.025027746334671974, 0.08760430663824081, 0.05665280297398567, 0.06261607259511948, 0.04820730537176132, 0.052665818482637405, 0.03612873703241348, 0.031042007729411125, 0.055290769785642624, 0.05006266385316849, 0.021663732826709747, 0.04616990312933922, 0.051904480904340744, 0.05161098763346672, 0.10174266248941422, 0.01182825118303299, 0.04183986037969589, 0.0520753413438797, 0.04019014537334442, 0.053402550518512726, 0.05758489668369293, 0.037636857479810715, 0.06585033982992172, 0.042018625885248184, 0.019855065271258354, 0.007318343501538038, 0.041791245341300964, 0.025681255385279655, 0.029826905578374863, 0.02891550399363041, 0.03848050534725189, 0.06492230296134949, 0.041185155510902405, 0.022859588265419006, 0.03166795149445534, 0.0201583169400692, 0.03182452544569969, 0.03321761637926102, 0.07319366186857224, 0.04193510115146637, 0.061685651540756226, 0.08097532391548157, 0.024431215599179268, 0.02129759080708027, 0.03156762942671776, 0.03881633281707764, 0.04016627371311188, 0.04651417210698128, 0.05296667665243149, 0.10030145943164825, 0.03430483862757683, 0.012648526579141617, 0.047273263335227966, 0.035949576646089554, 0.016114044934511185, 0.05578896775841713, 0.03835055232048035, 0.03454383835196495, 0.05953790619969368, 0.04481957107782364, 0.06947599351406097, 0.03039083629846573, 0.0746067464351654, 0.045842643827199936, 0.024849340319633484, 0.06342227011919022, 0.052774060517549515, 0.05183045566082001, 0.07231733947992325, 0.03392716869711876, 0.07801583409309387, 0.013301554135978222, 0.0401911698281765, 0.03277355432510376, 0.024407193064689636, 0.07410205155611038, 0.019534368067979813, 0.04715971276164055, 0.03579402342438698, 0.039071522653102875, 0.040810324251651764, 0.033399686217308044, 0.026977522298693657, 0.033464618027210236, 0.057779546827077866, 0.03797125443816185, 0.0952778086066246, 0.046663783490657806, 0.03514600917696953, 0.036450739949941635, 0.08205913007259369, 0.0534031055867672, 0.02458192966878414, 0.06465177237987518, 0.038479283452034, 0.10384064167737961, 0.02157815732061863, 0.04942132532596588, 0.04990324750542641, 0.012600990943610668, 0.03837962448596954, 0.04258648306131363, 0.074824258685112, 0.020000584423542023, 0.05179693549871445, 0.029938235878944397, 0.031893905252218246, 0.04559929668903351, 0.047012779861688614, 0.03798110410571098, 0.058563221246004105, 0.06456446647644043, 0.032919809222221375, 0.07012732326984406, 0.035477735102176666, 0.057565852999687195, 0.038987480103969574]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 라벨 설정\n",
        "test_frame_labels = driving12['go_stop_decision'] # 여기에 driving12, truck8, uturn7을 값을 바꿔가며 넣기"
      ],
      "metadata": {
        "id": "x5veQ7mkgHFB"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 타입 및 길이 확인\n",
        "print(type(test_action_buffer))\n",
        "print(type(test_frame_labels))\n",
        "print(len(test_action_buffer))\n",
        "print(len(test_frame_labels))"
      ],
      "metadata": {
        "id": "C-MyycqSgJ1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d24f52-623b-44a1-c7c6-0ea713bd02d0"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "369\n",
            "369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과 저장\n",
        "\n",
        "final_tasks.append(test_action_buffer)\n",
        "final_labels.append(test_frame_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "4LBASUQ4gMFi"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CL 메트릭 계산\n",
        "IM, FWT, BWT = compute_cl_metrics(final_tasks, final_labels)\n",
        "\n",
        "print(f\"IM (Initial Accuracy): {IM:.3f}\")\n",
        "print(f\"FWT (Forward Transfer): {FWT:.5f}\")\n",
        "print(f\"BWT (Backward Transfer): {BWT:.5f}\")\n"
      ],
      "metadata": {
        "id": "PmjzphxBgQlh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619093d7-10a5-44ea-9bb3-d60c0ccffbfe"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task accuracies: [    0.65854]\n",
            "IM (Initial Accuracy): 0.659\n",
            "FWT (Forward Transfer): 0.00000\n",
            "BWT (Backward Transfer): 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rehearsal 메모리 상태 확인\n",
        "print(f\"Rehearsal memory contains {len(rehearsal_memory.data_buffer)} samples\")\n",
        "print(f\"Memory usage: {len(rehearsal_memory.data_buffer)} / {rehearsal_memory.max_samples}\")"
      ],
      "metadata": {
        "id": "dlgkfzWMgSau",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ba8cd8-4087-4ce7-aee5-09b57190c9eb"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rehearsal memory contains 900 samples\n",
            "Memory usage: 900 / 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 샘플의 일부 확인\n",
        "if len(rehearsal_memory.data_buffer) > 0:\n",
        "    sample_data = rehearsal_memory.data_buffer[0]\n",
        "    sample_label = rehearsal_memory.label_buffer[0]\n",
        "    print(f\"Sample data shape: {sample_data.shape}\")\n",
        "    print(f\"Sample label: {sample_label}\")"
      ],
      "metadata": {
        "id": "mThjVyfvgVqn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498d2101-f35b-4d9b-8c1b-b09229e3b736"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data shape: (15,)\n",
            "Sample label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_tasks)"
      ],
      "metadata": {
        "id": "2FwusH8ygXtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c5b6d5-6514-4608-f547-72e49d5b1169"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## towtruck 8 평가"
      ],
      "metadata": {
        "id": "kD0fRDAwd8mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨 결과 저장\n",
        "final_labels = []\n",
        "final_tasks=[]"
      ],
      "metadata": {
        "id": "N5hZ7rxPd3fG"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 모드 설정\n",
        "fm_model.eval()\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "test_loss_buffer = []\n",
        "test_action_buffer = []\n",
        "measuring_loss = False\n",
        "test_video_file_count = 0\n"
      ],
      "metadata": {
        "id": "ns-rhd_6eRfj"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 비디오 업로드 (towtruck 8)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "test_video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "pI7CO5LDeTm3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b9abe3ae-d8e9-42b2-c45b-374487161dee"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0e08e6ab-b5e9-41a5-8f31-d430fefe7f90\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0e08e6ab-b5e9-41a5-8f31-d430fefe7f90\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving towtruck_seperation_8.mov to towtruck_seperation_8 (2).mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 테스트용 비디오 불러오기 =====\n",
        "cap = cv2.VideoCapture(test_video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "\n",
        "with torch.no_grad():  # 테스트 시 gradient 계산 비활성화\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "        step += 1\n",
        "\n",
        "        result = model(frame)[0]\n",
        "        h, w, _ = frame.shape\n",
        "        frame_actions = []\n",
        "\n",
        "        for box in result.boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 테스트 시에는 rehearsal 손실만 계산 (학습하지 않음)\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            total_loss = rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                test_loss_buffer.append(total_loss.item())\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "        final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "        if measuring_loss:\n",
        "            test_action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(\"Test completed with rehearsal evaluation.\")\n",
        "print(\"Test Action Buffer:\", test_action_buffer)\n",
        "print(\"Test Loss Buffer:\", test_loss_buffer)"
      ],
      "metadata": {
        "id": "d4ueHj8EeYbi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb023db-5f01-435d-bc64-76f04db20084"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 cars, 1 truck, 139.7ms\n",
            "Speed: 7.5ms preprocess, 139.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.4ms\n",
            "Speed: 4.3ms preprocess, 131.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.3ms\n",
            "Speed: 3.9ms preprocess, 136.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.8ms\n",
            "Speed: 4.1ms preprocess, 136.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 151.6ms\n",
            "Speed: 4.1ms preprocess, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.3ms\n",
            "Speed: 4.1ms preprocess, 134.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.7ms\n",
            "Speed: 4.1ms preprocess, 136.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.5ms\n",
            "Speed: 4.2ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 132.9ms\n",
            "Speed: 4.4ms preprocess, 132.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 132.5ms\n",
            "Speed: 4.1ms preprocess, 132.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.5ms\n",
            "Speed: 4.1ms preprocess, 133.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 148.7ms\n",
            "Speed: 4.0ms preprocess, 148.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.0ms\n",
            "Speed: 4.4ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.5ms\n",
            "Speed: 4.4ms preprocess, 133.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 143.7ms\n",
            "Speed: 4.4ms preprocess, 143.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.3ms\n",
            "Speed: 4.4ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.8ms\n",
            "Speed: 4.4ms preprocess, 135.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 154.0ms\n",
            "Speed: 4.6ms preprocess, 154.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.0ms\n",
            "Speed: 4.1ms preprocess, 134.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.8ms\n",
            "Speed: 4.5ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 138.6ms\n",
            "Speed: 4.0ms preprocess, 138.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 159.0ms\n",
            "Speed: 4.4ms preprocess, 159.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 171.7ms\n",
            "Speed: 5.3ms preprocess, 171.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 196.4ms\n",
            "Speed: 5.8ms preprocess, 196.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 164.5ms\n",
            "Speed: 4.9ms preprocess, 164.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 163.3ms\n",
            "Speed: 4.5ms preprocess, 163.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 147.7ms\n",
            "Speed: 4.9ms preprocess, 147.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.3ms\n",
            "Speed: 4.1ms preprocess, 134.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.2ms\n",
            "Speed: 4.0ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 150.0ms\n",
            "Speed: 4.2ms preprocess, 150.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.1ms\n",
            "Speed: 4.1ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 138.8ms\n",
            "Speed: 4.5ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.4ms\n",
            "Speed: 4.4ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.5ms\n",
            "Speed: 4.3ms preprocess, 131.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.6ms\n",
            "Speed: 4.4ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.0ms\n",
            "Speed: 4.7ms preprocess, 136.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 152.1ms\n",
            "Speed: 4.4ms preprocess, 152.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.8ms\n",
            "Speed: 4.2ms preprocess, 134.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 142.5ms\n",
            "Speed: 4.4ms preprocess, 142.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.2ms\n",
            "Speed: 4.2ms preprocess, 136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 138.6ms\n",
            "Speed: 3.9ms preprocess, 138.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.3ms\n",
            "Speed: 4.2ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.5ms\n",
            "Speed: 4.4ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 150.1ms\n",
            "Speed: 4.3ms preprocess, 150.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 143.3ms\n",
            "Speed: 3.8ms preprocess, 143.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 182.1ms\n",
            "Speed: 4.4ms preprocess, 182.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 210.8ms\n",
            "Speed: 4.2ms preprocess, 210.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 203.8ms\n",
            "Speed: 6.1ms preprocess, 203.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 221.7ms\n",
            "Speed: 4.3ms preprocess, 221.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 193.8ms\n",
            "Speed: 4.4ms preprocess, 193.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 196.6ms\n",
            "Speed: 4.2ms preprocess, 196.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 206.6ms\n",
            "Speed: 4.2ms preprocess, 206.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 198.5ms\n",
            "Speed: 4.0ms preprocess, 198.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 210.3ms\n",
            "Speed: 13.2ms preprocess, 210.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 200.2ms\n",
            "Speed: 4.4ms preprocess, 200.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 220.2ms\n",
            "Speed: 4.0ms preprocess, 220.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 202.7ms\n",
            "Speed: 4.4ms preprocess, 202.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 206.4ms\n",
            "Speed: 8.0ms preprocess, 206.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 254.0ms\n",
            "Speed: 7.2ms preprocess, 254.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 245.9ms\n",
            "Speed: 12.7ms preprocess, 245.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 241.8ms\n",
            "Speed: 4.9ms preprocess, 241.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 230.9ms\n",
            "Speed: 9.4ms preprocess, 230.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 167.3ms\n",
            "Speed: 5.2ms preprocess, 167.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 132.5ms\n",
            "Speed: 4.7ms preprocess, 132.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 132.6ms\n",
            "Speed: 4.4ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 143.5ms\n",
            "Speed: 4.5ms preprocess, 143.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 156.9ms\n",
            "Speed: 4.3ms preprocess, 156.9ms inference, 13.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 475.2ms\n",
            "Speed: 4.3ms preprocess, 475.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.6ms\n",
            "Speed: 4.2ms preprocess, 131.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 144.8ms\n",
            "Speed: 4.1ms preprocess, 144.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.6ms\n",
            "Speed: 4.5ms preprocess, 135.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.3ms\n",
            "Speed: 5.1ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 153.2ms\n",
            "Speed: 4.0ms preprocess, 153.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 135.1ms\n",
            "Speed: 6.4ms preprocess, 135.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 142.3ms\n",
            "Speed: 3.9ms preprocess, 142.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 138.7ms\n",
            "Speed: 4.2ms preprocess, 138.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 137.5ms\n",
            "Speed: 3.9ms preprocess, 137.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 134.7ms\n",
            "Speed: 4.6ms preprocess, 134.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 151.1ms\n",
            "Speed: 4.6ms preprocess, 151.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 138.3ms\n",
            "Speed: 3.9ms preprocess, 138.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 136.8ms\n",
            "Speed: 3.8ms preprocess, 136.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 135.8ms\n",
            "Speed: 3.9ms preprocess, 135.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 137.4ms\n",
            "Speed: 4.1ms preprocess, 137.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 140.0ms\n",
            "Speed: 4.0ms preprocess, 140.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 132.6ms\n",
            "Speed: 4.3ms preprocess, 132.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 153.4ms\n",
            "Speed: 4.7ms preprocess, 153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 132.9ms\n",
            "Speed: 4.4ms preprocess, 132.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 137.0ms\n",
            "Speed: 4.8ms preprocess, 137.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 134.4ms\n",
            "Speed: 5.0ms preprocess, 134.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 138.5ms\n",
            "Speed: 4.4ms preprocess, 138.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 134.5ms\n",
            "Speed: 4.3ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 141.1ms\n",
            "Speed: 4.3ms preprocess, 141.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 168.2ms\n",
            "Speed: 4.9ms preprocess, 168.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 529.4ms\n",
            "Speed: 4.3ms preprocess, 529.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 133.8ms\n",
            "Speed: 4.7ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 155.3ms\n",
            "Speed: 4.9ms preprocess, 155.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 135.7ms\n",
            "Speed: 4.4ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 136.5ms\n",
            "Speed: 4.3ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 138.7ms\n",
            "Speed: 4.3ms preprocess, 138.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 138.9ms\n",
            "Speed: 4.2ms preprocess, 138.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 134.7ms\n",
            "Speed: 4.4ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 134.9ms\n",
            "Speed: 4.4ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 151.5ms\n",
            "Speed: 4.6ms preprocess, 151.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 138.4ms\n",
            "Speed: 4.6ms preprocess, 138.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 136.0ms\n",
            "Speed: 4.6ms preprocess, 136.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 140.8ms\n",
            "Speed: 5.1ms preprocess, 140.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 136.2ms\n",
            "Speed: 4.7ms preprocess, 136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 131.7ms\n",
            "Speed: 4.3ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 suitcase, 148.4ms\n",
            "Speed: 4.4ms preprocess, 148.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 132.9ms\n",
            "Speed: 4.7ms preprocess, 132.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 suitcase, 138.4ms\n",
            "Speed: 4.3ms preprocess, 138.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 132.0ms\n",
            "Speed: 4.8ms preprocess, 132.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 suitcase, 129.5ms\n",
            "Speed: 7.2ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 131.8ms\n",
            "Speed: 4.5ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 135.2ms\n",
            "Speed: 3.9ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 147.7ms\n",
            "Speed: 3.9ms preprocess, 147.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 133.3ms\n",
            "Speed: 4.0ms preprocess, 133.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.4ms\n",
            "Speed: 5.0ms preprocess, 132.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 137.6ms\n",
            "Speed: 3.9ms preprocess, 137.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.3ms\n",
            "Speed: 4.1ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 176.3ms\n",
            "Speed: 4.1ms preprocess, 176.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 203.3ms\n",
            "Speed: 4.4ms preprocess, 203.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 194.1ms\n",
            "Speed: 4.1ms preprocess, 194.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 207.8ms\n",
            "Speed: 3.9ms preprocess, 207.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 205.4ms\n",
            "Speed: 4.5ms preprocess, 205.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 205.2ms\n",
            "Speed: 4.4ms preprocess, 205.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 226.9ms\n",
            "Speed: 4.8ms preprocess, 226.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 256.8ms\n",
            "Speed: 6.3ms preprocess, 256.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 229.8ms\n",
            "Speed: 4.9ms preprocess, 229.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 235.6ms\n",
            "Speed: 10.0ms preprocess, 235.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 240.2ms\n",
            "Speed: 6.0ms preprocess, 240.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 199.4ms\n",
            "Speed: 4.4ms preprocess, 199.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 198.3ms\n",
            "Speed: 4.3ms preprocess, 198.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 200.5ms\n",
            "Speed: 4.8ms preprocess, 200.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 213.5ms\n",
            "Speed: 5.4ms preprocess, 213.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 215.9ms\n",
            "Speed: 4.4ms preprocess, 215.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 213.1ms\n",
            "Speed: 6.4ms preprocess, 213.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 211.9ms\n",
            "Speed: 7.3ms preprocess, 211.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 140.5ms\n",
            "Speed: 4.5ms preprocess, 140.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 139.0ms\n",
            "Speed: 4.5ms preprocess, 139.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 151.9ms\n",
            "Speed: 4.5ms preprocess, 151.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 142.4ms\n",
            "Speed: 4.4ms preprocess, 142.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 136.4ms\n",
            "Speed: 4.3ms preprocess, 136.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.2ms\n",
            "Speed: 4.8ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 133.9ms\n",
            "Speed: 5.1ms preprocess, 133.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.2ms\n",
            "Speed: 4.7ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.8ms\n",
            "Speed: 6.4ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 159.9ms\n",
            "Speed: 6.1ms preprocess, 159.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 139.5ms\n",
            "Speed: 4.7ms preprocess, 139.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 141.2ms\n",
            "Speed: 4.6ms preprocess, 141.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 137.1ms\n",
            "Speed: 4.5ms preprocess, 137.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 137.8ms\n",
            "Speed: 5.0ms preprocess, 137.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 136.2ms\n",
            "Speed: 6.1ms preprocess, 136.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 155.8ms\n",
            "Speed: 5.4ms preprocess, 155.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.4ms\n",
            "Speed: 4.2ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 137.4ms\n",
            "Speed: 4.1ms preprocess, 137.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 137.3ms\n",
            "Speed: 4.3ms preprocess, 137.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 135.9ms\n",
            "Speed: 4.1ms preprocess, 135.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.4ms\n",
            "Speed: 4.6ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 134.7ms\n",
            "Speed: 5.0ms preprocess, 134.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 154.5ms\n",
            "Speed: 5.3ms preprocess, 154.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 136.4ms\n",
            "Speed: 3.9ms preprocess, 136.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 134.6ms\n",
            "Speed: 4.0ms preprocess, 134.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 132.1ms\n",
            "Speed: 4.0ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 135.4ms\n",
            "Speed: 4.2ms preprocess, 135.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 133.5ms\n",
            "Speed: 4.6ms preprocess, 133.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 137.4ms\n",
            "Speed: 4.4ms preprocess, 137.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 143.8ms\n",
            "Speed: 4.6ms preprocess, 143.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 134.6ms\n",
            "Speed: 4.1ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 129.1ms\n",
            "Speed: 4.3ms preprocess, 129.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 133.3ms\n",
            "Speed: 4.2ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.2ms\n",
            "Speed: 5.3ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.2ms\n",
            "Speed: 5.7ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 150.6ms\n",
            "Speed: 4.7ms preprocess, 150.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 133.5ms\n",
            "Speed: 4.1ms preprocess, 133.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 147.4ms\n",
            "Speed: 4.5ms preprocess, 147.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 160.2ms\n",
            "Speed: 5.1ms preprocess, 160.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 160.3ms\n",
            "Speed: 5.4ms preprocess, 160.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 164.2ms\n",
            "Speed: 5.2ms preprocess, 164.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 177.1ms\n",
            "Speed: 5.3ms preprocess, 177.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 154.3ms\n",
            "Speed: 8.7ms preprocess, 154.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 132.1ms\n",
            "Speed: 4.9ms preprocess, 132.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 131.5ms\n",
            "Speed: 4.8ms preprocess, 131.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 129.1ms\n",
            "Speed: 4.7ms preprocess, 129.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 133.9ms\n",
            "Speed: 4.8ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Test completed with rehearsal evaluation.\n",
            "Test Action Buffer: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Test Loss Buffer: [0.041709188371896744, 0.027012869715690613, 0.019092611968517303, 0.1103849858045578, 0.03698299452662468, 0.07111316919326782, 0.045959968119859695, 0.038439806550741196, 0.05333550274372101, 0.014106719754636288, 0.03548605367541313, 0.09105053544044495, 0.02471338026225567, 0.04836174100637436, 0.059648074209690094, 0.020055456086993217, 0.023080959916114807, 0.08508338779211044, 0.012755151838064194, 0.08257423341274261, 0.026771128177642822, 0.021830959245562553, 0.032965037971735, 0.0600731186568737, 0.03159579262137413, 0.04366881400346756, 0.01929669827222824, 0.031316742300987244, 0.025961637496948242, 0.05223188176751137, 0.03215270861983299, 0.03777015581727028, 0.033099543303251266, 0.025028912350535393, 0.0521254688501358, 0.05121259018778801, 0.07460419833660126, 0.05275018513202667, 0.06239003688097, 0.057933319360017776, 0.03594072908163071, 0.04755859076976776, 0.0273718424141407, 0.018170593306422234, 0.057216793298721313, 0.0342273935675621, 0.04828566685318947, 0.04312390089035034, 0.015978248789906502, 0.042199015617370605, 0.07528557628393173, 0.06033101677894592, 0.05269818380475044, 0.05584719404578209, 0.05728108435869217, 0.04201102256774902, 0.04278000444173813, 0.061175815761089325, 0.03248557075858116, 0.07409217953681946, 0.054397255182266235, 0.05877818539738655, 0.04682135209441185, 0.020497730001807213, 0.026452157646417618, 0.025187738239765167, 0.042010270059108734, 0.06982302665710449, 0.0331893227994442, 0.06700613349676132, 0.06728608161211014, 0.06478283554315567, 0.049508675932884216, 0.05743015557527542, 0.024419642984867096, 0.02226521447300911, 0.026041172444820404, 0.035653311759233475, 0.009296609088778496, 0.015821194276213646, 0.07589760422706604, 0.03676621615886688, 0.035522542893886566, 0.06539741903543472, 0.03941866382956505, 0.03577643632888794, 0.03571845963597298, 0.06003664433956146, 0.04124616086483002, 0.012034176848828793, 0.04233763739466667, 0.03997274488210678, 0.034491218626499176, 0.05157436057925224, 0.040525760501623154, 0.02873985655605793, 0.060684509575366974, 0.09987655282020569, 0.03891158476471901, 0.026382220908999443, 0.02437543123960495, 0.04906495660543442, 0.044127702713012695, 0.019922364503145218, 0.03198628127574921, 0.0732918530702591, 0.042305976152420044, 0.057018570601940155, 0.0962643250823021, 0.06074804067611694, 0.05872608721256256, 0.06597726047039032, 0.045150648802518845, 0.08749332278966904, 0.05918993055820465, 0.06229197606444359, 0.04841430485248566, 0.05328599363565445, 0.033512089401483536, 0.0794636458158493, 0.04501677304506302, 0.020426206290721893, 0.021263640373945236, 0.02686706930398941, 0.05977744236588478, 0.08590210229158401, 0.042967334389686584, 0.03417874127626419, 0.03107367269694805, 0.061426568776369095, 0.056747470051050186, 0.0640561580657959, 0.07077890634536743, 0.04132400453090668, 0.039740413427352905, 0.05422638729214668, 0.05105192959308624, 0.04588490352034569, 0.06271764636039734, 0.033905625343322754, 0.0497741624712944, 0.025737779214978218, 0.03310338407754898, 0.055641140788793564, 0.04913375899195671, 0.04219284653663635, 0.0435168631374836, 0.04296455532312393, 0.06733385473489761, 0.030024951323866844, 0.021420558914542198, 0.02829979732632637, 0.03454508259892464, 0.04804534465074539, 0.0635543167591095, 0.05379900708794594, 0.034299422055482864, 0.04507363587617874, 0.026158181950449944, 0.042663175612688065, 0.054513104259967804, 0.06057414039969444, 0.026459291577339172, 0.04512618109583855, 0.04787786677479744, 0.01305939070880413, 0.061800453811883926, 0.04954135790467262, 0.03172910213470459, 0.030867736786603928, 0.08150053769350052, 0.02031295746564865, 0.07391084730625153, 0.031498685479164124, 0.04831512272357941, 0.07965269684791565, 0.025219015777111053, 0.05773434787988663, 0.035500653088092804, 0.08043588697910309, 0.05903725326061249, 0.09984984248876572, 0.0358462817966938, 0.07019276916980743, 0.030400723218917847, 0.057516761124134064, 0.027870049700140953, 0.037728201597929, 0.026233414188027382, 0.06073814630508423, 0.03585954010486603, 0.06455223262310028, 0.04724959284067154, 0.058535486459732056, 0.03405725210905075, 0.03475331887602806, 0.06674491614103317, 0.04196024313569069, 0.047030866146087646, 0.055376362055540085, 0.03664228320121765, 0.04012215510010719, 0.04160263016819954, 0.01614566147327423, 0.05547238886356354, 0.0402371808886528, 0.07350582629442215, 0.0892491564154625, 0.04151839390397072, 0.03910364955663681, 0.10793286561965942, 0.025324931368231773, 0.05015145614743233, 0.035329874604940414, 0.03546793386340141, 0.022341230884194374, 0.039915554225444794, 0.046096812933683395, 0.021900881081819534, 0.03773166611790657, 0.029484253376722336, 0.10235066711902618, 0.04533892497420311, 0.052002064883708954, 0.03202560171484947, 0.09255221486091614, 0.05126519501209259, 0.05237926170229912, 0.030456453561782837, 0.04842711240053177, 0.02880280464887619, 0.046812087297439575, 0.07434085011482239, 0.057689420878887177, 0.0681895837187767, 0.0537949874997139, 0.04504435881972313, 0.0644615963101387, 0.06652139127254486, 0.033899929374456406, 0.043158452957868576, 0.025713996961712837, 0.023230820894241333, 0.05155443400144577, 0.12591037154197693, 0.04430471360683441, 0.06873217225074768, 0.04006002098321915, 0.07522295415401459, 0.04138273745775223, 0.03837955743074417, 0.05764906108379364, 0.06300866603851318, 0.049613773822784424, 0.041546694934368134, 0.07967251539230347, 0.059796202927827835, 0.04877564311027527, 0.029026392847299576, 0.022973837330937386, 0.061988040804862976, 0.04999935254454613, 0.07970881462097168, 0.020501064136624336, 0.0346706360578537, 0.09934399276971817, 0.010286270640790462, 0.03202943503856659, 0.05971015617251396, 0.06451787054538727, 0.07643913477659225, 0.02355276606976986, 0.0639406368136406, 0.04215000942349434, 0.03736303001642227, 0.08190061151981354, 0.049277327954769135, 0.026302672922611237, 0.052903398871421814, 0.02365099824965, 0.0447387620806694, 0.03593890368938446, 0.060954749584198, 0.03589200600981712, 0.04947488009929657, 0.05916823446750641, 0.06445034593343735, 0.01980629935860634, 0.009194099344313145, 0.04933752119541168, 0.04103147238492966, 0.0520491898059845, 0.06040305644273758, 0.04063177481293678, 0.058877088129520416, 0.02684573084115982, 0.03180725872516632, 0.06065372750163078, 0.08777802437543869, 0.02793605998158455, 0.04366779327392578, 0.04210379719734192, 0.03863823413848877, 0.061563778668642044, 0.028468262404203415, 0.012402493506669998, 0.03158365935087204, 0.015662413090467453, 0.021277885884046555, 0.07257717847824097, 0.032341841608285904, 0.04693146422505379, 0.07845203578472137, 0.05372583121061325, 0.016086313873529434, 0.0496646873652935, 0.02449386939406395, 0.0520591102540493, 0.03654427081346512, 0.049140121787786484, 0.05047072842717171, 0.048704054206609726, 0.04793545976281166, 0.05202034115791321, 0.07656262814998627, 0.08053610473871231, 0.04980522021651268, 0.0760621726512909, 0.054446421563625336, 0.02564164064824581, 0.03685896843671799, 0.03709016740322113, 0.030168810859322548, 0.023395013064146042, 0.04526394605636597, 0.04033711180090904, 0.03186212480068207, 0.06041578948497772, 0.04876894876360893, 0.08148110657930374, 0.03762991726398468, 0.07673030346632004, 0.06985419988632202, 0.03687331825494766, 0.07699203491210938, 0.031615000218153, 0.04838448017835617, 0.037090688943862915, 0.0411798320710659, 0.054023198783397675, 0.043011926114559174, 0.027462517842650414, 0.018018843606114388, 0.026587169617414474, 0.03951921686530113, 0.040470272302627563, 0.039342910051345825, 0.020569492131471634, 0.10271341353654861, 0.029648099094629288, 0.019408011808991432, 0.047762930393218994, 0.06306929886341095, 0.08113506436347961, 0.03787289559841156, 0.010004982352256775, 0.04394443333148956, 0.046055376529693604, 0.04111329838633537, 0.02993648871779442, 0.044170230627059937, 0.05876273661851883, 0.0468050092458725, 0.09579996019601822, 0.054563332349061966, 0.0385652557015419, 0.02376094087958336, 0.014835200272500515, 0.05816604942083359, 0.03498569130897522, 0.05201304331421852, 0.046175431460142136, 0.03864748403429985, 0.05005622282624245, 0.0550370030105114, 0.039007265120744705, 0.04256140813231468, 0.044195756316185, 0.04941019415855408, 0.024302050471305847, 0.02576533891260624, 0.034419991075992584, 0.03868444263935089, 0.020214896649122238, 0.058878399431705475, 0.032556988298892975, 0.02703709341585636, 0.033606670796871185, 0.028456861153244972, 0.02249482460319996, 0.05791288986802101, 0.038068778812885284, 0.04824405536055565, 0.009779890067875385, 0.030617065727710724, 0.0488726906478405, 0.06404968351125717, 0.037076689302921295, 0.08525430411100388, 0.07053360342979431, 0.031770821660757065, 0.027389533817768097, 0.053864262998104095, 0.1003623828291893, 0.052287958562374115, 0.043746814131736755, 0.03466784954071045, 0.037962477654218674, 0.05853390693664551, 0.06754383444786072, 0.014192400500178337, 0.058064162731170654, 0.055995479226112366, 0.06962191313505173, 0.04512877017259598, 0.06200762465596199, 0.03676874563097954, 0.07160881161689758, 0.0650588721036911, 0.06836515665054321, 0.03458390012383461, 0.07332806289196014, 0.0825425460934639, 0.031412992626428604, 0.021689850836992264, 0.034530192613601685, 0.02597137913107872, 0.0334458164870739, 0.035831183195114136, 0.04389164596796036, 0.046020910143852234, 0.0580679327249527, 0.04497778043150902, 0.05191092565655708, 0.03844289481639862, 0.0434788353741169, 0.01751617342233658, 0.03539359197020531, 0.058755435049533844, 0.03627018630504608, 0.038229405879974365, 0.03653253987431526, 0.042719416320323944, 0.05509808659553528, 0.04736986383795738, 0.034795645624399185, 0.06771127879619598, 0.020592032000422478, 0.053049132227897644, 0.024711130186915398, 0.0773017555475235, 0.05068642646074295, 0.05404837429523468, 0.016458481550216675, 0.06263826042413712, 0.04988374561071396, 0.08504517376422882, 0.057017624378204346, 0.07653548568487167, 0.08816463500261307, 0.05761224031448364, 0.05272306874394417, 0.02069242112338543, 0.07459422945976257, 0.03386550396680832, 0.016821103170514107, 0.08151701837778091, 0.022096892818808556, 0.02852463535964489, 0.032876644283533096, 0.04176438972353935, 0.043426867574453354, 0.05899158865213394, 0.07977950572967529, 0.05774512141942978, 0.014359838329255581, 0.042788587510585785, 0.03682379797101021, 0.0467575266957283, 0.07650421559810638, 0.022726288065314293, 0.0649452656507492, 0.04297411069273949, 0.049395959824323654, 0.04722815006971359, 0.030608713626861572, 0.04582011699676514, 0.0469215027987957, 0.04460746794939041, 0.025115706026554108, 0.05020206421613693, 0.01772717759013176, 0.04053119570016861, 0.06985229253768921, 0.03934561088681221, 0.03231922537088394, 0.04056193679571152, 0.03575480356812477, 0.07187441736459732, 0.09017953276634216, 0.08585917204618454, 0.0719916969537735, 0.05324114114046097, 0.012837651185691357, 0.010010840371251106, 0.02217409387230873, 0.03350674360990524, 0.062151916325092316, 0.07111614942550659, 0.07051025331020355]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 라벨 설정\n",
        "test_frame_labels = truck8['go_stop_decision'] # 여기에 driving12, truck8, uturn7을 값을 바꿔가며 넣기"
      ],
      "metadata": {
        "id": "4pjAszcxeb7O"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 타입 및 길이 확인\n",
        "print(type(test_action_buffer))\n",
        "print(type(test_frame_labels))\n",
        "print(len(test_action_buffer))\n",
        "print(len(test_frame_labels))"
      ],
      "metadata": {
        "id": "BI0X97J3eimB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5868c172-7d40-4da2-b7ab-bca6617ee93d"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "185\n",
            "185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과 저장\n",
        "final_tasks.append(test_action_buffer)\n",
        "final_labels.append(test_frame_labels)"
      ],
      "metadata": {
        "id": "LlBtn2FXelZE"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CL 메트릭 계산\n",
        "IM, FWT, BWT = compute_cl_metrics(final_tasks, final_labels)\n",
        "\n",
        "print(f\"IM (Initial Accuracy): {IM:.5f}\")\n",
        "print(f\"FWT (Forward Transfer): {FWT:.5f}\")\n",
        "print(f\"BWT (Backward Transfer): {BWT:.5f}\")\n"
      ],
      "metadata": {
        "id": "PhNoEDpIenp7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486b9a66-faf9-4bfa-b774-62aee52f338d"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task accuracies: [        0.4]\n",
            "IM (Initial Accuracy): 0.40000\n",
            "FWT (Forward Transfer): 0.00000\n",
            "BWT (Backward Transfer): 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rehearsal 메모리 상태 확인\n",
        "print(f\"Rehearsal memory contains {len(rehearsal_memory.data_buffer)} samples\")\n",
        "print(f\"Memory usage: {len(rehearsal_memory.data_buffer)} / {rehearsal_memory.max_samples}\")"
      ],
      "metadata": {
        "id": "3uicDJRAevZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e3aac1-afc3-434e-fa05-c3bf31ef664b"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rehearsal memory contains 900 samples\n",
            "Memory usage: 900 / 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 샘플의 일부 확인\n",
        "if len(rehearsal_memory.data_buffer) > 0:\n",
        "    sample_data = rehearsal_memory.data_buffer[0]\n",
        "    sample_label = rehearsal_memory.label_buffer[0]\n",
        "    print(f\"Sample data shape: {sample_data.shape}\")\n",
        "    print(f\"Sample label: {sample_label}\")"
      ],
      "metadata": {
        "id": "8OS6l0PUerVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9f8ea2-0ed5-422e-c2a0-fd3a3c5a0bfe"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data shape: (15,)\n",
            "Sample label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_tasks)"
      ],
      "metadata": {
        "id": "BRxnw3SKeynN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "962534a4-9805-4443-bf7a-a9c637d925e0"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task3 학습"
      ],
      "metadata": {
        "id": "DmsT56bGn70J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Uturn 5 학습 (라벨 미포함)"
      ],
      "metadata": {
        "id": "_VH6mWW5oAYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출 (Uturn5)\n",
        "train_video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "XLjZPXVKpFXm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "a7b6287d-616e-4c31-eaec-929ef665c902"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-35c3b0c3-0015-444d-9c49-d7ffb249381a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-35c3b0c3-0015-444d-9c49-d7ffb249381a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Uturn_5.mov to Uturn_5 (1).mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 모드 설정\n",
        "fm_model.train()\n",
        "loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "ExtADNQ020Yl"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 네 번째 태스크 학습 (rehearsal 방식) =====\n",
        "cap = cv2.VideoCapture(train_video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "new_task_data = []\n",
        "new_task_labels = []\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame_idx += 1\n",
        "    step += 1\n",
        "\n",
        "    result = model(frame)[0]\n",
        "    h, w, _ = frame.shape\n",
        "    frame_actions = []\n",
        "\n",
        "    for box in result.boxes:\n",
        "        cls_id = int(box.cls[0])\n",
        "        conf = float(box.conf[0])\n",
        "        if conf <= 0.6:\n",
        "            continue\n",
        "        else:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 노이즈에 대한 일관성 손실\n",
        "            consistency_loss = loss_fn(emb_noisy, emb_orig.detach())\n",
        "\n",
        "            # Rehearsal 손실: 이전 태스크 데이터와 함께 학습\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                # 이전 태스크 데이터에 대한 예측\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            # 총 손실 = 일관성 손실 + rehearsal 손실\n",
        "            total_loss = consistency_loss + 0.5 * rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                loss_buffer.append(total_loss.item())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # 새로운 태스크 데이터 저장 (numpy 배열로 변환)\n",
        "            new_task_data.append(x.detach().cpu().numpy().squeeze(0))\n",
        "            # 라벨이 없으므로 예측값을 pseudo-label로 사용\n",
        "            new_task_labels.append(y_pred.detach().cpu().numpy().squeeze(0))\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "    final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "    if measuring_loss:\n",
        "        action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# 새로운 태스크 데이터를 rehearsal 메모리에 추가\n",
        "rehearsal_memory.add_samples(new_task_data, new_task_labels)\n",
        "\n",
        "print(\"Second task completed with rehearsal learning.\")\n",
        "print(\"Rehearsal Action Buffer:\", action_buffer)\n",
        "print(\"Loss Buffer:\", loss_buffer)\n",
        "print(f\"Rehearsal memory size: {len(rehearsal_memory.data_buffer)}\")\n"
      ],
      "metadata": {
        "id": "ZQyS94LRpFXm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30f1b10-afe9-4918-f6d6-58804e64bb65"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 cars, 150.2ms\n",
            "Speed: 3.7ms preprocess, 150.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.2ms\n",
            "Speed: 5.2ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.9ms\n",
            "Speed: 4.7ms preprocess, 135.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.1ms\n",
            "Speed: 4.5ms preprocess, 134.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.1ms\n",
            "Speed: 4.4ms preprocess, 135.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.2ms\n",
            "Speed: 4.3ms preprocess, 134.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.3ms\n",
            "Speed: 4.0ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 149.5ms\n",
            "Speed: 4.2ms preprocess, 149.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.9ms\n",
            "Speed: 4.4ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 133.4ms\n",
            "Speed: 4.2ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 133.4ms\n",
            "Speed: 4.1ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.5ms\n",
            "Speed: 4.1ms preprocess, 132.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 135.5ms\n",
            "Speed: 4.1ms preprocess, 135.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 151.5ms\n",
            "Speed: 4.9ms preprocess, 151.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 161.2ms\n",
            "Speed: 4.4ms preprocess, 161.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 135.7ms\n",
            "Speed: 4.4ms preprocess, 135.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 139.4ms\n",
            "Speed: 4.5ms preprocess, 139.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 134.5ms\n",
            "Speed: 4.6ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 136.1ms\n",
            "Speed: 4.6ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 142.7ms\n",
            "Speed: 4.3ms preprocess, 142.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 151.7ms\n",
            "Speed: 4.6ms preprocess, 151.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 132.1ms\n",
            "Speed: 4.3ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 136.0ms\n",
            "Speed: 4.5ms preprocess, 136.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 134.6ms\n",
            "Speed: 4.8ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 139.5ms\n",
            "Speed: 4.6ms preprocess, 139.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 138.7ms\n",
            "Speed: 4.9ms preprocess, 138.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 kite, 149.1ms\n",
            "Speed: 4.5ms preprocess, 149.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.2ms\n",
            "Speed: 4.1ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.9ms\n",
            "Speed: 4.2ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.1ms\n",
            "Speed: 4.0ms preprocess, 135.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.9ms\n",
            "Speed: 4.8ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.1ms\n",
            "Speed: 4.4ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.2ms\n",
            "Speed: 4.5ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 147.5ms\n",
            "Speed: 4.4ms preprocess, 147.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.4ms\n",
            "Speed: 4.0ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.6ms\n",
            "Speed: 4.0ms preprocess, 132.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 143.6ms\n",
            "Speed: 4.1ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.1ms\n",
            "Speed: 4.3ms preprocess, 132.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 140.0ms\n",
            "Speed: 4.3ms preprocess, 140.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 153.2ms\n",
            "Speed: 4.3ms preprocess, 153.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.4ms\n",
            "Speed: 4.1ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 137.8ms\n",
            "Speed: 4.8ms preprocess, 137.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.9ms\n",
            "Speed: 4.6ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.9ms\n",
            "Speed: 5.0ms preprocess, 130.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.3ms\n",
            "Speed: 4.5ms preprocess, 135.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.2ms\n",
            "Speed: 4.2ms preprocess, 135.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 153.0ms\n",
            "Speed: 4.0ms preprocess, 153.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.3ms\n",
            "Speed: 3.9ms preprocess, 135.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 135.7ms\n",
            "Speed: 4.0ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 133.8ms\n",
            "Speed: 4.0ms preprocess, 133.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 137.7ms\n",
            "Speed: 4.1ms preprocess, 137.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.4ms\n",
            "Speed: 4.0ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 152.1ms\n",
            "Speed: 4.1ms preprocess, 152.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.2ms\n",
            "Speed: 4.2ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 133.0ms\n",
            "Speed: 4.0ms preprocess, 133.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 137.0ms\n",
            "Speed: 4.1ms preprocess, 137.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 163.2ms\n",
            "Speed: 4.0ms preprocess, 163.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 205.1ms\n",
            "Speed: 7.3ms preprocess, 205.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 204.1ms\n",
            "Speed: 4.8ms preprocess, 204.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 199.9ms\n",
            "Speed: 4.5ms preprocess, 199.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 200.2ms\n",
            "Speed: 4.4ms preprocess, 200.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 198.8ms\n",
            "Speed: 7.1ms preprocess, 198.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 207.4ms\n",
            "Speed: 10.7ms preprocess, 207.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 222.7ms\n",
            "Speed: 4.5ms preprocess, 222.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 197.8ms\n",
            "Speed: 8.4ms preprocess, 197.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 201.4ms\n",
            "Speed: 4.7ms preprocess, 201.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 199.4ms\n",
            "Speed: 4.4ms preprocess, 199.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 213.5ms\n",
            "Speed: 4.6ms preprocess, 213.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 201.3ms\n",
            "Speed: 4.5ms preprocess, 201.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 213.9ms\n",
            "Speed: 7.1ms preprocess, 213.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 209.5ms\n",
            "Speed: 4.1ms preprocess, 209.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 218.1ms\n",
            "Speed: 4.5ms preprocess, 218.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 230.6ms\n",
            "Speed: 4.4ms preprocess, 230.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 136.6ms\n",
            "Speed: 11.4ms preprocess, 136.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 truck, 132.6ms\n",
            "Speed: 4.8ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.0ms\n",
            "Speed: 4.4ms preprocess, 136.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.5ms\n",
            "Speed: 4.5ms preprocess, 133.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.2ms\n",
            "Speed: 4.5ms preprocess, 136.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 154.9ms\n",
            "Speed: 4.7ms preprocess, 154.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.1ms\n",
            "Speed: 4.4ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 138.3ms\n",
            "Speed: 5.1ms preprocess, 138.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.1ms\n",
            "Speed: 5.5ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.3ms\n",
            "Speed: 4.9ms preprocess, 133.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.5ms\n",
            "Speed: 4.5ms preprocess, 132.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.6ms\n",
            "Speed: 4.7ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 152.9ms\n",
            "Speed: 5.5ms preprocess, 152.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.1ms\n",
            "Speed: 4.9ms preprocess, 137.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.2ms\n",
            "Speed: 4.5ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.1ms\n",
            "Speed: 4.4ms preprocess, 134.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.2ms\n",
            "Speed: 4.5ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.3ms\n",
            "Speed: 4.3ms preprocess, 134.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 152.3ms\n",
            "Speed: 4.3ms preprocess, 152.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 138.4ms\n",
            "Speed: 4.4ms preprocess, 138.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.8ms\n",
            "Speed: 4.8ms preprocess, 136.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.0ms\n",
            "Speed: 4.7ms preprocess, 136.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 141.8ms\n",
            "Speed: 4.2ms preprocess, 141.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.9ms\n",
            "Speed: 4.6ms preprocess, 134.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.4ms\n",
            "Speed: 4.5ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 149.2ms\n",
            "Speed: 4.6ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.9ms\n",
            "Speed: 4.8ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.8ms\n",
            "Speed: 4.5ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.3ms\n",
            "Speed: 4.2ms preprocess, 135.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.9ms\n",
            "Speed: 4.5ms preprocess, 136.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.5ms\n",
            "Speed: 4.1ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.7ms\n",
            "Speed: 4.0ms preprocess, 135.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 157.6ms\n",
            "Speed: 4.5ms preprocess, 157.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.1ms\n",
            "Speed: 4.3ms preprocess, 134.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.6ms\n",
            "Speed: 4.0ms preprocess, 135.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.2ms\n",
            "Speed: 4.0ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.5ms\n",
            "Speed: 4.2ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.4ms\n",
            "Speed: 4.2ms preprocess, 132.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 149.3ms\n",
            "Speed: 4.4ms preprocess, 149.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 139.1ms\n",
            "Speed: 4.4ms preprocess, 139.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.0ms\n",
            "Speed: 4.9ms preprocess, 134.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.6ms\n",
            "Speed: 4.3ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.4ms\n",
            "Speed: 4.6ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.7ms\n",
            "Speed: 4.3ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.2ms\n",
            "Speed: 4.2ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 154.6ms\n",
            "Speed: 4.2ms preprocess, 154.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 130.8ms\n",
            "Speed: 4.1ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.9ms\n",
            "Speed: 5.7ms preprocess, 136.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.1ms\n",
            "Speed: 4.9ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.6ms\n",
            "Speed: 4.4ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.2ms\n",
            "Speed: 4.4ms preprocess, 128.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.1ms\n",
            "Speed: 4.6ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 148.5ms\n",
            "Speed: 4.3ms preprocess, 148.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.6ms\n",
            "Speed: 4.6ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.0ms\n",
            "Speed: 4.6ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.0ms\n",
            "Speed: 4.6ms preprocess, 130.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.7ms\n",
            "Speed: 4.3ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.1ms\n",
            "Speed: 4.3ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.7ms\n",
            "Speed: 4.4ms preprocess, 129.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 147.4ms\n",
            "Speed: 4.3ms preprocess, 147.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.4ms\n",
            "Speed: 4.5ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.7ms\n",
            "Speed: 4.0ms preprocess, 128.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.5ms\n",
            "Speed: 4.0ms preprocess, 129.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.8ms\n",
            "Speed: 4.0ms preprocess, 128.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 151.0ms\n",
            "Speed: 3.9ms preprocess, 151.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 205.4ms\n",
            "Speed: 4.2ms preprocess, 205.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 205.7ms\n",
            "Speed: 6.1ms preprocess, 205.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 196.2ms\n",
            "Speed: 6.9ms preprocess, 196.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 197.7ms\n",
            "Speed: 4.6ms preprocess, 197.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 194.3ms\n",
            "Speed: 4.6ms preprocess, 194.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 airplane, 207.2ms\n",
            "Speed: 4.5ms preprocess, 207.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 201.8ms\n",
            "Speed: 11.0ms preprocess, 201.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 194.0ms\n",
            "Speed: 6.2ms preprocess, 194.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 207.1ms\n",
            "Speed: 4.3ms preprocess, 207.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 202.6ms\n",
            "Speed: 4.3ms preprocess, 202.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 198.4ms\n",
            "Speed: 7.7ms preprocess, 198.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 191.3ms\n",
            "Speed: 5.2ms preprocess, 191.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 206.4ms\n",
            "Speed: 4.3ms preprocess, 206.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 202.0ms\n",
            "Speed: 5.4ms preprocess, 202.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 214.8ms\n",
            "Speed: 4.5ms preprocess, 214.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 201.4ms\n",
            "Speed: 8.5ms preprocess, 201.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.1ms\n",
            "Speed: 4.0ms preprocess, 132.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.2ms\n",
            "Speed: 4.4ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.0ms\n",
            "Speed: 4.2ms preprocess, 130.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 137.5ms\n",
            "Speed: 4.3ms preprocess, 137.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.3ms\n",
            "Speed: 4.5ms preprocess, 135.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.0ms\n",
            "Speed: 4.7ms preprocess, 129.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.8ms\n",
            "Speed: 4.5ms preprocess, 129.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 134.4ms\n",
            "Speed: 4.5ms preprocess, 134.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.4ms\n",
            "Speed: 4.4ms preprocess, 126.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.9ms\n",
            "Speed: 4.5ms preprocess, 130.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 149.7ms\n",
            "Speed: 4.5ms preprocess, 149.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.3ms\n",
            "Speed: 4.5ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.5ms\n",
            "Speed: 4.4ms preprocess, 128.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.2ms\n",
            "Speed: 4.4ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 airplane, 131.3ms\n",
            "Speed: 4.5ms preprocess, 131.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 airplane, 131.1ms\n",
            "Speed: 5.1ms preprocess, 131.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 136.9ms\n",
            "Speed: 9.8ms preprocess, 136.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 149.9ms\n",
            "Speed: 4.5ms preprocess, 149.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.4ms\n",
            "Speed: 4.5ms preprocess, 135.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.5ms\n",
            "Speed: 4.4ms preprocess, 128.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.4ms\n",
            "Speed: 6.7ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.3ms\n",
            "Speed: 5.4ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.0ms\n",
            "Speed: 4.8ms preprocess, 130.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 146.5ms\n",
            "Speed: 4.7ms preprocess, 146.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.6ms\n",
            "Speed: 4.7ms preprocess, 132.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.0ms\n",
            "Speed: 4.8ms preprocess, 131.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 2 kites, 135.7ms\n",
            "Speed: 4.4ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.1ms\n",
            "Speed: 4.1ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 125.3ms\n",
            "Speed: 7.1ms preprocess, 125.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 135.7ms\n",
            "Speed: 4.0ms preprocess, 135.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 151.3ms\n",
            "Speed: 4.0ms preprocess, 151.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 132.3ms\n",
            "Speed: 4.4ms preprocess, 132.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 kite, 133.4ms\n",
            "Speed: 4.7ms preprocess, 133.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 135.0ms\n",
            "Speed: 4.6ms preprocess, 135.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 143.8ms\n",
            "Speed: 4.9ms preprocess, 143.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 kite, 141.2ms\n",
            "Speed: 4.6ms preprocess, 141.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 airplane, 133.8ms\n",
            "Speed: 4.0ms preprocess, 133.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 149.2ms\n",
            "Speed: 5.2ms preprocess, 149.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 131.6ms\n",
            "Speed: 4.6ms preprocess, 131.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 140.5ms\n",
            "Speed: 4.6ms preprocess, 140.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 128.7ms\n",
            "Speed: 4.9ms preprocess, 128.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.0ms\n",
            "Speed: 4.5ms preprocess, 129.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.6ms\n",
            "Speed: 4.3ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 144.8ms\n",
            "Speed: 4.2ms preprocess, 144.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.4ms\n",
            "Speed: 4.1ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.2ms\n",
            "Speed: 4.0ms preprocess, 131.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 130.0ms\n",
            "Speed: 4.2ms preprocess, 130.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.1ms\n",
            "Speed: 4.5ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.2ms\n",
            "Speed: 4.4ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.9ms\n",
            "Speed: 5.2ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 146.7ms\n",
            "Speed: 4.0ms preprocess, 146.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 133.0ms\n",
            "Speed: 5.0ms preprocess, 133.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.6ms\n",
            "Speed: 4.4ms preprocess, 129.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.7ms\n",
            "Speed: 4.3ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.3ms\n",
            "Speed: 4.5ms preprocess, 135.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.8ms\n",
            "Speed: 4.4ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 141.1ms\n",
            "Speed: 4.8ms preprocess, 141.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 145.1ms\n",
            "Speed: 4.2ms preprocess, 145.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.7ms\n",
            "Speed: 5.4ms preprocess, 132.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 304.9ms\n",
            "Speed: 4.9ms preprocess, 304.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 299.7ms\n",
            "Speed: 7.1ms preprocess, 299.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 214.6ms\n",
            "Speed: 4.8ms preprocess, 214.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 199.4ms\n",
            "Speed: 9.0ms preprocess, 199.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 194.1ms\n",
            "Speed: 4.3ms preprocess, 194.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 190.2ms\n",
            "Speed: 4.3ms preprocess, 190.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 207.5ms\n",
            "Speed: 4.3ms preprocess, 207.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 198.2ms\n",
            "Speed: 6.8ms preprocess, 198.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Second task completed with rehearsal learning.\n",
            "Rehearsal Action Buffer: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Loss Buffer: [0.21263432502746582, 0.25857076048851013, 0.3389688730239868, 0.24148285388946533, 0.18101570010185242, 0.17303767800331116, 0.21629910171031952, 0.327926903963089, 0.15108650922775269, 0.19588398933410645, 0.3217637836933136, 0.13185395300388336, 0.17466239631175995, 0.12004157900810242, 0.1605074107646942, 0.1496599018573761, 0.10582607984542847, 0.31011316180229187, 0.13200484216213226, 0.08914873003959656, 0.07929714024066925, 0.11793123185634613, 0.11131016910076141, 0.06602030247449875, 0.2961684763431549, 0.10017939656972885, 0.05605718865990639, 0.2888360917568207, 0.08985063433647156, 0.04968687519431114, 0.28346335887908936, 0.08256057649850845, 0.04435082897543907, 0.2786356806755066, 0.5282779335975647, 0.6243489980697632, 0.45248645544052124, 0.2246241420507431, 0.5407928228378296, 0.6071640849113464, 0.2240561693906784, 0.525640606880188, 0.5817229151725769, 0.22071881592273712, 0.5127175450325012, 0.5309697985649109, 0.5035403966903687, 0.47907567024230957, 0.21463197469711304, 0.4877597987651825, 0.4295162856578827, 0.21197138726711273, 0.46309390664100647, 0.3902970254421234, 0.20637038350105286, 0.43848568201065063, 0.3549475073814392, 0.20304694771766663, 0.3248615264892578, 0.40189290046691895, 0.19866417348384857, 0.3838198781013489, 0.28934571146965027, 0.191949725151062, 0.2728714048862457, 0.3500130772590637, 0.18717913329601288, 0.2551894187927246, 0.3236665427684784, 0.24020400643348694, 0.30596035718917847, 0.2969124913215637, 0.2235306054353714, 0.2813332676887512, 0.21448826789855957, 0.2667844295501709, 0.20458370447158813, 0.2501380741596222, 0.19601933658123016, 0.23381629586219788, 0.18824562430381775, 0.21810051798820496, 0.18069525063037872, 0.2033621221780777, 0.17484621703624725, 0.18997807800769806, 0.16823790967464447, 0.17856153845787048, 0.16292642056941986, 0.16816624999046326, 0.15835003554821014, 0.15875695645809174, 0.1533978134393692, 0.15007047355175018, 0.14913393557071686, 0.3803260624408722, 0.39290180802345276, 0.1375759243965149, 0.1436200886964798, 0.13397051393985748, 0.14184710383415222, 0.1300356090068817, 0.13860797882080078, 0.13828809559345245, 0.12435772269964218, 0.13575366139411926, 0.1218138188123703, 0.1329548954963684, 0.11813785135746002, 0.1296181082725525, 0.11466033011674881, 0.1264861524105072, 0.11303630471229553, 0.11311408132314682, 0.12928465008735657, 0.1197737604379654, 0.11956228315830231, 0.1086202934384346, 0.11710980534553528, 0.10802481323480606, 0.1236671656370163, 0.12265624105930328, 0.11309942603111267, 0.11300565302371979, 0.11204167455434799, 0.11794809997081757, 0.10965733230113983, 0.10980161279439926, 0.11545498669147491, 0.11582670360803604, 0.11362101137638092, 0.1056218072772026, 0.1121121197938919, 0.11423957347869873, 0.10288633406162262, 0.11034805327653885, 0.11375993490219116, 0.10022664070129395, 0.10807424038648605, 0.09842859208583832, 0.10689550638198853, 0.11354035139083862, 0.09607022255659103, 0.10476168990135193, 0.0942973792552948, 0.10372903198003769, 0.09221991151571274, 0.10357578098773956, 0.09060703217983246, 0.08909044414758682, 0.08784205466508865, 0.09705337136983871, 0.09520046412944794, 0.08507855981588364, 0.08403560519218445, 0.09172356873750687, 0.08309949189424515, 0.08068136125802994, 0.08452340960502625, 0.07707889378070831, 0.07531324774026871, 0.07415373623371124, 0.06165207922458649, 0.5704616904258728, 0.06696801632642746, 0.06453963369131088, 0.06255749613046646, 0.06139019876718521, 0.06061330810189247, 0.06754345446825027, 0.06629858911037445, 0.05493536219000816, 0.053147539496421814, 0.06170259416103363, 0.05066141486167908, 0.05909543111920357, 0.04863835871219635, 0.046531349420547485, 0.04497896134853363, 0.06649253517389297, 0.04254910349845886, 0.04965412616729736, 0.03984031826257706, 0.08217434585094452, 0.03771507740020752, 0.08513904362916946, 0.03551868349313736, 0.08658719807863235, 0.04427154362201691, 0.08727657794952393, 0.03203766047954559, 0.030387263745069504, 0.029246091842651367, 0.02825031243264675, 0.02709348313510418, 0.02646121382713318, 0.026475870981812477, 0.026547959074378014, 0.06739199161529541, 0.026025135070085526, 0.06532490998506546, 0.02565206028521061, 0.02571115829050541, 0.0627390444278717, 0.02414243295788765, 0.030895618721842766, 0.03004639223217964, 0.030375640839338303, 0.03089260123670101, 0.023949652910232544, 0.030075211077928543, 0.023379778489470482, 0.022855395451188087, 0.021654509007930756, 0.021268831565976143, 0.01990215852856636, 0.019134795293211937, 0.0183523241430521, 0.017134854570031166, 0.016421977430582047, 0.015244731679558754, 0.01448195893317461, 0.013987403362989426, 0.013385282829403877, 0.012636343948543072, 0.011435162276029587, 0.010896285995841026, 0.012606993317604065, 0.009997877292335033, 0.009502746164798737, 0.008673567324876785, 0.00830660667270422, 0.00757718225941062, 0.006963944528251886, 0.007946529425680637, 0.0062958174385130405, 0.007263263687491417, 0.006392709445208311, 0.0060665784403681755, 0.005266112741082907, 0.0047412752173841, 0.8725939989089966, 0.8837761282920837, 0.8857192993164062, 0.8879403471946716, 0.889151930809021, 0.894506573677063, 0.8925232291221619, 0.8922939300537109, 0.8926197290420532, 0.8874508142471313, 0.8835626840591431, 0.8814855813980103, 0.8757755160331726, 0.8757005929946899, 0.8665307760238647, 0.8551257252693176, 0.8454599380493164, 0.8347617387771606, 0.8219482898712158, 0.8068317770957947, 0.7907668948173523, 0.7717898488044739, 0.7506366968154907, 0.7282410860061646, 0.7037431001663208, 0.6769790649414062, 0.6473711729049683, 0.6156364679336548, 0.5810166597366333, 0.5438334941864014, 0.505216121673584, 0.4641435444355011, 0.4224313497543335, 0.38036319613456726, 0.33912575244903564, 0.2981168329715729, 0.25914058089256287, 0.2239052653312683, 0.26827511191368103, 0.16200250387191772, 0.13822795450687408, 0.11585456877946854, 0.09838703274726868, 0.0822964608669281, 0.0686635971069336, 0.05810470134019852, 0.04970395565032959, 0.04251781851053238, 0.06733623892068863, 0.030451511964201927, 0.04991564899682999, 0.02294079214334488, 0.03875613957643509, 0.01760311983525753, 0.031265102326869965, 0.013618161901831627, 0.026378871873021126, 0.01153454277664423, 0.022140467539429665, 0.009151442907750607, 0.018772920593619347, 0.007919611409306526, 0.01603025197982788, 0.006427675485610962, 0.00492611899971962, 0.011203156784176826, 0.00898811500519514, 0.004133753944188356, 0.0049295127391815186, 0.009955145418643951, 0.014524949714541435, 0.006653268355876207, 0.019949711859226227, 0.014257258735597134, 0.017940636724233627, 0.03719994053244591, 0.6153067946434021, 0.5639525651931763, 0.5137622356414795, 0.47006282210350037, 0.4296417236328125, 0.5529211163520813, 0.38504043221473694, 0.34566086530685425, 0.32827243208885193, 0.3113107979297638, 0.2962275445461273, 0.2851378321647644, 0.2717738747596741, 0.1571742296218872, 0.25263917446136475, 0.24185915291309357, 0.14908280968666077, 0.22661463916301727, 0.1440013200044632, 0.20822358131408691, 0.13950222730636597, 0.19782137870788574, 0.19225680828094482, 0.18720291554927826, 0.1800668090581894, 0.17611846327781677, 0.17398297786712646, 0.17154556512832642, 0.16880744695663452, 0.16630437970161438, 0.16422878205776215, 0.16162990033626556, 0.159407839179039, 0.16023613512516022, 0.19426938891410828, 0.1541980504989624, 0.18988190591335297, 0.1495572328567505, 0.14711792767047882, 0.1448511928319931, 0.38263094425201416, 0.13968676328659058, 0.13711993396282196, 0.13557587563991547, 0.1334105134010315, 0.13245905935764313, 0.1311711072921753, 0.13087725639343262, 0.13101975619792938, 0.23807398974895477, 0.12570077180862427, 0.2332979440689087, 0.1209041029214859, 0.22422710061073303, 0.21915051341056824, 0.21645595133304596, 0.218618705868721, 0.14521969854831696, 0.21264703571796417, 0.10865865647792816, 0.13524377346038818, 0.1324838250875473, 0.10012808442115784, 0.1859426647424698, 0.0966501384973526, 0.09273813664913177, 0.09257148206233978, 0.17843341827392578, 0.08809170126914978, 0.08657700568437576, 0.16834840178489685, 0.08361701667308807, 0.1571682095527649, 0.07703348249197006, 0.07500843703746796, 0.1470731645822525, 0.0676218569278717, 0.06561630964279175, 0.12972700595855713, 0.12738515436649323, 0.06040961667895317, 0.11735252290964127, 0.05473588407039642, 0.10695195198059082, 0.048304036259651184, 0.10087659955024719, 0.04425884410738945, 0.49513790011405945, 0.6408843398094177, 0.5050345063209534, 0.6412843465805054, 0.5110008120536804, 0.6362613439559937, 0.49208322167396545, 0.6322436928749084, 0.6178907155990601, 0.45595207810401917, 0.4421848654747009, 0.5625085234642029, 0.39282840490341187, 0.5127180218696594, 0.3307693600654602, 0.4465197026729584, 0.2775351107120514, 0.35994186997413635, 0.18566085398197174, 0.15418197214603424, 0.2507210075855255, 0.1989697813987732, 0.08183512836694717, 0.12806767225265503, 0.08021669089794159, 0.035191815346479416, 0.023074351251125336, 0.018517853692173958, 0.03802109882235527, 0.03155244141817093, 0.009486515074968338, 0.021362828090786934, 0.007203019689768553, 0.0136100510135293, 0.004335638601332903, 0.00998509582132101, 0.0034332526847720146, 0.007815038785338402, 0.0034297583624720573, 0.0059684221632778645, 0.0019561592489480972, 0.004947832319885492, 0.0015204483643174171, 0.0041352822445333, 0.001340672723017633, 0.003974607214331627, 0.001702778972685337, 0.003805719083175063, 0.0011890631867572665, 0.003753846511244774, 0.0012631481513381004, 0.0031215378548949957, 0.0010412184055894613, 0.0028135336469858885, 0.0012426862958818674, 0.0035149119794368744, 0.0020991098135709763, 0.0031435564160346985, 0.0028347678016871214, 0.0014076782390475273, 0.0025342244189232588, 0.0026679043658077717, 0.0010597024811431766, 0.002441014861688018, 0.0018673159647732973, 0.002687574364244938, 0.0008755985181778669, 0.0024427827447652817, 0.0009707739809527993, 0.002541830064728856, 0.0008521932177245617, 0.002254252089187503, 0.0010070926509797573, 0.00095107447123155, 0.00235337414778769, 0.0009529558010399342, 0.002446497557684779, 0.002618433441966772, 0.0008769360720179975, 0.0022557415068149567, 0.0007617274532094598, 0.002362098777666688, 0.0009295072522945702, 0.0022053259890526533, 0.0010685035958886147, 0.002095886506140232, 0.0020893013570457697, 0.000878767401445657, 0.002118564210832119, 0.0013967951526865363, 0.0021825777366757393, 0.0008883225964382291, 0.0022871308028697968, 0.0007126852869987488, 0.002281023422256112, 0.0007434422732330859, 0.001938311499543488, 0.0007732420926913619, 0.0020199003629386425, 0.0010793134570121765, 0.0017611890798434615, 0.0010249648476019502, 0.000926762935705483, 0.0017114535439759493, 0.07382987439632416, 0.08565075695514679, 0.11153233051300049, 0.09206820279359818, 0.05875307694077492, 0.12180664390325546, 0.15153047442436218, 0.06783819198608398, 0.0819883644580841, 0.07586593925952911, 0.08638586103916168, 0.10365532338619232, 0.08040815591812134, 0.07392024993896484, 0.08732450753450394, 0.0929948166012764, 0.07827784866094589, 0.08196781575679779, 0.1129530817270279, 0.06170062720775604, 0.10747218132019043, 0.08531614392995834, 0.09292465448379517, 0.06600382924079895, 0.09917885065078735, 0.09205905348062515, 0.09045646339654922, 0.08420857042074203, 0.09807056933641434, 0.090894415974617, 0.04860890656709671, 0.08824321627616882, 0.059087157249450684, 0.10142400860786438, 0.06575673818588257, 0.07299204915761948, 0.09506894648075104, 0.08791296929121017, 0.09587200731039047, 0.06509885936975479, 0.07389731705188751, 0.06991849094629288, 0.06474688649177551, 0.0746384784579277, 0.08105485886335373, 0.08658289164304733, 0.04118048772215843, 0.08258655667304993, 0.07562024891376495, 0.10131516307592392, 0.07860688120126724, 0.07078942656517029, 0.07835042476654053, 0.08447305858135223, 0.06332330405712128, 0.053875960409641266, 0.08252338320016861, 0.07010260969400406, 0.07853631675243378, 0.0860101655125618, 0.10655520111322403, 0.07402264326810837, 0.06972341984510422, 0.08989569544792175, 0.05478101596236229, 0.08871133625507355, 0.059398334473371506, 0.07355879247188568, 0.08109065145254135, 0.0836954265832901, 0.05394695699214935, 0.04103505238890648, 0.09032099694013596, 0.06571539491415024, 0.06808245927095413, 0.07905525714159012, 0.05261966958642006, 0.05350274220108986, 0.07311117649078369, 0.07018838822841644, 0.06635834276676178, 0.10045550018548965, 0.06198643893003464, 0.07432428747415543, 0.05391479283571243, 0.06310463696718216, 0.08962047100067139, 0.06882986426353455, 0.06696227937936783, 0.07497619837522507, 0.07156987488269806, 0.059260040521621704, 0.08112076669931412, 0.09640555828809738, 0.07075833529233932, 0.0878162682056427, 0.058991335332393646, 0.07778776437044144, 0.05793927237391472, 0.07437529414892197, 0.08653362840414047, 0.07288046181201935, 0.06138358637690544, 0.08531519025564194, 0.05083426088094711, 0.07168123126029968, 0.05348491296172142, 0.05544203892350197, 0.0514569915831089, 0.06524624675512314, 0.0698089450597763, 0.08542045950889587, 0.06781019270420074, 0.10970263183116913, 0.06673291325569153, 0.057979147881269455, 0.07838255167007446, 0.06400766968727112, 0.07216216623783112, 0.06124001741409302, 0.07071494311094284, 0.06773309409618378, 0.09380816668272018, 0.08222710341215134, 0.06462334841489792, 0.06317776441574097, 0.07835885882377625, 0.055371832102537155, 0.0692749097943306, 0.0655284970998764, 0.05829291790723801, 0.07565616816282272, 0.06612814217805862, 0.07314693927764893, 0.04461490735411644, 0.07177578657865524, 0.08269113302230835, 0.07109421491622925, 0.06284447759389877, 0.07383115589618683, 0.08136064559221268, 0.07854417711496353, 0.057203508913517, 0.08590790629386902, 0.06735020875930786, 0.09182114154100418, 0.09787014126777649, 0.0691026896238327, 0.08300014585256577, 0.06386934965848923, 0.061209701001644135, 0.08452817052602768, 0.0863148644566536, 0.07193280011415482, 0.0712895542383194, 0.05561874806880951, 0.06396528333425522, 0.06443124264478683, 0.07282407581806183, 0.09784086793661118, 0.05526275187730789, 0.08276346325874329, 0.05631852522492409, 0.06704039126634598, 0.06932906806468964, 0.055533695966005325, 0.07673808187246323, 0.0785355493426323, 0.0788143053650856, 0.08785883337259293, 0.08313272893428802, 0.04516220837831497, 0.060735780745744705, 0.0790582075715065, 0.06028377264738083, 0.07132478803396225, 0.08179965615272522, 0.0513470321893692, 0.06969065964221954, 0.07177212834358215, 0.0704503208398819, 0.0449228398501873, 0.05611202493309975, 0.07421692460775375, 0.08094602078199387, 0.0827280580997467, 0.06978368759155273, 0.0601310133934021, 0.052623819559812546, 0.056742191314697266, 0.05569873005151749, 0.06319227069616318, 0.08322855085134506, 0.07651518285274506, 0.0757988691329956, 0.049183279275894165, 0.07955627888441086, 0.06863880157470703, 0.05076908320188522, 0.06144733726978302, 0.07414129376411438, 0.07609784603118896, 0.04931512847542763, 0.054195333272218704, 0.07504512369632721, 0.07181313633918762, 0.039070092141628265, 0.08080750703811646, 0.07701295614242554, 0.051311470568180084, 0.07921825349330902, 0.07806094735860825, 0.06962218135595322, 0.05474301427602768, 0.06303121894598007, 0.08204378187656403, 0.06467747688293457, 0.0440903939306736, 0.062442753463983536, 0.03440164029598236, 0.0349305123090744, 0.030248334631323814, 0.05893440172076225, 0.053688064217567444, 0.0414779894053936, 0.06803184747695923, 0.05806121230125427, 0.05034733563661575, 0.04773079976439476, 0.026816606521606445, 0.027697689831256866, 0.057438384741544724, 0.04613643139600754, 0.04946921020746231, 0.05939207598567009, 0.05931835621595383, 0.04497072473168373, 0.04258733615279198, 0.06702467054128647, 0.043619729578495026, 0.046963855624198914, 0.04375652223825455, 0.04716942831873894, 0.05809880420565605, 0.05095590278506279, 0.04974928870797157, 0.03866906464099884, 0.08415877819061279, 0.041525792330503464, 0.05513426288962364, 0.03639881685376167, 0.047410063445568085, 0.055353421717882156, 0.03464819863438606, 0.033446043729782104, 0.04617277905344963, 0.033879656344652176, 0.07001805305480957, 0.0556723028421402, 0.036864373832941055, 0.06537341326475143, 0.04135702922940254, 0.06784185022115707, 0.04058277979493141, 0.041307128965854645, 0.0579773485660553, 0.04108736291527748, 0.06118229776620865, 0.05609767884016037, 0.07238440215587616, 0.06717967987060547, 0.048067204654216766, 0.04104619100689888, 0.05326113849878311, 0.062216874212026596, 0.052922848612070084, 0.043649766594171524, 0.03464267775416374, 0.036779191344976425, 0.04581402242183685, 0.04775546118617058, 0.06099293380975723, 0.054767679423093796, 0.03476937115192413, 0.07953458279371262, 0.047130927443504333, 0.07341040670871735, 0.03730735555291176, 0.023818714544177055, 0.023992927744984627, 0.030706359073519707, 0.05329200625419617, 0.03749933838844299, 0.04719913750886917, 0.055049750953912735, 0.05556735396385193, 0.036350689828395844, 0.06665121763944626, 0.048985037952661514, 0.03737214207649231, 0.053696367889642715, 0.04590938612818718, 0.06947564333677292, 0.04716961458325386, 0.07666604220867157, 0.057818081229925156, 0.06127871945500374, 0.07834379374980927, 0.06775351613759995, 0.023655377328395844, 0.048046935349702835, 0.06219116970896721, 0.06426063925027847, 0.03009503334760666, 0.040557779371738434, 0.06544231623411179, 0.05503260716795921, 0.06587226688861847, 0.0521816723048687, 0.05066840723156929, 0.04389485344290733, 0.05518964305520058, 0.03636929392814636, 0.04094894230365753, 0.05543498322367668, 0.040341295301914215, 0.026747293770313263, 0.07304288446903229, 0.027193309739232063, 0.06239558756351471, 0.043714895844459534, 0.04785090684890747, 0.05203781649470329, 0.04061780869960785, 0.03729218617081642, 0.04010338708758354, 0.03604964539408684, 0.03991091251373291, 0.0509665384888649, 0.03833810240030289, 0.044557124376297, 0.029990483075380325, 0.06273303925991058, 0.03793236240744591, 0.06102606654167175, 0.039536841213703156, 0.02315109223127365, 0.040837325155735016, 0.026334555819630623, 0.03184497356414795, 0.0406351238489151, 0.04939223453402519, 0.040813226252794266, 0.06191523000597954, 0.029748983681201935, 0.038579825311899185, 0.08208905160427094, 0.03899366036057472, 0.027390114963054657, 0.03596486523747444, 0.052121687680482864, 0.06663905829191208, 0.0343935489654541, 0.06297755241394043, 0.05487355589866638, 0.060559164732694626, 0.045747678726911545, 0.05373033136129379, 0.02826184593141079, 0.048063088208436966, 0.028695670887827873, 0.031698077917099, 0.041593872010707855, 0.05796031653881073, 0.030853966251015663, 0.04982934147119522, 0.061731237918138504, 0.024328526109457016, 0.03929620236158371, 0.02681587263941765, 0.04316119849681854, 0.052767008543014526, 0.027699453756213188, 0.04013738036155701, 0.03769437223672867, 0.03786523640155792, 0.05200296267867088, 0.046285856515169144, 0.031652603298425674, 0.026737893000245094, 0.06490025669336319, 0.03639742359519005, 0.05942535027861595, 0.046694062650203705, 0.04221755266189575, 0.05504357069730759, 0.037567734718322754, 0.06934458762407303, 0.03150734305381775, 0.06902427971363068, 0.05273348093032837, 0.04268457368016243, 0.035625286400318146, 0.08465302735567093, 0.04027571529150009, 0.03449811041355133, 0.05250973254442215, 0.04031148552894592, 0.06086016446352005, 0.040561042726039886, 0.04098866507411003, 0.05803672969341278, 0.04129432141780853, 0.06609272956848145, 0.021162712946534157, 0.052695322781801224, 0.045583274215459824, 0.051883287727832794, 0.05881550535559654, 0.03255489841103554, 0.042712319642305374, 0.03555848449468613, 0.05806342139840126, 0.02820475772023201, 0.04442781209945679, 0.03514830768108368, 0.01749144308269024, 0.0386960543692112, 0.04958978667855263, 0.06061813235282898, 0.04322195053100586, 0.04525523632764816, 0.043710436671972275, 0.03095611184835434, 0.02375001087784767, 0.06474602967500687, 0.07429444789886475, 0.04215802624821663, 0.05685684457421303, 0.05108219012618065, 0.031640730798244476, 0.05138546973466873, 0.04798409342765808, 0.035537246614694595, 0.038779426366090775, 0.033386554569005966, 0.056759752333164215, 0.037268638610839844, 0.047674842178821564, 0.042751412838697433, 0.0437016561627388, 0.04545218497514725, 0.03652076795697212, 0.05619030073285103, 0.02931617759168148, 0.03924122080206871, 0.03148270398378372, 0.038948096334934235, 0.026411181315779686, 0.04116618633270264, 0.07017499208450317, 0.026553962379693985, 0.029868975281715393, 0.01960844360291958, 0.06373520195484161, 0.04740059748291969, 0.034715402871370316, 0.030234914273023605, 0.047714509069919586, 0.022041989490389824, 0.04639004170894623, 0.034203339368104935, 0.029831591993570328, 0.025576267391443253, 0.05374618247151375, 0.06513240188360214, 0.07676693797111511, 0.054625388234853745, 0.03710783272981644, 0.048799507319927216, 0.040587857365608215, 0.05224354565143585, 0.041988957673311234, 0.06496942043304443, 0.043894048780202866, 0.04147831350564957, 0.03399541229009628, 0.01491409819573164, 0.03849800303578377, 0.024842167273163795, 0.03089979663491249, 0.01559553761035204, 0.030691735446453094, 0.033879976719617844, 0.01348668523132801, 0.019582854583859444, 0.010279657319188118, 0.02753148414194584, 0.01535130850970745, 0.01459022518247366, 0.01773413084447384, 0.051936641335487366, 0.037047985941171646, 0.014831955544650555, 0.03947443142533302, 0.022384583950042725, 0.044323280453681946, 0.029360631480813026, 0.02468213252723217, 0.020644355565309525, 0.026892120018601418, 0.045804157853126526, 0.026218974962830544, 0.030277451500296593, 0.01961885765194893, 0.01646522246301174, 0.04486082121729851, 0.02473345212638378, 0.026490699499845505, 0.020455364137887955, 0.0139002725481987, 0.0263838991522789, 0.03137693926692009, 0.03533495217561722, 0.0329572856426239, 0.03598470613360405, 0.02666766382753849, 0.010957727208733559, 0.025884749367833138, 0.015118582174181938, 0.031750988215208054, 0.030241211876273155, 0.022273307666182518, 0.026037942618131638, 0.023526493459939957, 0.021753914654254913, 0.03088807500898838, 0.029597651213407516, 0.025934386998414993, 0.02179574780166149, 0.01732517033815384, 0.008937046863138676, 0.027052585035562515, 0.033479463309049606, 0.028102509677410126, 0.015197128988802433, 0.025723321363329887, 0.03794766217470169, 0.01581634022295475, 0.026863982900977135, 0.03084043599665165, 0.030766116455197334, 0.011593888513743877, 0.02123754844069481, 0.01571505330502987, 0.024862658232450485, 0.009783521294593811, 0.017185943201184273, 0.014814745634794235, 0.014805976301431656, 0.05384046956896782, 0.04545649141073227, 0.021907612681388855, 0.015613943338394165, 0.031115403398871422, 0.01613469608128071, 0.01724931038916111, 0.02040644735097885, 0.02239784225821495, 0.022264990955591202, 0.02991931326687336, 0.025010360404849052, 0.018880225718021393, 0.016134675592184067, 0.009932704269886017, 0.017681319266557693, 0.022200463339686394, 0.03305898234248161, 0.025863369926810265, 0.029326384887099266, 0.03441840782761574, 0.026682155206799507, 0.017962731420993805, 0.016885165125131607, 0.018372539430856705, 0.010962868109345436, 0.03278404846787453, 0.013009454123675823, 0.01225948240607977, 0.016987968236207962, 0.038580894470214844, 0.014378692954778671, 0.03357412666082382, 0.02153925783932209, 0.012704314664006233, 0.03062720224261284, 0.04544338583946228, 0.02528386004269123, 0.00947016291320324, 0.021716954186558723, 0.034932490438222885, 0.011435242369771004, 0.019565805792808533, 0.0244147852063179, 0.019775236025452614, 0.029519056901335716, 0.022385234013199806, 0.025604406371712685, 0.05133526399731636, 0.0151358712464571, 0.028561647981405258, 0.011370450258255005, 0.031180918216705322, 0.010873167775571346, 0.058451056480407715, 0.02736663818359375, 0.022578338161110878, 0.006857164669781923, 0.0176385585218668, 0.013027049601078033, 0.02556389756500721, 0.014980287291109562, 0.010507886298000813, 0.032801974564790726, 0.023697147145867348, 0.015120796859264374, 0.03890825808048248, 0.00820143986493349, 0.012901794165372849, 0.03923410922288895, 0.05578388273715973, 0.028506524860858917, 0.01967092603445053, 0.02219931036233902, 0.043940264731645584, 0.01113959401845932, 0.02214190736413002, 0.01971988007426262, 0.019150953739881516, 0.018483413383364677, 0.021875815466046333, 0.0230607558041811, 0.02959229052066803, 0.02636183425784111, 0.013037933968007565, 0.02015751414000988, 0.05201440304517746, 0.01695971004664898, 0.012676268815994263, 0.02302705869078636, 0.038698118180036545, 0.020292917266488075, 0.021928586065769196, 0.019244782626628876, 0.027418194338679314, 0.04615155607461929, 0.01770365983247757, 0.024830106645822525, 0.019345154985785484, 0.012534581124782562, 0.03197100758552551, 0.030414529144763947, 0.03300204128026962, 0.018099192529916763, 0.026765093207359314, 0.017982134595513344, 0.012761042453348637, 0.019521400332450867, 0.03377573937177658, 0.01799248903989792, 0.03398427739739418, 0.019193993881344795, 0.019448714330792427, 0.02422233298420906, 0.01256474293768406, 0.03797341138124466, 0.019658807665109634, 0.018064215779304504, 0.028862057253718376, 0.018869316205382347, 0.021173987537622452, 0.03408375382423401, 0.012069695629179478, 0.03233795985579491, 0.010436459444463253, 0.020677341148257256, 0.012947890907526016, 0.01609189808368683, 0.018062172457575798, 0.04060124605894089, 0.04061136394739151, 0.014573832042515278, 0.021332833915948868, 0.036756858229637146, 0.03614641726016998, 0.023785855621099472, 0.0326598584651947, 0.021468674764037132, 0.018909171223640442, 0.03582825884222984, 0.03134787827730179, 0.02229383960366249, 0.023242250084877014, 0.02428278885781765, 0.045398831367492676, 0.01834864355623722, 0.01918412372469902, 0.04751087725162506, 0.01716313697397709, 0.023312654346227646, 0.018714530393481255, 0.027522360906004906, 0.020694531500339508, 0.027990441769361496, 0.026994075626134872, 0.014130993746221066, 0.03532378003001213, 0.027205852791666985, 0.015768669545650482, 0.014093655161559582, 0.02080661803483963, 0.02839571237564087, 0.05597176402807236, 0.038121242076158524, 0.032902978360652924, 0.023030929267406464, 0.02442474290728569, 0.024707326665520668, 0.0225345678627491, 0.02479923702776432, 0.03258061781525612, 0.027446402236819267, 0.009823992848396301, 0.029768140986561775, 0.016078922897577286, 0.008315232582390308, 0.019157657399773598, 0.017473094165325165, 0.030818112194538116, 0.02219594456255436, 0.029472913593053818, 0.010506007820367813, 0.013279533945024014, 0.011598645709455013, 0.023196324706077576, 0.02564799226820469, 0.01825682446360588, 0.02060377597808838, 0.01578068546950817, 0.02796926349401474, 0.02461884543299675, 0.014193926937878132, 0.025933925062417984, 0.034319471567869186, 0.024405386298894882, 0.02622848190367222, 0.031295403838157654, 0.03565298765897751, 0.018971819430589676, 0.021058009937405586, 0.03909127786755562, 0.008319984190165997, 0.02539176493883133, 0.02231535315513611, 0.001177669153548777, 0.02438390627503395, 0.021425563842058182, 0.042793069034814835, 0.020874513313174248, 0.02256801351904869, 0.028996266424655914, 0.02696114592254162, 0.014558732509613037, 0.02803814969956875, 0.023181265220046043, 0.01961580477654934, 0.02293338254094124, 0.028108345344662666, 0.011785214766860008, 0.008241451345384121, 0.020409997552633286, 0.024109382182359695, 0.030557934194803238, 0.032672345638275146, 0.045339856296777725, 0.01964295096695423, 0.019766639918088913, 0.016264962032437325, 0.023016683757305145, 0.030530983582139015, 0.022978877648711205, 0.033809807151556015, 0.021848006173968315, 0.01602044887840748, 0.029302455484867096, 0.037439536303281784, 0.014100680127739906, 0.03164644539356232, 0.030929407104849815, 0.024194655939936638, 0.0361025370657444, 0.02502385526895523, 0.010072200559079647, 0.01874297857284546, 0.020648086443543434, 0.014406676404178143, 0.03395192697644234, 0.032147541642189026, 0.040887679904699326, 0.023752694949507713]\n",
            "Rehearsal memory size: 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task3 평가"
      ],
      "metadata": {
        "id": "RuBxvOcwoHLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##driving12 평가"
      ],
      "metadata": {
        "id": "e8gQVPCpoKUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨 결과 저장\n",
        "final_labels = []\n",
        "final_tasks=[]"
      ],
      "metadata": {
        "id": "AtGjBxMWoSUf"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 모드 설정\n",
        "fm_model.eval()\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "test_loss_buffer = []\n",
        "test_action_buffer = []\n",
        "measuring_loss = False\n",
        "test_video_file_count = 0\n"
      ],
      "metadata": {
        "id": "89l91E2eoSUf"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 비디오 업로드 (driving12)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "test_video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "BPDebFYjoSUf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "6db0bd97-1003-469e-8ca7-65892c75f786"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-03df71f9-3fb2-4e34-88e9-25360c7dd5bd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-03df71f9-3fb2-4e34-88e9-25360c7dd5bd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving driving_12.mp4 to driving_12 (5).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 테스트용 비디오 불러오기 =====\n",
        "cap = cv2.VideoCapture(test_video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "\n",
        "with torch.no_grad():  # 테스트 시 gradient 계산 비활성화\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "        step += 1\n",
        "\n",
        "        result = model(frame)[0]\n",
        "        h, w, _ = frame.shape\n",
        "        frame_actions = []\n",
        "\n",
        "        for box in result.boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 테스트 시에는 rehearsal 손실만 계산 (학습하지 않음)\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            total_loss = rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                test_loss_buffer.append(total_loss.item())\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "        final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "        if measuring_loss:\n",
        "            test_action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(\"Test completed with rehearsal evaluation.\")\n",
        "print(\"Test Action Buffer:\", test_action_buffer)\n",
        "print(\"Test Loss Buffer:\", test_loss_buffer)"
      ],
      "metadata": {
        "id": "spNrFb6IoSUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c255289e-96f1-4308-8045-92553f47e1f8"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 1 car, 213.6ms\n",
            "Speed: 4.4ms preprocess, 213.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 209.2ms\n",
            "Speed: 3.2ms preprocess, 209.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 195.1ms\n",
            "Speed: 9.2ms preprocess, 195.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 188.5ms\n",
            "Speed: 3.2ms preprocess, 188.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 194.7ms\n",
            "Speed: 3.1ms preprocess, 194.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 205.9ms\n",
            "Speed: 3.1ms preprocess, 205.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 211.6ms\n",
            "Speed: 3.1ms preprocess, 211.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 196.7ms\n",
            "Speed: 3.2ms preprocess, 196.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 206.1ms\n",
            "Speed: 4.1ms preprocess, 206.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 195.8ms\n",
            "Speed: 3.1ms preprocess, 195.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 198.6ms\n",
            "Speed: 3.1ms preprocess, 198.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 208.5ms\n",
            "Speed: 3.6ms preprocess, 208.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 193.5ms\n",
            "Speed: 3.0ms preprocess, 193.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 196.7ms\n",
            "Speed: 3.4ms preprocess, 196.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 209.5ms\n",
            "Speed: 3.2ms preprocess, 209.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 198.7ms\n",
            "Speed: 2.9ms preprocess, 198.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 209.1ms\n",
            "Speed: 3.1ms preprocess, 209.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.1ms\n",
            "Speed: 3.0ms preprocess, 128.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 131.7ms\n",
            "Speed: 3.4ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.7ms\n",
            "Speed: 3.2ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 125.8ms\n",
            "Speed: 3.0ms preprocess, 125.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 126.5ms\n",
            "Speed: 3.5ms preprocess, 126.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 129.7ms\n",
            "Speed: 3.0ms preprocess, 129.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 145.7ms\n",
            "Speed: 3.0ms preprocess, 145.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 126.5ms\n",
            "Speed: 3.3ms preprocess, 126.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.1ms\n",
            "Speed: 2.9ms preprocess, 126.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 134.6ms\n",
            "Speed: 3.1ms preprocess, 134.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 bus, 126.4ms\n",
            "Speed: 2.7ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bus, 149.9ms\n",
            "Speed: 3.3ms preprocess, 149.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.4ms\n",
            "Speed: 3.0ms preprocess, 126.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 148.5ms\n",
            "Speed: 3.0ms preprocess, 148.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.6ms\n",
            "Speed: 3.1ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.2ms\n",
            "Speed: 3.9ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.1ms\n",
            "Speed: 3.7ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.3ms\n",
            "Speed: 3.0ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.3ms\n",
            "Speed: 3.6ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 123.4ms\n",
            "Speed: 3.4ms preprocess, 123.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.6ms\n",
            "Speed: 3.0ms preprocess, 128.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 131.8ms\n",
            "Speed: 3.0ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.0ms\n",
            "Speed: 2.8ms preprocess, 127.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 128.1ms\n",
            "Speed: 4.4ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 124.3ms\n",
            "Speed: 3.0ms preprocess, 124.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.5ms\n",
            "Speed: 3.3ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 126.1ms\n",
            "Speed: 2.9ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 125.1ms\n",
            "Speed: 4.0ms preprocess, 125.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 145.8ms\n",
            "Speed: 2.9ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 135.2ms\n",
            "Speed: 2.8ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.5ms\n",
            "Speed: 2.9ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 124.8ms\n",
            "Speed: 3.2ms preprocess, 124.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 127.2ms\n",
            "Speed: 3.5ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 132.6ms\n",
            "Speed: 3.7ms preprocess, 132.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 124.2ms\n",
            "Speed: 3.0ms preprocess, 124.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 144.6ms\n",
            "Speed: 3.3ms preprocess, 144.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 chair, 128.2ms\n",
            "Speed: 3.0ms preprocess, 128.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 129.3ms\n",
            "Speed: 3.2ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.6ms\n",
            "Speed: 2.9ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 127.8ms\n",
            "Speed: 2.9ms preprocess, 127.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 couch, 126.3ms\n",
            "Speed: 2.9ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 129.0ms\n",
            "Speed: 3.1ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 bed, 143.7ms\n",
            "Speed: 3.0ms preprocess, 143.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 133.0ms\n",
            "Speed: 2.9ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 126.8ms\n",
            "Speed: 2.9ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 128.0ms\n",
            "Speed: 3.1ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 bed, 129.4ms\n",
            "Speed: 3.0ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 126.4ms\n",
            "Speed: 3.1ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 126.2ms\n",
            "Speed: 3.1ms preprocess, 126.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 1 cell phone, 148.3ms\n",
            "Speed: 3.3ms preprocess, 148.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 131.7ms\n",
            "Speed: 2.9ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 123.1ms\n",
            "Speed: 3.3ms preprocess, 123.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 126.0ms\n",
            "Speed: 3.2ms preprocess, 126.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 125.0ms\n",
            "Speed: 3.0ms preprocess, 125.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 125.3ms\n",
            "Speed: 3.1ms preprocess, 125.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 124.8ms\n",
            "Speed: 3.2ms preprocess, 124.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 130.5ms\n",
            "Speed: 3.1ms preprocess, 130.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 143.6ms\n",
            "Speed: 3.5ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bed, 125.3ms\n",
            "Speed: 4.0ms preprocess, 125.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 126.9ms\n",
            "Speed: 3.1ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bed, 1 cell phone, 133.0ms\n",
            "Speed: 3.0ms preprocess, 133.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 126.8ms\n",
            "Speed: 3.2ms preprocess, 126.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 130.5ms\n",
            "Speed: 3.1ms preprocess, 130.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 127.2ms\n",
            "Speed: 3.2ms preprocess, 127.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 153.8ms\n",
            "Speed: 3.2ms preprocess, 153.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 124.6ms\n",
            "Speed: 4.0ms preprocess, 124.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 135.2ms\n",
            "Speed: 3.1ms preprocess, 135.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 1 bed, 174.9ms\n",
            "Speed: 3.7ms preprocess, 174.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 250.7ms\n",
            "Speed: 5.3ms preprocess, 250.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 toilet, 247.1ms\n",
            "Speed: 3.1ms preprocess, 247.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 1 toilet, 224.3ms\n",
            "Speed: 3.2ms preprocess, 224.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 197.7ms\n",
            "Speed: 2.9ms preprocess, 197.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 226.7ms\n",
            "Speed: 3.1ms preprocess, 226.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 203.0ms\n",
            "Speed: 6.2ms preprocess, 203.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 couch, 242.5ms\n",
            "Speed: 3.4ms preprocess, 242.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 200.3ms\n",
            "Speed: 3.1ms preprocess, 200.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 259.5ms\n",
            "Speed: 3.0ms preprocess, 259.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 265.3ms\n",
            "Speed: 7.4ms preprocess, 265.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 248.0ms\n",
            "Speed: 3.1ms preprocess, 248.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 229.7ms\n",
            "Speed: 3.0ms preprocess, 229.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 223.9ms\n",
            "Speed: 3.1ms preprocess, 223.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 1 couch, 205.0ms\n",
            "Speed: 3.0ms preprocess, 205.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 195.4ms\n",
            "Speed: 3.1ms preprocess, 195.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 couch, 232.8ms\n",
            "Speed: 2.8ms preprocess, 232.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 192.0ms\n",
            "Speed: 3.3ms preprocess, 192.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 219.0ms\n",
            "Speed: 3.0ms preprocess, 219.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 191.3ms\n",
            "Speed: 8.5ms preprocess, 191.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 193.2ms\n",
            "Speed: 3.0ms preprocess, 193.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 211.9ms\n",
            "Speed: 3.1ms preprocess, 211.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 218.6ms\n",
            "Speed: 2.9ms preprocess, 218.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 221.0ms\n",
            "Speed: 3.2ms preprocess, 221.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 kite, 217.5ms\n",
            "Speed: 5.5ms preprocess, 217.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 233.5ms\n",
            "Speed: 4.9ms preprocess, 233.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 260.4ms\n",
            "Speed: 4.0ms preprocess, 260.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 238.2ms\n",
            "Speed: 8.5ms preprocess, 238.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 212.3ms\n",
            "Speed: 3.0ms preprocess, 212.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 167.5ms\n",
            "Speed: 3.4ms preprocess, 167.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.5ms\n",
            "Speed: 3.1ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 139.5ms\n",
            "Speed: 4.3ms preprocess, 139.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 126.7ms\n",
            "Speed: 5.0ms preprocess, 126.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.6ms\n",
            "Speed: 3.0ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.0ms\n",
            "Speed: 3.8ms preprocess, 131.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.3ms\n",
            "Speed: 3.4ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 126.2ms\n",
            "Speed: 3.4ms preprocess, 126.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.9ms\n",
            "Speed: 3.3ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 146.8ms\n",
            "Speed: 3.4ms preprocess, 146.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.4ms\n",
            "Speed: 3.0ms preprocess, 129.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.0ms\n",
            "Speed: 3.0ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 127.1ms\n",
            "Speed: 2.9ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 127.0ms\n",
            "Speed: 2.9ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 124.4ms\n",
            "Speed: 3.0ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 125.5ms\n",
            "Speed: 3.0ms preprocess, 125.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 140.9ms\n",
            "Speed: 3.0ms preprocess, 140.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 131.1ms\n",
            "Speed: 3.0ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 127.3ms\n",
            "Speed: 3.1ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 130.5ms\n",
            "Speed: 2.9ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 125.7ms\n",
            "Speed: 3.0ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 129.0ms\n",
            "Speed: 3.0ms preprocess, 129.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 136.9ms\n",
            "Speed: 3.3ms preprocess, 136.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 146.3ms\n",
            "Speed: 3.2ms preprocess, 146.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 129.2ms\n",
            "Speed: 3.1ms preprocess, 129.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 129.0ms\n",
            "Speed: 3.3ms preprocess, 129.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 126.3ms\n",
            "Speed: 3.2ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 127.4ms\n",
            "Speed: 3.3ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 126.5ms\n",
            "Speed: 3.2ms preprocess, 126.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 131.1ms\n",
            "Speed: 3.3ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 144.5ms\n",
            "Speed: 3.0ms preprocess, 144.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 130.3ms\n",
            "Speed: 3.1ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 126.9ms\n",
            "Speed: 3.1ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 127.8ms\n",
            "Speed: 3.3ms preprocess, 127.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 125.5ms\n",
            "Speed: 3.2ms preprocess, 125.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 124.7ms\n",
            "Speed: 3.3ms preprocess, 124.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 1 truck, 126.2ms\n",
            "Speed: 2.9ms preprocess, 126.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 130.0ms\n",
            "Speed: 3.3ms preprocess, 130.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 140.6ms\n",
            "Speed: 3.2ms preprocess, 140.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 128.3ms\n",
            "Speed: 3.1ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 126.3ms\n",
            "Speed: 4.2ms preprocess, 126.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 1 truck, 124.9ms\n",
            "Speed: 3.1ms preprocess, 124.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 125.9ms\n",
            "Speed: 3.4ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 126.0ms\n",
            "Speed: 3.3ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 135.5ms\n",
            "Speed: 3.3ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 150.6ms\n",
            "Speed: 3.2ms preprocess, 150.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 130.1ms\n",
            "Speed: 2.9ms preprocess, 130.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 127.7ms\n",
            "Speed: 2.9ms preprocess, 127.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 128.1ms\n",
            "Speed: 3.0ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 1 bus, 134.8ms\n",
            "Speed: 3.1ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 125.4ms\n",
            "Speed: 3.0ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 129.4ms\n",
            "Speed: 3.0ms preprocess, 129.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 149.0ms\n",
            "Speed: 3.0ms preprocess, 149.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 131.8ms\n",
            "Speed: 3.2ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 128.1ms\n",
            "Speed: 3.0ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.9ms\n",
            "Speed: 3.2ms preprocess, 129.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.6ms\n",
            "Speed: 3.3ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 133.9ms\n",
            "Speed: 3.4ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 135.2ms\n",
            "Speed: 2.9ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 143.5ms\n",
            "Speed: 3.0ms preprocess, 143.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 125.6ms\n",
            "Speed: 3.1ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 128.3ms\n",
            "Speed: 3.2ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 133.8ms\n",
            "Speed: 3.4ms preprocess, 133.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.9ms\n",
            "Speed: 3.3ms preprocess, 135.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.7ms\n",
            "Speed: 3.2ms preprocess, 137.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 132.1ms\n",
            "Speed: 3.0ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 146.5ms\n",
            "Speed: 3.2ms preprocess, 146.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 124.2ms\n",
            "Speed: 3.1ms preprocess, 124.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 1 cell phone, 130.9ms\n",
            "Speed: 3.2ms preprocess, 130.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 205.1ms\n",
            "Speed: 2.9ms preprocess, 205.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 201.5ms\n",
            "Speed: 4.0ms preprocess, 201.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 201.4ms\n",
            "Speed: 3.0ms preprocess, 201.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 202.7ms\n",
            "Speed: 5.5ms preprocess, 202.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 190.0ms\n",
            "Speed: 4.8ms preprocess, 190.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 192.5ms\n",
            "Speed: 2.9ms preprocess, 192.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 kite, 216.1ms\n",
            "Speed: 9.3ms preprocess, 216.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 202.9ms\n",
            "Speed: 6.1ms preprocess, 202.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 212.0ms\n",
            "Speed: 3.1ms preprocess, 212.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 196.9ms\n",
            "Speed: 3.2ms preprocess, 196.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 kite, 197.1ms\n",
            "Speed: 2.8ms preprocess, 197.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 195.1ms\n",
            "Speed: 3.4ms preprocess, 195.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 193.8ms\n",
            "Speed: 4.9ms preprocess, 193.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 206.0ms\n",
            "Speed: 5.5ms preprocess, 206.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 203.0ms\n",
            "Speed: 4.9ms preprocess, 203.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 203.5ms\n",
            "Speed: 3.1ms preprocess, 203.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 207.4ms\n",
            "Speed: 3.1ms preprocess, 207.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 211.6ms\n",
            "Speed: 3.0ms preprocess, 211.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.3ms\n",
            "Speed: 3.2ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 125.0ms\n",
            "Speed: 2.7ms preprocess, 125.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.1ms\n",
            "Speed: 3.2ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.6ms\n",
            "Speed: 3.2ms preprocess, 129.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 148.7ms\n",
            "Speed: 3.0ms preprocess, 148.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.7ms\n",
            "Speed: 4.0ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.8ms\n",
            "Speed: 3.1ms preprocess, 135.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 140.1ms\n",
            "Speed: 5.3ms preprocess, 140.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.9ms\n",
            "Speed: 3.1ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 129.6ms\n",
            "Speed: 4.2ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 126.0ms\n",
            "Speed: 3.2ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 124.5ms\n",
            "Speed: 3.2ms preprocess, 124.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.8ms\n",
            "Speed: 3.4ms preprocess, 127.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.6ms\n",
            "Speed: 3.1ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 151.7ms\n",
            "Speed: 3.5ms preprocess, 151.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.4ms\n",
            "Speed: 3.5ms preprocess, 129.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 124.8ms\n",
            "Speed: 3.1ms preprocess, 124.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.4ms\n",
            "Speed: 4.0ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.8ms\n",
            "Speed: 2.9ms preprocess, 132.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 125.0ms\n",
            "Speed: 3.0ms preprocess, 125.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 126.9ms\n",
            "Speed: 3.1ms preprocess, 126.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 147.9ms\n",
            "Speed: 4.5ms preprocess, 147.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.2ms\n",
            "Speed: 5.0ms preprocess, 133.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 127.4ms\n",
            "Speed: 2.9ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.0ms\n",
            "Speed: 3.2ms preprocess, 127.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.5ms\n",
            "Speed: 4.5ms preprocess, 133.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 cell phone, 125.9ms\n",
            "Speed: 3.1ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.6ms\n",
            "Speed: 3.1ms preprocess, 131.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 144.9ms\n",
            "Speed: 4.2ms preprocess, 144.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.8ms\n",
            "Speed: 3.2ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.4ms\n",
            "Speed: 3.1ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.1ms\n",
            "Speed: 2.9ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 129.1ms\n",
            "Speed: 3.0ms preprocess, 129.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.9ms\n",
            "Speed: 3.3ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.4ms\n",
            "Speed: 3.1ms preprocess, 132.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 144.9ms\n",
            "Speed: 3.5ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.2ms\n",
            "Speed: 3.8ms preprocess, 129.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.2ms\n",
            "Speed: 2.9ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 130.5ms\n",
            "Speed: 2.9ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 130.4ms\n",
            "Speed: 3.1ms preprocess, 130.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 125.9ms\n",
            "Speed: 3.3ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 129.2ms\n",
            "Speed: 3.5ms preprocess, 129.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 148.1ms\n",
            "Speed: 3.2ms preprocess, 148.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 132.3ms\n",
            "Speed: 3.1ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 127.3ms\n",
            "Speed: 6.1ms preprocess, 127.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 128.7ms\n",
            "Speed: 3.4ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 130.7ms\n",
            "Speed: 2.9ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 129.0ms\n",
            "Speed: 3.1ms preprocess, 129.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.5ms\n",
            "Speed: 3.1ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 145.8ms\n",
            "Speed: 3.0ms preprocess, 145.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.2ms\n",
            "Speed: 6.5ms preprocess, 126.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.0ms\n",
            "Speed: 3.2ms preprocess, 134.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.8ms\n",
            "Speed: 3.2ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.4ms\n",
            "Speed: 3.1ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 135.2ms\n",
            "Speed: 3.1ms preprocess, 135.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 130.2ms\n",
            "Speed: 3.1ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 151.1ms\n",
            "Speed: 3.3ms preprocess, 151.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 128.6ms\n",
            "Speed: 3.0ms preprocess, 128.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.4ms\n",
            "Speed: 5.4ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 128.7ms\n",
            "Speed: 3.2ms preprocess, 128.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 125.7ms\n",
            "Speed: 3.0ms preprocess, 125.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 1 cell phone, 128.4ms\n",
            "Speed: 3.3ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 132.3ms\n",
            "Speed: 3.4ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 146.0ms\n",
            "Speed: 4.8ms preprocess, 146.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 134.0ms\n",
            "Speed: 3.1ms preprocess, 134.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 128.0ms\n",
            "Speed: 3.4ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 130.8ms\n",
            "Speed: 3.7ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 147.9ms\n",
            "Speed: 3.6ms preprocess, 147.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 203.2ms\n",
            "Speed: 4.5ms preprocess, 203.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 220.4ms\n",
            "Speed: 4.6ms preprocess, 220.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 211.0ms\n",
            "Speed: 3.2ms preprocess, 211.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 193.9ms\n",
            "Speed: 5.2ms preprocess, 193.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 199.3ms\n",
            "Speed: 3.1ms preprocess, 199.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 208.3ms\n",
            "Speed: 3.1ms preprocess, 208.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 231.8ms\n",
            "Speed: 3.8ms preprocess, 231.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 1 bus, 203.5ms\n",
            "Speed: 3.3ms preprocess, 203.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 207.9ms\n",
            "Speed: 3.4ms preprocess, 207.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 201.9ms\n",
            "Speed: 3.3ms preprocess, 201.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 205.8ms\n",
            "Speed: 3.4ms preprocess, 205.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 209.4ms\n",
            "Speed: 3.2ms preprocess, 209.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 204.5ms\n",
            "Speed: 3.3ms preprocess, 204.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 215.3ms\n",
            "Speed: 3.3ms preprocess, 215.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 221.2ms\n",
            "Speed: 3.3ms preprocess, 221.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 229.6ms\n",
            "Speed: 3.2ms preprocess, 229.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 222.9ms\n",
            "Speed: 4.4ms preprocess, 222.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 139.8ms\n",
            "Speed: 3.1ms preprocess, 139.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.4ms\n",
            "Speed: 3.4ms preprocess, 141.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.3ms\n",
            "Speed: 3.3ms preprocess, 141.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 140.3ms\n",
            "Speed: 3.9ms preprocess, 140.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.0ms\n",
            "Speed: 3.3ms preprocess, 137.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 155.4ms\n",
            "Speed: 3.3ms preprocess, 155.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 140.3ms\n",
            "Speed: 3.8ms preprocess, 140.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.5ms\n",
            "Speed: 2.9ms preprocess, 132.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 133.7ms\n",
            "Speed: 3.2ms preprocess, 133.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 airplane, 1 bus, 142.5ms\n",
            "Speed: 3.5ms preprocess, 142.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 136.4ms\n",
            "Speed: 3.1ms preprocess, 136.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 150.5ms\n",
            "Speed: 3.3ms preprocess, 150.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 144.8ms\n",
            "Speed: 3.3ms preprocess, 144.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.5ms\n",
            "Speed: 3.2ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 143.1ms\n",
            "Speed: 3.4ms preprocess, 143.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.8ms\n",
            "Speed: 4.0ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.1ms\n",
            "Speed: 3.2ms preprocess, 141.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.3ms\n",
            "Speed: 3.3ms preprocess, 141.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 151.3ms\n",
            "Speed: 5.3ms preprocess, 151.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.0ms\n",
            "Speed: 3.0ms preprocess, 141.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 144.5ms\n",
            "Speed: 3.8ms preprocess, 144.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.0ms\n",
            "Speed: 3.3ms preprocess, 138.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 139.2ms\n",
            "Speed: 6.0ms preprocess, 139.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.4ms\n",
            "Speed: 3.3ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.6ms\n",
            "Speed: 3.1ms preprocess, 131.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 161.3ms\n",
            "Speed: 3.9ms preprocess, 161.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.8ms\n",
            "Speed: 3.8ms preprocess, 138.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 137.8ms\n",
            "Speed: 3.5ms preprocess, 137.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 139.5ms\n",
            "Speed: 3.6ms preprocess, 139.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 141.0ms\n",
            "Speed: 3.7ms preprocess, 141.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.0ms\n",
            "Speed: 3.3ms preprocess, 138.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 142.6ms\n",
            "Speed: 3.2ms preprocess, 142.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.0ms\n",
            "Speed: 3.3ms preprocess, 138.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 135.7ms\n",
            "Speed: 4.0ms preprocess, 135.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.8ms\n",
            "Speed: 3.6ms preprocess, 134.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 143.0ms\n",
            "Speed: 3.2ms preprocess, 143.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.2ms\n",
            "Speed: 3.6ms preprocess, 138.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 134.9ms\n",
            "Speed: 3.4ms preprocess, 134.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 156.8ms\n",
            "Speed: 3.4ms preprocess, 156.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.1ms\n",
            "Speed: 3.6ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 1 truck, 133.0ms\n",
            "Speed: 4.8ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 138.5ms\n",
            "Speed: 5.1ms preprocess, 138.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 517.1ms\n",
            "Speed: 3.5ms preprocess, 517.1ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 139.1ms\n",
            "Speed: 9.4ms preprocess, 139.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.8ms\n",
            "Speed: 3.8ms preprocess, 135.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 143.6ms\n",
            "Speed: 3.1ms preprocess, 143.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.5ms\n",
            "Speed: 3.4ms preprocess, 137.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.4ms\n",
            "Speed: 3.6ms preprocess, 132.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.5ms\n",
            "Speed: 3.0ms preprocess, 132.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 156.8ms\n",
            "Speed: 3.5ms preprocess, 156.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 138.7ms\n",
            "Speed: 3.0ms preprocess, 138.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 135.0ms\n",
            "Speed: 3.4ms preprocess, 135.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 137.6ms\n",
            "Speed: 3.3ms preprocess, 137.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.5ms\n",
            "Speed: 3.1ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.6ms\n",
            "Speed: 3.0ms preprocess, 133.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 138.4ms\n",
            "Speed: 3.4ms preprocess, 138.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 150.8ms\n",
            "Speed: 3.2ms preprocess, 150.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 140.4ms\n",
            "Speed: 3.4ms preprocess, 140.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 137.0ms\n",
            "Speed: 4.9ms preprocess, 137.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 134.6ms\n",
            "Speed: 3.3ms preprocess, 134.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 132.0ms\n",
            "Speed: 3.1ms preprocess, 132.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 187.8ms\n",
            "Speed: 3.0ms preprocess, 187.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 221.5ms\n",
            "Speed: 3.1ms preprocess, 221.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 204.9ms\n",
            "Speed: 3.0ms preprocess, 204.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 cell phone, 211.2ms\n",
            "Speed: 3.3ms preprocess, 211.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 207.6ms\n",
            "Speed: 3.4ms preprocess, 207.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 201.3ms\n",
            "Speed: 3.0ms preprocess, 201.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 237.3ms\n",
            "Speed: 3.5ms preprocess, 237.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 210.8ms\n",
            "Speed: 3.3ms preprocess, 210.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 202.2ms\n",
            "Speed: 3.4ms preprocess, 202.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 200.2ms\n",
            "Speed: 3.6ms preprocess, 200.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 216.1ms\n",
            "Speed: 3.3ms preprocess, 216.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 208.7ms\n",
            "Speed: 3.2ms preprocess, 208.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 205.5ms\n",
            "Speed: 3.3ms preprocess, 205.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 208.3ms\n",
            "Speed: 3.2ms preprocess, 208.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 213.6ms\n",
            "Speed: 3.1ms preprocess, 213.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 230.8ms\n",
            "Speed: 5.0ms preprocess, 230.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 204.5ms\n",
            "Speed: 3.2ms preprocess, 204.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 188.8ms\n",
            "Speed: 3.2ms preprocess, 188.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.6ms\n",
            "Speed: 3.7ms preprocess, 133.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 131.7ms\n",
            "Speed: 5.0ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 133.4ms\n",
            "Speed: 3.2ms preprocess, 133.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 bus, 147.8ms\n",
            "Speed: 3.5ms preprocess, 147.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bus, 131.5ms\n",
            "Speed: 3.1ms preprocess, 131.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Test completed with rehearsal evaluation.\n",
            "Test Action Buffer: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Test Loss Buffer: [0.004629116039723158, 0.00377430091612041, 0.003606135956943035, 0.001910179271362722, 0.005279079079627991, 0.002353548537939787, 0.009110177867114544, 0.004166860599070787, 0.005898663308471441, 0.0021466000471264124, 0.006297796033322811, 0.004947603680193424, 0.006037881597876549, 0.005250430665910244, 0.0026417868211865425, 0.004610973410308361, 0.0033960186410695314, 0.0013484219089150429, 0.005144333932548761, 0.00394961703568697, 0.0034943807404488325, 0.009535751305520535, 0.002630180213600397, 0.005487996153533459, 0.0054049077443778515, 0.005030736327171326, 0.0033401576802134514, 0.0009604422957636416, 0.002143175806850195, 0.0024172209668904543, 0.0037293899804353714, 0.0018390683690086007, 0.0025151786394417286, 0.002588310744613409, 0.0032293584663420916, 0.003047333564609289, 0.0048287357203662395, 0.0057978518307209015, 0.005399463698267937, 0.002748798346146941, 0.0033448042813688517, 0.004987126681953669, 0.003846255596727133, 0.001861655036918819, 0.004903366789221764, 0.0021984949707984924, 0.003022177843376994, 0.0029213831294327974, 0.002841321285814047, 0.0025752466171979904, 0.0020325067453086376, 0.004137046169489622, 0.002541351830586791, 0.0040097348392009735, 0.002165177371352911, 0.007749396376311779, 0.0030264591332525015, 0.00371427065692842, 0.005371971521526575, 0.0047055743634700775, 0.003054984612390399, 0.003241848200559616, 0.004545289091765881, 0.005956683307886124, 0.0019586929120123386, 0.006526508368551731, 0.0021420479752123356, 0.007647359278053045, 0.005925583187490702, 0.004358101636171341, 0.004746411927044392, 0.0049203201197087765, 0.002519692527130246, 0.0017740209586918354, 0.0036297834012657404, 0.00229059811681509, 0.002940539503470063, 0.004308558534830809, 0.00476954085752368, 0.003391509409993887, 0.004329084884375334, 0.0011148323537781835, 0.0015505938790738583, 0.004383562132716179, 0.0061484393663704395, 0.0018580101896077394, 0.0024837024975568056, 0.002017019549384713, 0.002091866685077548, 0.004675684496760368, 0.0014916034415364265, 0.003837440861389041, 0.00584140932187438, 0.0023188672494143248, 0.0025420994497835636, 0.005082959309220314, 0.0029346502851694822, 0.003422542242333293, 0.00482292240485549, 0.00630858214572072, 0.004991287365555763, 0.0030523668974637985, 0.005993873346596956, 0.0037139083724468946, 0.002559548942372203, 0.003010041080415249, 0.005839882884174585, 0.002736880909651518, 0.004265165887773037, 0.002049494069069624, 0.0022031182888895273, 0.003767414251342416, 0.0023720453027635813, 0.0039084735326468945, 0.005764679051935673, 0.006760799791663885, 0.0038779820315539837, 0.004269675351679325, 0.002033646684139967, 0.0023049144074320793, 0.0039405012503266335, 0.005272291135042906, 0.003441338427364826, 0.0024306559935212135, 0.0031987507827579975, 0.007110693491995335, 0.005262956954538822, 0.004182809963822365, 0.001887058955617249, 0.008013293147087097, 0.0051980107091367245, 0.0028356038965284824, 0.0027060830034315586, 0.0054290518164634705, 0.002658664947375655, 0.0020711522083729506, 0.007626700680702925, 0.005026907194405794, 0.0054763685911893845, 0.002584330039098859, 0.001988697797060013, 0.005622176453471184, 0.0015477091073989868, 0.003782512154430151, 0.0029523693956434727, 0.003164723515510559, 0.00429559824988246, 0.004989929497241974, 0.0033613324631005526, 0.004414812661707401, 0.0030174085404723883, 0.006147956941276789, 0.003482535947114229, 0.005707523785531521, 0.005248036235570908, 0.004216377157717943, 0.0027704299427568913, 0.004223019350320101, 0.0063206590712070465, 0.0059141069650650024, 0.002974527422338724, 0.0028559034690260887, 0.00807165540754795, 0.0014939180109649897, 0.004175485577434301, 0.0016356566920876503, 0.003832091111689806, 0.0020470982417464256, 0.004229167476296425, 0.004098452161997557, 0.00581906083971262, 0.004614447709172964, 0.00263541704043746, 0.002420048462226987, 0.0019940452184528112, 0.0012151156552135944, 0.003596613882109523, 0.004636581055819988, 0.0016919608460739255, 0.00284397485665977, 0.004321803338825703, 0.004090712405741215, 0.0030928964260965586, 0.0036746342666447163, 0.0045300736092031, 0.0027860961854457855, 0.0046378071419894695, 0.0023526649456471205, 0.0013692467473447323, 0.001913546584546566, 0.008998638018965721, 0.004378884565085173, 0.005557078402489424, 0.001320374314673245, 0.002025381661951542, 0.0029139374382793903, 0.0027093496173620224, 0.004481182433664799, 0.0023745419457554817, 0.003911799751222134, 0.003963744267821312, 0.0025143150705844164, 0.0062761250883340836, 0.004188709892332554, 0.0016626138240098953, 0.0036392256151884794, 0.0027993549592792988, 0.0055323401466012, 0.0030084496829658747, 0.004606339614838362, 0.003058753442019224, 0.004159608855843544, 0.006727871485054493, 0.0045823692344129086, 0.0018177063902840018, 0.007896757684648037, 0.002086891559883952, 0.004467950202524662, 0.0026958826929330826, 0.008889580145478249, 0.0038592072669416666, 0.007417891640216112, 0.0035872641019523144, 0.006747746840119362, 0.005212962627410889, 0.0038079761434346437, 0.0026177209801971912, 0.002290930598974228, 0.001431120908819139, 0.003773119067773223, 0.005475006531924009, 0.0032997424714267254, 0.0048649851232767105, 0.002097513759508729, 0.005209668539464474, 0.004282601177692413, 0.002451615408062935, 0.0039097703993320465, 0.0013585203560069203, 0.0041930191218853, 0.0042029619216918945, 0.0063443370163440704, 0.0051671043038368225, 0.005227291490882635, 0.0014301079791039228, 0.002201995812356472, 0.004809223115444183, 0.0018574106507003307, 0.002894609235227108, 0.002705249935388565, 0.003011401742696762, 0.002984884660691023, 0.005191790871322155, 0.003378723980858922, 0.005268299486488104, 0.003262912156060338, 0.0024863125290721655, 0.003926543053239584, 0.004156341776251793, 0.006107833702117205, 0.002846252638846636, 0.0025303754955530167, 0.0024897295515984297, 0.004488237202167511, 0.008785011246800423, 0.002691020956262946, 0.001413568388670683, 0.0010785313788801432, 0.002070198766887188, 0.003914272412657738, 0.003651275299489498, 0.004473596345633268, 0.002931158524006605, 0.004410939756780863, 0.004783443175256252, 0.008000766858458519, 0.0037479123566299677, 0.004572640173137188, 0.0030365162529051304, 0.0057211704552173615, 0.006293751765042543, 0.0042881290428340435, 0.005127397831529379, 0.001777369063347578, 0.007642852608114481, 0.004559244029223919, 0.003589371219277382, 0.001966499723494053, 0.004571059253066778, 0.0017868787981569767, 0.0031946850940585136, 0.0030379395466297865, 0.003200564766302705, 0.00808716844767332, 0.003214456606656313, 0.004458842799067497, 0.005798799451440573, 0.0034883872140198946, 0.0044631934724748135, 0.0026137917302548885, 0.007092304527759552, 0.003333138767629862, 0.002291714772582054, 0.004768000449985266, 0.004677600227296352, 0.0020714213605970144, 0.0017580667044967413, 0.0049683647230267525, 0.0035268061328679323, 0.0037379376590251923, 0.003511799732223153, 0.003202488413080573, 0.004455124028027058, 0.008001608774065971, 0.0032213558442890644, 0.005894815549254417, 0.004879041574895382, 0.001716305036097765, 0.0025918432511389256, 0.00203323015011847, 0.004434328526258469, 0.003586161183193326, 0.00400763563811779, 0.007112251129001379, 0.004704468883574009, 0.004394007381051779, 0.006557985208928585, 0.0033014831133186817, 0.004401031881570816, 0.003378017572686076, 0.004907951690256596, 0.0030632794369012117, 0.0019536002073436975, 0.0020240640733391047, 0.0053563909605145454, 0.001476810546591878, 0.004269051365554333, 0.003670914564281702, 0.0021189923863857985, 0.0029960598330944777, 0.004401995800435543, 0.0033973194658756256, 0.0027812416665256023, 0.003322591772302985, 0.010929534211754799, 0.005503065884113312, 0.003708102973178029, 0.0017474270425736904, 0.0030174318235367537, 0.005638070870190859, 0.0032312918920069933, 0.005294623784720898, 0.004982029087841511, 0.004136674106121063, 0.003357051173225045, 0.0024715587496757507, 0.00589403323829174, 0.0031869797967374325, 0.005818242207169533, 0.0011583794839680195, 0.011319042183458805, 0.004253481514751911, 0.0061499206349253654, 0.0019518232438713312, 0.002210318809375167, 0.0028961305506527424, 0.0027848579920828342, 0.0041260430589318275, 0.003327840007841587, 0.0021386761218309402, 0.002999307122081518, 0.0032140538096427917, 0.0047426288947463036, 0.001971427584066987, 0.001845416147261858, 0.0037132843863219023, 0.002809276571497321, 0.0015416779788210988, 0.0030116650741547346, 0.0029276954010128975, 0.0024035966489464045, 0.005201599560678005, 0.003086427692323923, 0.003984672948718071, 0.0024583623744547367, 0.005362626630812883, 0.003549267305061221, 0.0024970683734863997, 0.0015203077346086502, 0.004433649592101574, 0.003555364441126585, 0.0034486944787204266, 0.002777412300929427, 0.0030176974833011627, 0.000832779798656702, 0.005006303545087576, 0.005116961896419525, 0.0021267756819725037, 0.0017770425183698535, 0.0023907949216663837, 0.0022033103741705418, 0.00208188034594059, 0.0033749504946172237, 0.003407262032851577, 0.009045323356986046, 0.003949685953557491, 0.003361547365784645, 0.0037014135159552097, 0.0011703623458743095, 0.003168335650116205, 0.0037943064235150814, 0.004016674589365721, 0.005057615227997303, 0.00589732127264142, 0.001491446397267282, 0.004475593101233244, 0.002115231705829501, 0.005322143901139498, 0.005687338765710592, 0.0020866207778453827, 0.0019945839885622263, 0.005778428167104721, 0.0016262707067653537, 0.004846619442105293, 0.004063211847096682, 0.004129866603761911, 0.004672986455261707, 0.0017687040381133556, 0.002882392844185233, 0.0034639863297343254, 0.005546811502426863, 0.0024451788049191236, 0.002054902259260416, 0.002225668402388692, 0.0021007577888667583, 0.004035644233226776, 0.0013961262302473187, 0.004191562067717314, 0.0020584422163665295, 0.005012689623981714, 0.00816875696182251, 0.004056388512253761, 0.0017232982208952308, 0.00752405496314168, 0.0031017246656119823, 0.008037391118705273, 0.006032487377524376, 0.004229685291647911, 0.0018992291297763586, 0.007435324601829052, 0.003183855675160885, 0.002045881003141403, 0.005347006022930145, 0.0028226193971931934, 0.0023541294503957033, 0.0017074166098609567, 0.001979268155992031, 0.0017364700324833393, 0.003351474180817604, 0.0024556987918913364, 0.0055016144178807735, 0.003468062961474061, 0.0043208240531384945, 0.00188190839253366, 0.001733885845169425, 0.004294226411730051, 0.002557838801294565, 0.0034326380118727684, 0.001621697098016739, 0.0021865442395210266, 0.008170518092811108, 0.00514637166634202, 0.00653926283121109, 0.004022233188152313, 0.005954852793365717, 0.0034713479690253735, 0.0022686480078846216, 0.0016092538135126233, 0.0017874212935566902, 0.005526495631784201, 0.0029244855977594852, 0.0020270959939807653, 0.007520715240389109, 0.0042471252381801605, 0.004234961234033108, 0.00207396037876606, 0.0034649455919861794, 0.0032713101245462894, 0.004277064464986324, 0.004465963691473007, 0.002625945257022977, 0.006518769543617964, 0.003924043849110603, 0.0018290886655449867, 0.003788780188187957, 0.0039019796531647444, 0.002473753411322832, 0.0018043005838990211, 0.004687292501330376, 0.004980802536010742, 0.002680707024410367, 0.005789823830127716, 0.0036213495768606663, 0.004995746538043022, 0.004511941224336624, 0.003664192510768771, 0.004675754811614752, 0.004040436819195747, 0.002923361724242568, 0.009422793984413147, 0.0024807178415358067, 0.0027672885917127132, 0.00317024951800704, 0.004840928595513105, 0.005221111699938774, 0.003917999565601349, 0.006845698691904545, 0.006536140572279692, 0.004036632366478443, 0.0034313229843974113, 0.003120451932772994, 0.0061194715090096, 0.0024387422017753124, 0.0034620941150933504, 0.0021622180938720703, 0.007024004124104977, 0.0028032728005200624, 0.00385712506249547, 0.0031553609296679497, 0.0023446741979569197, 0.0031288936734199524, 0.0046159615740180016, 0.0025332169607281685, 0.007991424761712551, 0.004001816269010305, 0.003567130072042346, 0.0028103748336434364, 0.0017420449294149876, 0.006818578112870455, 0.0032782540656626225, 0.006059742067009211, 0.0016060329508036375, 0.00503185112029314, 0.005646098405122757, 0.0049424562603235245, 0.005840540863573551, 0.0036348728463053703, 0.003025048179551959, 0.0033088461495935917, 0.004385464824736118, 0.0036290246061980724, 0.0028016597498208284, 0.001805438776500523, 0.0021426433231681585, 0.0038127079606056213, 0.003248866880312562, 0.003961407113820314, 0.0015737401554360986, 0.007279722020030022, 0.0026459195651113987, 0.0032335484866052866, 0.006847824901342392, 0.00618642708286643, 0.0042159720323979855, 0.0022991271689534187, 0.00282337237149477, 0.0030212709680199623, 0.0017914234194904566, 0.005120216403156519, 0.002285327762365341, 0.004483998753130436, 0.002178255468606949, 0.0026835419703274965, 0.007389700040221214, 0.0027926135808229446, 0.002472776686772704, 0.0012083797482773662, 0.003402530215680599, 0.006985855754464865, 0.002304255263879895, 0.0028568312991410494, 0.004539871588349342, 0.00550703564658761, 0.004596872255206108, 0.0013973310124129057, 0.006210144143551588, 0.0023304049391299486, 0.0016678179381415248, 0.0033363564871251583, 0.005052119493484497, 0.0026002353988587856, 0.0020230901427567005, 0.002686311723664403, 0.0015555706340819597, 0.003482804400846362, 0.006508386693894863, 0.006174945272505283, 0.003797153476625681, 0.007522867526859045, 0.0015227858675643802, 0.004216144792735577, 0.0016363903414458036, 0.0030377544462680817, 0.0013411276740953326, 0.006135397125035524, 0.003992625046521425, 0.005463474430143833, 0.0027995891869068146, 0.0012155163567513227, 0.006149544846266508, 0.0039617461152374744, 0.006098940037190914, 0.001430452917702496, 0.0018755211494863033, 0.0019007888622581959, 0.005738677456974983, 0.00262700067833066, 0.004894789308309555, 0.0025072433054447174, 0.004992400761693716, 0.0028398269787430763, 0.0031470011454075575, 0.0021548885852098465, 0.00709545286372304, 0.004133980721235275, 0.0021693005692213774, 0.0028028865344822407, 0.008634630590677261, 0.002443573670461774]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 라벨 설정\n",
        "test_frame_labels = driving12['go_stop_decision'] # 여기에 driving12, truck8, uturn7을 값을 바꿔가며 넣기"
      ],
      "metadata": {
        "id": "reYw-deVoSUf"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 타입 및 길이 확인\n",
        "print(type(test_action_buffer))\n",
        "print(type(test_frame_labels))\n",
        "print(len(test_action_buffer))\n",
        "print(len(test_frame_labels))"
      ],
      "metadata": {
        "id": "Bne9BFpioSUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b98c654-744a-407a-ea14-bcac1ee1f222"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "369\n",
            "369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과 저장\n",
        "final_tasks.append(test_action_buffer)\n",
        "final_labels.append(test_frame_labels)"
      ],
      "metadata": {
        "id": "QdILflG3oSUg"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CL 메트릭 계산\n",
        "IM, FWT, BWT = compute_cl_metrics(final_tasks, final_labels)\n",
        "\n",
        "print(f\"IM (Initial Accuracy): {IM:.5f}\")\n",
        "print(f\"FWT (Forward Transfer): {FWT:.5f}\")\n",
        "print(f\"BWT (Backward Transfer): {BWT:.5f}\")\n"
      ],
      "metadata": {
        "id": "ZU3loBYYoSUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9caa249a-c406-4e70-efca-9bf2f6928983"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task accuracies: [    0.67209]\n",
            "IM (Initial Accuracy): 0.67209\n",
            "FWT (Forward Transfer): 0.00000\n",
            "BWT (Backward Transfer): 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rehearsal 메모리 상태 확인\n",
        "print(f\"Rehearsal memory contains {len(rehearsal_memory.data_buffer)} samples\")\n",
        "print(f\"Memory usage: {len(rehearsal_memory.data_buffer)} / {rehearsal_memory.max_samples}\")"
      ],
      "metadata": {
        "id": "z_nW5uUcoSUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4f56ae-ddb7-456a-c7eb-0e98c2077f52"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rehearsal memory contains 900 samples\n",
            "Memory usage: 900 / 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 샘플의 일부 확인\n",
        "if len(rehearsal_memory.data_buffer) > 0:\n",
        "    sample_data = rehearsal_memory.data_buffer[0]\n",
        "    sample_label = rehearsal_memory.label_buffer[0]\n",
        "    print(f\"Sample data shape: {sample_data.shape}\")\n",
        "    print(f\"Sample label: {sample_label}\")"
      ],
      "metadata": {
        "id": "4yvKMscNoSUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbf191c-2c94-4271-c32c-c42f41c86f71"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data shape: (15,)\n",
            "Sample label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_tasks)"
      ],
      "metadata": {
        "id": "C7VRPzz2oSUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb8df163-d243-4536-b393-0fe064b24f26"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##towtruck8 평가"
      ],
      "metadata": {
        "id": "2JCfn9p1oa2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨 결과 저장\n",
        "final_labels = []\n",
        "final_tasks=[]\n"
      ],
      "metadata": {
        "id": "gxd0_lUhog32"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 모드 설정\n",
        "fm_model.eval()\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "test_loss_buffer = []\n",
        "test_action_buffer = []\n",
        "measuring_loss = False\n",
        "test_video_file_count = 0\n"
      ],
      "metadata": {
        "id": "9uDYx2Gnog33"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 비디오 업로드 (towtruck 8)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "test_video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "lPTk0j80og33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "4fade470-c5cc-4af5-9003-ddab6e8c9970"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-46592429-a432-48a8-8a99-46e67783584f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-46592429-a432-48a8-8a99-46e67783584f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving towtruck_seperation_8.mov to towtruck_seperation_8 (3).mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 테스트용 비디오 불러오기 =====\n",
        "cap = cv2.VideoCapture(test_video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "\n",
        "with torch.no_grad():  # 테스트 시 gradient 계산 비활성화\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "        step += 1\n",
        "\n",
        "        result = model(frame)[0]\n",
        "        h, w, _ = frame.shape\n",
        "        frame_actions = []\n",
        "\n",
        "        for box in result.boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 테스트 시에는 rehearsal 손실만 계산 (학습하지 않음)\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            total_loss = rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                test_loss_buffer.append(total_loss.item())\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "        final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "        if measuring_loss:\n",
        "            test_action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(\"Test completed with rehearsal evaluation.\")\n",
        "print(\"Test Action Buffer:\", test_action_buffer)\n",
        "print(\"Test Loss Buffer:\", test_loss_buffer)"
      ],
      "metadata": {
        "id": "Bw6FlGImog33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e614f518-7718-4777-8354-f9603c593f3f"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 2 cars, 1 truck, 196.2ms\n",
            "Speed: 4.5ms preprocess, 196.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 214.2ms\n",
            "Speed: 6.4ms preprocess, 214.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 203.6ms\n",
            "Speed: 4.3ms preprocess, 203.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 201.8ms\n",
            "Speed: 6.3ms preprocess, 201.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 209.6ms\n",
            "Speed: 4.3ms preprocess, 209.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.8ms\n",
            "Speed: 4.5ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.9ms\n",
            "Speed: 4.3ms preprocess, 134.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 150.1ms\n",
            "Speed: 4.6ms preprocess, 150.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 139.2ms\n",
            "Speed: 4.0ms preprocess, 139.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.2ms\n",
            "Speed: 4.0ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.8ms\n",
            "Speed: 4.0ms preprocess, 129.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.4ms\n",
            "Speed: 4.0ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.8ms\n",
            "Speed: 4.0ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.7ms\n",
            "Speed: 4.1ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 149.8ms\n",
            "Speed: 7.6ms preprocess, 149.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.1ms\n",
            "Speed: 4.2ms preprocess, 133.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.3ms\n",
            "Speed: 4.6ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.0ms\n",
            "Speed: 4.5ms preprocess, 130.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.0ms\n",
            "Speed: 4.3ms preprocess, 128.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.8ms\n",
            "Speed: 4.3ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 126.5ms\n",
            "Speed: 4.3ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 140.6ms\n",
            "Speed: 7.3ms preprocess, 140.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.7ms\n",
            "Speed: 4.4ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.3ms\n",
            "Speed: 4.3ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.6ms\n",
            "Speed: 4.5ms preprocess, 128.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.5ms\n",
            "Speed: 4.6ms preprocess, 134.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 136.1ms\n",
            "Speed: 4.5ms preprocess, 136.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 149.1ms\n",
            "Speed: 4.6ms preprocess, 149.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.7ms\n",
            "Speed: 3.9ms preprocess, 129.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.0ms\n",
            "Speed: 4.2ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.6ms\n",
            "Speed: 4.1ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.0ms\n",
            "Speed: 4.1ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.1ms\n",
            "Speed: 4.2ms preprocess, 133.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.0ms\n",
            "Speed: 4.1ms preprocess, 134.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 147.4ms\n",
            "Speed: 4.1ms preprocess, 147.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.9ms\n",
            "Speed: 3.9ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.9ms\n",
            "Speed: 4.3ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 126.4ms\n",
            "Speed: 4.3ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.8ms\n",
            "Speed: 4.3ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.9ms\n",
            "Speed: 4.5ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.8ms\n",
            "Speed: 5.3ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 146.7ms\n",
            "Speed: 4.3ms preprocess, 146.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.2ms\n",
            "Speed: 4.1ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.5ms\n",
            "Speed: 4.1ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.4ms\n",
            "Speed: 4.2ms preprocess, 130.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 132.3ms\n",
            "Speed: 4.1ms preprocess, 132.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 133.1ms\n",
            "Speed: 4.4ms preprocess, 133.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.8ms\n",
            "Speed: 4.4ms preprocess, 128.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 143.9ms\n",
            "Speed: 4.8ms preprocess, 143.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.5ms\n",
            "Speed: 3.9ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.1ms\n",
            "Speed: 4.1ms preprocess, 131.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.3ms\n",
            "Speed: 4.1ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 131.9ms\n",
            "Speed: 4.1ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.6ms\n",
            "Speed: 5.8ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.2ms\n",
            "Speed: 4.8ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 146.4ms\n",
            "Speed: 4.6ms preprocess, 146.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 132.1ms\n",
            "Speed: 4.2ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.9ms\n",
            "Speed: 5.1ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.3ms\n",
            "Speed: 4.4ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.9ms\n",
            "Speed: 4.3ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.9ms\n",
            "Speed: 4.2ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.0ms\n",
            "Speed: 4.5ms preprocess, 134.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 143.8ms\n",
            "Speed: 4.6ms preprocess, 143.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 129.6ms\n",
            "Speed: 4.4ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 127.7ms\n",
            "Speed: 4.3ms preprocess, 127.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.9ms\n",
            "Speed: 4.2ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 130.8ms\n",
            "Speed: 4.0ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 127.6ms\n",
            "Speed: 4.3ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 128.6ms\n",
            "Speed: 4.2ms preprocess, 128.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 148.5ms\n",
            "Speed: 4.1ms preprocess, 148.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 168.7ms\n",
            "Speed: 4.3ms preprocess, 168.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 196.9ms\n",
            "Speed: 4.3ms preprocess, 196.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 195.0ms\n",
            "Speed: 6.1ms preprocess, 195.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 193.1ms\n",
            "Speed: 4.3ms preprocess, 193.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 215.3ms\n",
            "Speed: 4.3ms preprocess, 215.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 193.2ms\n",
            "Speed: 4.2ms preprocess, 193.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 199.0ms\n",
            "Speed: 4.3ms preprocess, 199.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 airplane, 196.3ms\n",
            "Speed: 4.3ms preprocess, 196.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 193.5ms\n",
            "Speed: 4.3ms preprocess, 193.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 201.1ms\n",
            "Speed: 9.0ms preprocess, 201.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 192.0ms\n",
            "Speed: 4.3ms preprocess, 192.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 196.0ms\n",
            "Speed: 4.5ms preprocess, 196.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 191.7ms\n",
            "Speed: 4.4ms preprocess, 191.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 188.0ms\n",
            "Speed: 4.4ms preprocess, 188.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 207.7ms\n",
            "Speed: 4.1ms preprocess, 207.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 214.1ms\n",
            "Speed: 4.3ms preprocess, 214.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 210.8ms\n",
            "Speed: 4.4ms preprocess, 210.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 204.2ms\n",
            "Speed: 4.7ms preprocess, 204.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 1 truck, 168.1ms\n",
            "Speed: 4.4ms preprocess, 168.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 130.6ms\n",
            "Speed: 4.9ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 132.9ms\n",
            "Speed: 4.7ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 128.4ms\n",
            "Speed: 4.3ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 128.9ms\n",
            "Speed: 4.4ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 130.2ms\n",
            "Speed: 4.4ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 131.2ms\n",
            "Speed: 4.3ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 150.0ms\n",
            "Speed: 4.2ms preprocess, 150.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 131.3ms\n",
            "Speed: 4.4ms preprocess, 131.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 137.0ms\n",
            "Speed: 4.5ms preprocess, 137.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 130.7ms\n",
            "Speed: 4.3ms preprocess, 130.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 130.3ms\n",
            "Speed: 4.3ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 131.4ms\n",
            "Speed: 4.6ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 129.7ms\n",
            "Speed: 4.5ms preprocess, 129.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 148.6ms\n",
            "Speed: 4.3ms preprocess, 148.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 bus, 132.6ms\n",
            "Speed: 4.4ms preprocess, 132.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.6ms\n",
            "Speed: 4.4ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 128.2ms\n",
            "Speed: 4.5ms preprocess, 128.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 128.1ms\n",
            "Speed: 4.4ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 130.2ms\n",
            "Speed: 4.4ms preprocess, 130.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 suitcase, 127.8ms\n",
            "Speed: 4.3ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 148.4ms\n",
            "Speed: 4.4ms preprocess, 148.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 suitcase, 131.8ms\n",
            "Speed: 4.0ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 126.9ms\n",
            "Speed: 4.2ms preprocess, 126.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 cars, 1 suitcase, 131.7ms\n",
            "Speed: 4.1ms preprocess, 131.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 131.2ms\n",
            "Speed: 4.0ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 130.6ms\n",
            "Speed: 4.1ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 130.6ms\n",
            "Speed: 4.4ms preprocess, 130.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 144.5ms\n",
            "Speed: 4.3ms preprocess, 144.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.7ms\n",
            "Speed: 4.2ms preprocess, 130.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.1ms\n",
            "Speed: 4.1ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 136.9ms\n",
            "Speed: 4.1ms preprocess, 136.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 127.5ms\n",
            "Speed: 4.3ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.2ms\n",
            "Speed: 3.9ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 128.2ms\n",
            "Speed: 4.3ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 148.5ms\n",
            "Speed: 7.7ms preprocess, 148.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 129.7ms\n",
            "Speed: 4.4ms preprocess, 129.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.3ms\n",
            "Speed: 4.2ms preprocess, 130.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 125.9ms\n",
            "Speed: 4.3ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 133.2ms\n",
            "Speed: 4.2ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.1ms\n",
            "Speed: 4.0ms preprocess, 132.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.8ms\n",
            "Speed: 4.1ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 149.0ms\n",
            "Speed: 4.0ms preprocess, 149.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 129.1ms\n",
            "Speed: 4.3ms preprocess, 129.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 133.1ms\n",
            "Speed: 4.1ms preprocess, 133.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.9ms\n",
            "Speed: 4.5ms preprocess, 130.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.3ms\n",
            "Speed: 4.4ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 147.5ms\n",
            "Speed: 5.5ms preprocess, 147.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 134.3ms\n",
            "Speed: 4.4ms preprocess, 134.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.5ms\n",
            "Speed: 4.2ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 129.7ms\n",
            "Speed: 4.4ms preprocess, 129.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 129.9ms\n",
            "Speed: 4.6ms preprocess, 129.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.2ms\n",
            "Speed: 4.4ms preprocess, 130.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 128.2ms\n",
            "Speed: 4.4ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 127.4ms\n",
            "Speed: 5.0ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 144.8ms\n",
            "Speed: 4.0ms preprocess, 144.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 124.6ms\n",
            "Speed: 4.4ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 128.7ms\n",
            "Speed: 4.3ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.0ms\n",
            "Speed: 4.4ms preprocess, 130.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.3ms\n",
            "Speed: 4.0ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.5ms\n",
            "Speed: 4.3ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.9ms\n",
            "Speed: 4.3ms preprocess, 130.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 148.0ms\n",
            "Speed: 4.5ms preprocess, 148.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 128.9ms\n",
            "Speed: 5.4ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 128.3ms\n",
            "Speed: 4.5ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 131.1ms\n",
            "Speed: 5.6ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 202.3ms\n",
            "Speed: 5.3ms preprocess, 202.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 196.7ms\n",
            "Speed: 4.3ms preprocess, 196.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 212.3ms\n",
            "Speed: 5.2ms preprocess, 212.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 193.6ms\n",
            "Speed: 4.1ms preprocess, 193.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 197.2ms\n",
            "Speed: 4.5ms preprocess, 197.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 192.8ms\n",
            "Speed: 5.2ms preprocess, 192.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 231.0ms\n",
            "Speed: 4.2ms preprocess, 231.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 267.1ms\n",
            "Speed: 5.7ms preprocess, 267.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 265.5ms\n",
            "Speed: 8.6ms preprocess, 265.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 219.9ms\n",
            "Speed: 4.5ms preprocess, 219.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 204.4ms\n",
            "Speed: 12.6ms preprocess, 204.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 257.1ms\n",
            "Speed: 6.5ms preprocess, 257.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 209.2ms\n",
            "Speed: 4.3ms preprocess, 209.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 194.3ms\n",
            "Speed: 4.5ms preprocess, 194.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 200.2ms\n",
            "Speed: 5.7ms preprocess, 200.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 222.3ms\n",
            "Speed: 5.7ms preprocess, 222.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 260.8ms\n",
            "Speed: 6.8ms preprocess, 260.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 254.3ms\n",
            "Speed: 5.7ms preprocess, 254.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 216.6ms\n",
            "Speed: 10.6ms preprocess, 216.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 216.4ms\n",
            "Speed: 8.2ms preprocess, 216.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 284.4ms\n",
            "Speed: 4.2ms preprocess, 284.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 247.3ms\n",
            "Speed: 11.2ms preprocess, 247.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 258.9ms\n",
            "Speed: 4.2ms preprocess, 258.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 230.9ms\n",
            "Speed: 6.9ms preprocess, 230.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 266.7ms\n",
            "Speed: 4.0ms preprocess, 266.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 202.4ms\n",
            "Speed: 4.1ms preprocess, 202.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 202.5ms\n",
            "Speed: 7.5ms preprocess, 202.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 208.7ms\n",
            "Speed: 7.0ms preprocess, 208.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 212.5ms\n",
            "Speed: 4.2ms preprocess, 212.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 198.8ms\n",
            "Speed: 7.0ms preprocess, 198.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 suitcase, 125.8ms\n",
            "Speed: 3.9ms preprocess, 125.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Test completed with rehearsal evaluation.\n",
            "Test Action Buffer: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Test Loss Buffer: [0.004119704477488995, 0.002728597493842244, 0.004967603366822004, 0.003125577000901103, 0.0019495076267048717, 0.003468576353043318, 0.002237489214166999, 0.004616935271769762, 0.005716542713344097, 0.003530496032908559, 0.005613786168396473, 0.0019771482329815626, 0.00549314497038722, 0.001865818863734603, 0.0032126614823937416, 0.0015904126921668649, 0.0031838323920965195, 0.002882394939661026, 0.005771840922534466, 0.004362758249044418, 0.002460762858390808, 0.009876448661088943, 0.0032764538191258907, 0.004943192936480045, 0.006328854709863663, 0.004467749036848545, 0.004919355269521475, 0.0026726394426077604, 0.007116687949746847, 0.0033531533554196358, 0.005633518099784851, 0.003922020085155964, 0.003104632953181863, 0.002389343222603202, 0.004571139812469482, 0.00218366552144289, 0.0011704795761033893, 0.004246770869940519, 0.0031821983866393566, 0.004017270170152187, 0.0027280407957732677, 0.001475996570661664, 0.00633220886811614, 0.005181091837584972, 0.005859037395566702, 0.004025402944535017, 0.002152335597202182, 0.003634618129581213, 0.005356539040803909, 0.0033700685016810894, 0.006344215478748083, 0.0007498001214116812, 0.002678660908713937, 0.0051894411444664, 0.005590910091996193, 0.009102326817810535, 0.0022687094751745462, 0.004001008812338114, 0.002307119546458125, 0.005353786516934633, 0.003926093690097332, 0.0028579425998032093, 0.004816023632884026, 0.0017776809399947524, 0.0015374822542071342, 0.006504821591079235, 0.0038026270922273397, 0.0037632081657648087, 0.0020046972203999758, 0.0037913289852440357, 0.0022995711769908667, 0.0023321236949414015, 0.006235412321984768, 0.0033577706199139357, 0.006626141257584095, 0.003411024808883667, 0.00317212357185781, 0.005402070935815573, 0.004877571947872639, 0.003683808259665966, 0.006711409892886877, 0.007238069549202919, 0.00211954559199512, 0.0021536811254918575, 0.007684720680117607, 0.0039765904657542706, 0.0045519014820456505, 0.004440424498170614, 0.001794772339053452, 0.00576508603990078, 0.005849318113178015, 0.005485697649419308, 0.0026482800021767616, 0.0010599521920084953, 0.003356353146955371, 0.00302178505808115, 0.001511354697868228, 0.0026375765446573496, 0.003681545378640294, 0.0038422932848334312, 0.0042929258197546005, 0.003506840905174613, 0.003843404818326235, 0.0011306088417768478, 0.0019679651595652103, 0.006762392353266478, 0.006815672852098942, 0.0035387538373470306, 0.003622140735387802, 0.008671671152114868, 0.002436186419799924, 0.005241394508630037, 0.00454272236675024, 0.006472458131611347, 0.004380900878459215, 0.001213595038279891, 0.00317625654861331, 0.006107148248702288, 0.0036553856916725636, 0.001842227065935731, 0.0019119540229439735, 0.0035579795949161053, 0.0017285286448895931, 0.004364355467259884, 0.0033079751301556826, 0.004856140352785587, 0.002638152800500393, 0.004737344570457935, 0.003589802887290716, 0.0033411853946745396, 0.0030280454084277153, 0.0030289997812360525, 0.0047544194385409355, 0.0030071716755628586, 0.0067183091305196285, 0.011874916963279247, 0.004357045982033014, 0.004552271217107773, 0.0067537459544837475, 0.001972849015146494, 0.004726456478238106, 0.0071547129191458225, 0.002496670000255108, 0.0019050497794523835, 0.001125069335103035, 0.0034163726959377527, 0.0027418104000389576, 0.006590275093913078, 0.002428718376904726, 0.005536758340895176, 0.003188047558069229, 0.0033410985488444567, 0.003974171355366707, 0.004892562981694937, 0.00417122058570385, 0.001966908574104309, 0.0023767133243381977, 0.0035095512866973877, 0.0034819631837308407, 0.006860826164484024, 0.005624615121632814, 0.00430032704025507, 0.0015441630966961384, 0.006686174310743809, 0.001960159745067358, 0.0020924650598317385, 0.0048471600748598576, 0.006042202934622765, 0.003628411330282688, 0.004843045026063919, 0.008933539502322674, 0.0032812897115945816, 0.004208359867334366, 0.0051583233289420605, 0.0021429904736578465, 0.004449308384209871, 0.0032444868702441454, 0.0075320047326385975, 0.004440732300281525, 0.0030985905323177576, 0.003300708718597889, 0.004134526941925287, 0.004803630989044905, 0.0028051314875483513, 0.0033535929396748543, 0.0020558745600283146, 0.003031729022040963, 0.003733484074473381, 0.0024036657996475697, 0.005415933206677437, 0.006460650824010372, 0.002482071053236723, 0.0019546118564903736, 0.004314726684242487, 0.0016993387835100293, 0.002709160093218088, 0.0018614405998960137, 0.0020316217560321093, 0.003499619895592332, 0.002117249183356762, 0.004416657146066427, 0.002895515412092209, 0.0015455844113603234, 0.004160622134804726, 0.0030604624189436436, 0.007743590511381626, 0.0037186203990131617, 0.0016224365681409836, 0.007623491808772087, 0.0027808716986328363, 0.0025425117928534746, 0.002920818282291293, 0.004165046848356724, 0.008112376555800438, 0.003250613110139966, 0.0018304350087419152, 0.0036500655114650726, 0.0030771985184401274, 0.004445152822881937, 0.002190222265198827, 0.003402384929358959, 0.0033160399179905653, 0.002835080260410905, 0.004686965607106686, 0.002629912458360195, 0.009337876923382282, 0.007448400836437941, 0.0027200139593333006, 0.008653569966554642, 0.003810850204899907, 0.0015585448127239943, 0.003856523660942912, 0.0021697988267987967, 0.0061609819531440735, 0.004712326917797327, 0.003917048219591379, 0.005152709782123566, 0.004182054195553064, 0.003041645046323538, 0.0012611898127943277, 0.0035366308875381947, 0.0014747948152944446, 0.0032760174944996834, 0.0024094837717711926, 0.0017913661431521177, 0.002774226712062955, 0.007558475714176893, 0.003554391209036112, 0.0013189607998356223, 0.002459165873005986, 0.005898912437260151, 0.0051209828816354275, 0.005812408868223429, 0.004233276937156916, 0.00177755206823349, 0.0018227645196020603, 0.005244412459433079, 0.006455696187913418, 0.0022351592779159546, 0.0031186637934297323, 0.0024635258596390486, 0.005259167868643999, 0.0033255750313401222, 0.00828518345952034, 0.0031618785578757524, 0.002666355110704899, 0.0032414740417152643, 0.0025017003063112497, 0.005183362402021885, 0.0011461079120635986, 0.0032340215984731913, 0.0016993798781186342, 0.011182039976119995, 0.0035427601542323828, 0.0054129366762936115, 0.002495779888704419, 0.0036842897534370422, 0.004630195442587137, 0.009148125536739826, 0.002083844505250454, 0.0009104618802666664, 0.0030076750554144382, 0.003087474498897791, 0.001410618075169623, 0.0058264234103262424, 0.00707253348082304, 0.003974422812461853, 0.006803321186453104, 0.0048155952244997025, 0.0051815505139529705, 0.0014460866805166006, 0.006762180011719465, 0.00235644169151783, 0.0010686384048312902, 0.0054871151223778725, 0.003331623738631606, 0.0021717504132539034, 0.003219595178961754, 0.005967115983366966, 0.004502527415752411, 0.005061740055680275, 0.006067892070859671, 0.0030185701325535774, 0.006611886899918318, 0.005014645867049694, 0.0037979730404913425, 0.0016604985576123, 0.006888465955853462, 0.002494643209502101, 0.0009992157574743032, 0.002687737811356783, 0.0023726611398160458, 0.005397237837314606, 0.00346640357747674, 0.004949851892888546, 0.0035549006424844265, 0.007279097568243742, 0.0033087837509810925, 0.0039031743071973324, 0.0027280624490231276, 0.007931588217616081, 0.003122077789157629, 0.0037151239812374115, 0.005204716697335243, 0.003422255627810955, 0.001958453794941306, 0.0050197322852909565, 0.0046073067933321, 0.005661933682858944, 0.004367757122963667, 0.004796403925865889, 0.0059185088612139225, 0.007714117877185345, 0.0024344297125935555, 0.004441958852112293, 0.0044379327446222305, 0.002134050941094756, 0.002322737593203783, 0.007264536339789629, 0.004102876875549555, 0.003647832665592432, 0.004467490594834089, 0.003924207296222448, 0.0033271918073296547, 0.0028446498326957226, 0.006539004389196634, 0.0035991703625768423, 0.004326045513153076, 0.0038604033179581165, 0.0033316921908408403, 0.004200615920126438, 0.00426487298682332, 0.0037485267966985703, 0.00291315745562315, 0.0037759686820209026, 0.0013128418941050768, 0.0034951167181134224, 0.004520878661423922, 0.003947963938117027, 0.0014715117868036032, 0.006056959740817547, 0.0035012178122997284, 0.0018263818928971887, 0.005032888613641262, 0.0025472023990005255, 0.009441300295293331, 0.0027566482312977314, 0.0013939300552010536, 0.005253482609987259, 0.001952093094587326, 0.0023250163067132235, 0.0031400166917592287, 0.0014929904136806726, 0.002068502129986882, 0.003023725701496005, 0.002457153517752886, 0.003875352907925844, 0.001547773601487279, 0.001992925303056836, 0.0031596971675753593, 0.004947655834257603, 0.004123129416257143, 0.003811111906543374, 0.0019772490486502647, 0.005571391433477402, 0.004039463121443987, 0.003746365662664175, 0.0031934676226228476, 0.0054341577924788, 0.005578779615461826, 0.0033768785651773214, 0.0017698470037430525, 0.006603343412280083, 0.005157166160643101, 0.0028259693644940853, 0.0033313401509076357, 0.0037895578425377607, 0.0022655497305095196, 0.0030586794018745422, 0.005065408535301685, 0.006678259465843439, 0.004311013501137495, 0.009085562080144882, 0.003788028610870242, 0.008526566438376904, 0.0039642686024308205, 0.003450254676863551, 0.0030740774236619473, 0.0018959532026201487, 0.005386709235608578, 0.0015322070103138685, 0.004732772707939148, 0.004763043485581875, 0.0029962132684886456, 0.002500799484550953, 0.004407122265547514, 0.005848343018442392, 0.003908719401806593, 0.0018857658142223954, 0.0030337213538587093, 0.004328710958361626, 0.0044005559757351875, 0.003543880069628358, 0.0030988273210823536, 0.0019192543113604188, 0.0018824439030140638, 0.0057410551235079765, 0.006191393826156855, 0.002627133158966899, 0.0019830656237900257, 0.0027135019190609455, 0.005021755117923021, 0.009558851830661297, 0.0019895851146429777, 0.01072024181485176, 0.002949984511360526, 0.0019129845313727856, 0.00483215507119894, 0.004252875689417124, 0.0018662691581994295, 0.0026656724512577057, 0.004430676344782114, 0.0033076144754886627, 0.0027198137249797583, 0.002102864906191826, 0.0014698050217702985, 0.0014265545178204775, 0.004869806580245495, 0.0028684523422271013, 0.005507157649844885, 0.0018650121055543423, 0.004465659148991108, 0.002442017663270235, 0.006554339546710253, 0.0016316125402227044, 0.005580045748502016, 0.00223709037527442, 0.003107877913862467, 0.004820671863853931, 0.001992663601413369, 0.004018635489046574, 0.004554255865514278, 0.004960776772350073, 0.005159772001206875, 0.006802254822105169, 0.003064572112634778, 0.003655307460576296, 0.001352915889583528, 0.001350226579234004, 0.005137885920703411, 0.007072301581501961, 0.004758997354656458, 0.006204561796039343, 0.003974183928221464, 0.00418970687314868, 0.002139908727258444, 0.003214495722204447, 0.004469031933695078, 0.00158772524446249, 0.0021315105259418488, 0.0027747261337935925, 0.0036558755673468113, 0.006735143251717091, 0.003340537892654538, 0.003834867151454091, 0.0012749464949592948, 0.005316516384482384, 0.003082074923440814, 0.0019497110042721033, 0.0019082040525972843, 0.002228118944913149, 0.002144724130630493, 0.0042505888268351555, 0.0017307919915765524, 0.0028548783157020807, 0.003101595211774111, 0.003678181441500783, 0.001511560520157218, 0.0027334154583513737, 0.0031899106688797474, 0.002444595331326127, 0.0035110434982925653, 0.004205286502838135, 0.0039947377517819405, 0.0027396944351494312, 0.003674902254715562, 0.003272249596193433, 0.007841585204005241, 0.0007234306540340185, 0.0031899823807179928, 0.009465166367590427, 0.0050394111312925816, 0.004930827300995588, 0.004012394696474075, 0.009406961500644684, 0.0034180558286607265, 0.0038322554901242256, 0.0030489391647279263, 0.005253134295344353, 0.004998567048460245]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 라벨 설정\n",
        "test_frame_labels = truck8['go_stop_decision'] # 여기에 driving12, truck8, uturn7을 값을 바꿔가며 넣기"
      ],
      "metadata": {
        "id": "wb_zwz-0og33"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 타입 및 길이 확인\n",
        "print(type(test_action_buffer))\n",
        "print(type(test_frame_labels))\n",
        "print(len(test_action_buffer))\n",
        "print(len(test_frame_labels))"
      ],
      "metadata": {
        "id": "8HYNNE7gog33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f8fa59-b1b4-4451-95ba-9b4f8af8c604"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "185\n",
            "185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과 저장\n",
        "final_tasks.append(test_action_buffer)\n",
        "final_labels.append(test_frame_labels)"
      ],
      "metadata": {
        "id": "PJ-DVkkRog33"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CL 메트릭 계산\n",
        "IM, FWT, BWT = compute_cl_metrics(final_tasks, final_labels)\n",
        "\n",
        "print(f\"IM (Initial Accuracy): {IM:.5f}\")\n",
        "print(f\"FWT (Forward Transfer): {FWT:.5f}\")\n",
        "print(f\"BWT (Backward Transfer): {BWT:.5f}\")\n"
      ],
      "metadata": {
        "id": "LwQ01F00og33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f5a085-d458-4a42-96c2-75cdffebbfee"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task accuracies: [    0.41081]\n",
            "IM (Initial Accuracy): 0.41081\n",
            "FWT (Forward Transfer): 0.00000\n",
            "BWT (Backward Transfer): 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rehearsal 메모리 상태 확인\n",
        "print(f\"Rehearsal memory contains {len(rehearsal_memory.data_buffer)} samples\")\n",
        "print(f\"Memory usage: {len(rehearsal_memory.data_buffer)} / {rehearsal_memory.max_samples}\")"
      ],
      "metadata": {
        "id": "ZQxDZRmXog33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd5587ff-bfe4-43f9-c627-5c52ba72be8e"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rehearsal memory contains 900 samples\n",
            "Memory usage: 900 / 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 샘플의 일부 확인\n",
        "if len(rehearsal_memory.data_buffer) > 0:\n",
        "    sample_data = rehearsal_memory.data_buffer[0]\n",
        "    sample_label = rehearsal_memory.label_buffer[0]\n",
        "    print(f\"Sample data shape: {sample_data.shape}\")\n",
        "    print(f\"Sample label: {sample_label}\")"
      ],
      "metadata": {
        "id": "Ut3b7dg9og33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5d0a87-0bab-4f1c-a819-1788286036ea"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data shape: (15,)\n",
            "Sample label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_tasks)"
      ],
      "metadata": {
        "id": "aHyIUDc5og34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ab4c30-45bb-474f-d5ce-60591a193eb1"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Uturn7 평가"
      ],
      "metadata": {
        "id": "XcJ7GPkcolQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#라벨 결과 저장\n",
        "final_labels = []\n",
        "final_tasks=[]\n"
      ],
      "metadata": {
        "id": "vEd5urcEo1cw"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 평가 모드 설정\n",
        "fm_model.eval()\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "test_loss_buffer = []\n",
        "test_action_buffer = []\n",
        "measuring_loss = False\n",
        "test_video_file_count = 0\n"
      ],
      "metadata": {
        "id": "zGQ0c0qZo1cw"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 비디오 업로드 (Uturn 7)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일명 추출\n",
        "test_video_path = next(iter(uploaded))"
      ],
      "metadata": {
        "id": "4j4hk4Mko1cw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "e14a5f8d-1bbe-4683-e5aa-f2f97e23bce4"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5bb7519d-63c3-499b-b234-16c23bde9d16\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5bb7519d-63c3-499b-b234-16c23bde9d16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Uturn_7.mov to Uturn_7 (1).mov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 테스트용 비디오 불러오기 =====\n",
        "cap = cv2.VideoCapture(test_video_path)\n",
        "\n",
        "frame_idx = 0\n",
        "step = 0\n",
        "measuring_loss = True\n",
        "\n",
        "with torch.no_grad():  # 테스트 시 gradient 계산 비활성화\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_idx += 1\n",
        "        step += 1\n",
        "\n",
        "        result = model(frame)[0]\n",
        "        h, w, _ = frame.shape\n",
        "        frame_actions = []\n",
        "\n",
        "        for box in result.boxes:\n",
        "            cls_id = int(box.cls[0])\n",
        "            conf = float(box.conf[0])\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            area = (x2 - x1) * (y2 - y1)\n",
        "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
        "            est_dist = 700 * 1.7 / (y2 - y1 + 1e-6)\n",
        "\n",
        "            x = preprocess_input(cls_id, conf, est_dist, area, cx, cy).to(device)\n",
        "            x_noisy = add_noise(x)\n",
        "\n",
        "            y_pred, emb_orig = fm_model(x)\n",
        "            _, emb_noisy = fm_model(x_noisy)\n",
        "\n",
        "            # 테스트 시에는 rehearsal 손실만 계산 (학습하지 않음)\n",
        "            rehearsal_data, rehearsal_labels = rehearsal_memory.get_rehearsal_batch(batch_size=16)\n",
        "            rehearsal_loss = 0\n",
        "\n",
        "            if rehearsal_data is not None:\n",
        "                rehearsal_data = rehearsal_data.to(device)\n",
        "                rehearsal_labels = rehearsal_labels.to(device)\n",
        "\n",
        "                rehearsal_preds, _ = fm_model(rehearsal_data)\n",
        "                rehearsal_loss = loss_fn(rehearsal_preds, rehearsal_labels)\n",
        "\n",
        "            total_loss = rehearsal_loss\n",
        "\n",
        "            if measuring_loss:\n",
        "                test_loss_buffer.append(total_loss.item())\n",
        "\n",
        "            act = int(y_pred.item() >= 0.5)\n",
        "            frame_actions.append(act)\n",
        "\n",
        "        final_act = 1 if frame_actions and sum(frame_actions) / len(frame_actions) >= 0.5 else 0\n",
        "        if measuring_loss:\n",
        "            test_action_buffer.append(final_act)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "print(\"Test completed with rehearsal evaluation.\")\n",
        "print(\"Test Action Buffer:\", test_action_buffer)\n",
        "print(\"Test Loss Buffer:\", test_loss_buffer)"
      ],
      "metadata": {
        "id": "JHhLCUV3o1cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f4fd35-b5b3-4dff-f174-8705b17b7f43"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 155.0ms\n",
            "Speed: 5.1ms preprocess, 155.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 129.3ms\n",
            "Speed: 4.0ms preprocess, 129.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 129.3ms\n",
            "Speed: 4.2ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 129.8ms\n",
            "Speed: 4.3ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 127.2ms\n",
            "Speed: 4.2ms preprocess, 127.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 129.9ms\n",
            "Speed: 4.8ms preprocess, 129.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 127.7ms\n",
            "Speed: 4.3ms preprocess, 127.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 150.8ms\n",
            "Speed: 4.3ms preprocess, 150.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 truck, 127.5ms\n",
            "Speed: 4.3ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 132.8ms\n",
            "Speed: 4.3ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 129.0ms\n",
            "Speed: 4.3ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 129.4ms\n",
            "Speed: 4.3ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 truck, 128.5ms\n",
            "Speed: 4.0ms preprocess, 128.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 truck, 133.4ms\n",
            "Speed: 4.0ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 142.3ms\n",
            "Speed: 5.3ms preprocess, 142.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.3ms\n",
            "Speed: 4.0ms preprocess, 134.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 134.3ms\n",
            "Speed: 4.4ms preprocess, 134.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 131.1ms\n",
            "Speed: 4.0ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 132.5ms\n",
            "Speed: 4.1ms preprocess, 132.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 130.2ms\n",
            "Speed: 4.4ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 133.3ms\n",
            "Speed: 4.1ms preprocess, 133.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 137.5ms\n",
            "Speed: 14.2ms preprocess, 137.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 129.2ms\n",
            "Speed: 4.2ms preprocess, 129.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 131.8ms\n",
            "Speed: 4.1ms preprocess, 131.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 132.8ms\n",
            "Speed: 4.1ms preprocess, 132.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 128.5ms\n",
            "Speed: 4.2ms preprocess, 128.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 131.8ms\n",
            "Speed: 4.2ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 cars, 141.8ms\n",
            "Speed: 5.5ms preprocess, 141.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.0ms\n",
            "Speed: 4.4ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.4ms\n",
            "Speed: 4.3ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.6ms\n",
            "Speed: 3.9ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.1ms\n",
            "Speed: 4.3ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.5ms\n",
            "Speed: 4.2ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.9ms\n",
            "Speed: 4.6ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.5ms\n",
            "Speed: 3.9ms preprocess, 136.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 211.1ms\n",
            "Speed: 4.2ms preprocess, 211.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 194.8ms\n",
            "Speed: 5.5ms preprocess, 194.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 196.9ms\n",
            "Speed: 4.2ms preprocess, 196.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 200.6ms\n",
            "Speed: 7.3ms preprocess, 200.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 213.3ms\n",
            "Speed: 4.2ms preprocess, 213.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 200.2ms\n",
            "Speed: 4.2ms preprocess, 200.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 212.2ms\n",
            "Speed: 4.1ms preprocess, 212.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 207.9ms\n",
            "Speed: 4.8ms preprocess, 207.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 207.4ms\n",
            "Speed: 5.1ms preprocess, 207.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 204.3ms\n",
            "Speed: 4.2ms preprocess, 204.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 193.2ms\n",
            "Speed: 4.2ms preprocess, 193.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 197.8ms\n",
            "Speed: 4.2ms preprocess, 197.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 194.2ms\n",
            "Speed: 6.9ms preprocess, 194.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 207.6ms\n",
            "Speed: 5.4ms preprocess, 207.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 227.5ms\n",
            "Speed: 4.3ms preprocess, 227.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 206.4ms\n",
            "Speed: 4.1ms preprocess, 206.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 199.0ms\n",
            "Speed: 6.0ms preprocess, 199.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 139.4ms\n",
            "Speed: 6.6ms preprocess, 139.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.7ms\n",
            "Speed: 4.3ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.1ms\n",
            "Speed: 4.4ms preprocess, 131.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.6ms\n",
            "Speed: 4.2ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.9ms\n",
            "Speed: 3.8ms preprocess, 130.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.6ms\n",
            "Speed: 4.3ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.7ms\n",
            "Speed: 4.4ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 128.4ms\n",
            "Speed: 4.5ms preprocess, 128.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 130.8ms\n",
            "Speed: 4.3ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 136.3ms\n",
            "Speed: 4.3ms preprocess, 136.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.6ms\n",
            "Speed: 4.4ms preprocess, 128.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.2ms\n",
            "Speed: 5.4ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.9ms\n",
            "Speed: 4.3ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.9ms\n",
            "Speed: 4.3ms preprocess, 126.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 124.9ms\n",
            "Speed: 4.2ms preprocess, 124.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 129.1ms\n",
            "Speed: 4.3ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 134.1ms\n",
            "Speed: 4.7ms preprocess, 134.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 124.2ms\n",
            "Speed: 6.8ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.5ms\n",
            "Speed: 4.2ms preprocess, 128.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.8ms\n",
            "Speed: 4.0ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.8ms\n",
            "Speed: 4.4ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.1ms\n",
            "Speed: 4.3ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.6ms\n",
            "Speed: 4.5ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 134.2ms\n",
            "Speed: 4.2ms preprocess, 134.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 141.2ms\n",
            "Speed: 4.2ms preprocess, 141.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.9ms\n",
            "Speed: 4.6ms preprocess, 133.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 131.6ms\n",
            "Speed: 4.3ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 129.1ms\n",
            "Speed: 4.7ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 128.3ms\n",
            "Speed: 4.3ms preprocess, 128.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 126.5ms\n",
            "Speed: 4.3ms preprocess, 126.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 128.2ms\n",
            "Speed: 4.2ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 149.6ms\n",
            "Speed: 4.2ms preprocess, 149.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.4ms\n",
            "Speed: 4.3ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.2ms\n",
            "Speed: 4.3ms preprocess, 126.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 128.3ms\n",
            "Speed: 4.2ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 1 frisbee, 126.4ms\n",
            "Speed: 4.3ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 124.9ms\n",
            "Speed: 4.2ms preprocess, 124.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 128.3ms\n",
            "Speed: 4.3ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 140.8ms\n",
            "Speed: 4.3ms preprocess, 140.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 123.9ms\n",
            "Speed: 4.4ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.1ms\n",
            "Speed: 5.3ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.7ms\n",
            "Speed: 4.1ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 125.1ms\n",
            "Speed: 4.5ms preprocess, 125.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 123.1ms\n",
            "Speed: 5.8ms preprocess, 123.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.0ms\n",
            "Speed: 4.2ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 150.0ms\n",
            "Speed: 4.0ms preprocess, 150.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.8ms\n",
            "Speed: 4.3ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 124.1ms\n",
            "Speed: 4.2ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 124.7ms\n",
            "Speed: 4.5ms preprocess, 124.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.5ms\n",
            "Speed: 4.2ms preprocess, 129.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 frisbee, 127.2ms\n",
            "Speed: 4.2ms preprocess, 127.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 128.1ms\n",
            "Speed: 4.3ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 150.3ms\n",
            "Speed: 4.0ms preprocess, 150.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 129.2ms\n",
            "Speed: 4.2ms preprocess, 129.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 124.5ms\n",
            "Speed: 4.3ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.4ms\n",
            "Speed: 4.5ms preprocess, 126.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 127.5ms\n",
            "Speed: 4.9ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.9ms\n",
            "Speed: 4.3ms preprocess, 126.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.3ms\n",
            "Speed: 4.6ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 146.4ms\n",
            "Speed: 4.5ms preprocess, 146.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 132.9ms\n",
            "Speed: 4.0ms preprocess, 132.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 125.2ms\n",
            "Speed: 4.2ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.9ms\n",
            "Speed: 4.2ms preprocess, 130.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 133.2ms\n",
            "Speed: 4.2ms preprocess, 133.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 126.3ms\n",
            "Speed: 4.3ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 130.5ms\n",
            "Speed: 4.2ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 141.6ms\n",
            "Speed: 4.2ms preprocess, 141.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 166.5ms\n",
            "Speed: 6.5ms preprocess, 166.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 207.8ms\n",
            "Speed: 4.5ms preprocess, 207.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 193.2ms\n",
            "Speed: 7.9ms preprocess, 193.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 196.4ms\n",
            "Speed: 4.2ms preprocess, 196.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 213.0ms\n",
            "Speed: 4.3ms preprocess, 213.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 196.5ms\n",
            "Speed: 4.0ms preprocess, 196.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 191.0ms\n",
            "Speed: 4.5ms preprocess, 191.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 204.1ms\n",
            "Speed: 5.0ms preprocess, 204.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 193.1ms\n",
            "Speed: 6.4ms preprocess, 193.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 217.7ms\n",
            "Speed: 4.2ms preprocess, 217.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 1 airplane, 194.7ms\n",
            "Speed: 9.8ms preprocess, 194.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 197.2ms\n",
            "Speed: 5.1ms preprocess, 197.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 192.5ms\n",
            "Speed: 9.7ms preprocess, 192.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 196.1ms\n",
            "Speed: 4.2ms preprocess, 196.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 car, 213.8ms\n",
            "Speed: 4.1ms preprocess, 213.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Test completed with rehearsal evaluation.\n",
            "Test Action Buffer: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "Test Loss Buffer: [0.004049004055559635, 0.0043342639692127705, 0.004849906079471111, 0.005361911840736866, 0.010201934725046158, 0.003793057519942522, 0.0044760205782949924, 0.0019191509345546365, 0.0014550720807164907, 0.002908437978476286, 0.001581458724103868, 0.0024384271819144487, 0.0032259286381304264, 0.004905169829726219, 0.003052642336115241, 0.006821583490818739, 0.002120999386534095, 0.00684445071965456, 0.00196392391808331, 0.006075842771679163, 0.0029432703740894794, 0.001532925758510828, 0.003887442173436284, 0.009035223163664341, 0.004815584514290094, 0.005978195928037167, 0.003476222511380911, 0.0025099576450884342, 0.0047320155426859856, 0.00306625640951097, 0.001226804917678237, 0.00391747523099184, 0.0017823501257225871, 0.0032912027090787888, 0.001173771102912724, 0.0023968468885868788, 0.002035609446465969, 0.0025816159322857857, 0.00284598208963871, 0.004336768761277199, 0.0027330403681844473, 0.00608806312084198, 0.003219778649508953, 0.004934991244226694, 0.002733940724283457, 0.002503693802282214, 0.0015324280830100179, 0.003935564775019884, 0.0087539441883564, 0.003480402519926429, 0.0031747333705425262, 0.002815688494592905, 0.0034716292284429073, 0.0039703394286334515, 0.0057466221041977406, 0.0028373876120895147, 0.004700613208115101, 0.0036379145458340645, 0.00966757070273161, 0.004861089400947094, 0.004409885033965111, 0.002260546898469329, 0.0057272836565971375, 0.0025715138763189316, 0.0048421695828437805, 0.004008031450212002, 0.004916221834719181, 0.00491361366584897, 0.004111938178539276, 0.0018795643700286746, 0.002929761540144682, 0.0011194385588169098, 0.00403807545080781, 0.002635546261444688, 0.0032839493360370398, 0.007064411416649818, 0.0018739652587100863, 0.0014626788906753063, 0.007520458661019802, 0.0021652011200785637, 0.01096411608159542, 0.0068891700357198715, 0.0030141703318804502, 0.0015590719413012266, 0.0026537971571087837, 0.0026771605480462313, 0.0038597395177930593, 0.0023527760058641434, 0.0007064785459078848, 0.0032980176620185375, 0.006254928186535835, 0.004987193271517754, 0.0035042413510382175, 0.0028052804991602898, 0.0037900079041719437, 0.005204353481531143, 0.002121340949088335, 0.002356752287596464, 0.003319753101095557, 0.001542328274808824, 0.00353409955278039, 0.0033191980328410864, 0.0019485903903841972, 0.003971046302467585, 0.0072600096464157104, 0.002948792651295662, 0.0024300608783960342, 0.0015994899440556765, 0.006062635220587254, 0.0025387576315551996, 0.00505378283560276, 0.00155847636051476, 0.0026818327605724335, 0.004705800674855709, 0.0036457760725170374, 0.003171307034790516, 0.004774876404553652, 0.0035111752804368734, 0.0032870788127183914, 0.004389275796711445, 0.002244640840217471, 0.004496309906244278, 0.0009420386631973088, 0.001660168869420886, 0.004968447610735893, 0.0014753354480490088, 0.0015932312235236168, 0.0037786844186484814, 0.003904159879311919, 0.0015496863052248955, 0.0023715815041214228, 0.004189908504486084, 0.003753574099391699, 0.003652963787317276, 0.0021174391731619835, 0.003082717303186655, 0.0017278613522648811, 0.0023479261435568333, 0.0037328496109694242, 0.00259793852455914, 0.002471450250595808, 0.003154283156618476, 0.003717835759744048, 0.005415335763245821, 0.006035416387021542, 0.0025853998959064484, 0.004521023482084274, 0.002489871345460415, 0.001513450755737722, 0.0032092533074319363, 0.0024862857535481453, 0.0029309417586773634, 0.004927022848278284, 0.006232672370970249, 0.0024692541919648647, 0.0018482864834368229, 0.003904422279447317, 0.0023177028633654118, 0.0038102595135569572, 0.002781650749966502, 0.0015226193936541677, 0.007133946754038334, 0.0065668500028550625, 0.0036179032176733017, 0.003845422063022852, 0.003152968594804406, 0.003473605727776885, 0.006291418336331844, 0.0017360621131956577, 0.004114432260394096, 0.004664464388042688, 0.002349372487515211, 0.0023423691745847464, 0.009687120094895363, 0.0023648396600037813, 0.004104121122509241, 0.0013621527468785644, 0.001835900591686368, 0.0015889505157247186, 0.002610348165035248, 0.004974243696779013, 0.006730764172971249, 0.002661848207935691, 0.0028612755704671144, 0.006827699951827526, 0.003045425284653902, 0.0028666898142546415, 0.0033984575420618057, 0.005900366697460413, 0.0033017960377037525, 0.0010037559550255537, 0.004697127267718315, 0.006521624978631735, 0.004374059848487377, 0.0013937620678916574, 0.0029713071417063475, 0.003459624946117401, 0.0020926024299114943, 0.0029996479861438274, 0.001124685863032937, 0.004301122389733791, 0.006353740114718676, 0.005637442227452993, 0.004794823005795479, 0.006386679597198963, 0.0017856815829873085, 0.003967166878283024, 0.0011079906253144145, 0.0019479920156300068]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#테스트 라벨 설정\n",
        "test_frame_labels = uturn7['go_stop_decision'] # 여기에 driving12, truck8, uturn7을 값을 바꿔가며 넣기"
      ],
      "metadata": {
        "id": "G622BrqSo1cw"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 타입 및 길이 확인\n",
        "print(type(test_action_buffer))\n",
        "print(type(test_frame_labels))\n",
        "print(len(test_action_buffer))\n",
        "print(len(test_frame_labels))"
      ],
      "metadata": {
        "id": "XGCFS48Ro1cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115b1ce1-cab8-49e8-a581-13da3a5c1969"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "134\n",
            "134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#결과 저장\n",
        "final_tasks.append(test_action_buffer)\n",
        "final_labels.append(test_frame_labels)"
      ],
      "metadata": {
        "id": "1tJn7gvao1cx"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CL 메트릭 계산\n",
        "IM, FWT, BWT = compute_cl_metrics(final_tasks, final_labels)\n",
        "\n",
        "print(f\"IM (Initial Accuracy): {IM:.5f}\")\n",
        "print(f\"FWT (Forward Transfer): {FWT:.5f}\")\n",
        "print(f\"BWT (Backward Transfer): {BWT:.5f}\")\n"
      ],
      "metadata": {
        "id": "GSUhv42Mo1cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab6825c-7f06-435b-f127-1322c5f1a0fd"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task accuracies: [    0.76119]\n",
            "IM (Initial Accuracy): 0.76119\n",
            "FWT (Forward Transfer): 0.00000\n",
            "BWT (Backward Transfer): 0.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rehearsal 메모리 상태 확인\n",
        "print(f\"Rehearsal memory contains {len(rehearsal_memory.data_buffer)} samples\")\n",
        "print(f\"Memory usage: {len(rehearsal_memory.data_buffer)} / {rehearsal_memory.max_samples}\")"
      ],
      "metadata": {
        "id": "6HpkclyCo1cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74affc42-6296-453b-b910-ccac72861b37"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rehearsal memory contains 900 samples\n",
            "Memory usage: 900 / 900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 샘플의 일부 확인\n",
        "if len(rehearsal_memory.data_buffer) > 0:\n",
        "    sample_data = rehearsal_memory.data_buffer[0]\n",
        "    sample_label = rehearsal_memory.label_buffer[0]\n",
        "    print(f\"Sample data shape: {sample_data.shape}\")\n",
        "    print(f\"Sample label: {sample_label}\")"
      ],
      "metadata": {
        "id": "RalDI5Ezo1cx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14aeafaa-4c1b-464b-d398-0c18cfac6052"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample data shape: (15,)\n",
            "Sample label: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EEqdGv7ho1cx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}